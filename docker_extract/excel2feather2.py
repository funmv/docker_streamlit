import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.graph_objects as go
from datetime import datetime
import time
import stat
import shutil
import gc 
import matplotlib.pyplot as plt 
import glob
import io

# =====================================
# ë°˜ë“œì‹œ ì²« ë²ˆì§¸ Streamlit ëª…ë ¹ì–´!
# =====================================
st.set_page_config(
    page_title="ë°ì´í„° ë³€í™˜ ë„êµ¬", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# =====================================
# í•œê¸€ í°íŠ¸ ì„¤ì •
# =====================================
def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì • í•¨ìˆ˜"""
    try:
        from matplotlib import font_manager, rc
        # Windows í™˜ê²½
        try:
            font_name = font_manager.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
            rc('font', family=font_name)
            plt.rcParams['axes.unicode_minus'] = False
            return "Windows í°íŠ¸ ë¡œë“œ ì„±ê³µ"
        except:
            # Linux í™˜ê²½
            try:
                font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
                font_name = font_manager.FontProperties(fname=font_path).get_name()
                rc('font', family=font_name)  
                plt.rcParams['axes.unicode_minus'] = False
                return "Linux í°íŠ¸ ë¡œë“œ ì„±ê³µ"
            except:
                # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                plt.rcParams['axes.unicode_minus'] = False
                return "ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©"
    except Exception as e:
        return f"í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}"

# í°íŠ¸ ì„¤ì • ì‹¤í–‰
setup_korean_font()

# matplotlib ê²½ê³  ì œê±°ë¥¼ ìœ„í•œ ì„¤ì •
plt.rcParams['figure.max_open_warning'] = 50

# âœ… FutureWarning í•´ê²°ì„ ìœ„í•œ ì„¤ì •
try:
    pd.set_option('future.no_silent_downcasting', True)
except Exception:
    pass

# =====================================
# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =====================================
def safe_rmtree(path):
    """ì•ˆì „í•œ í´ë” ì‚­ì œ"""
    def handle_readonly(func, path, exc):
        os.chmod(path, stat.S_IWRITE)
        func(path)
    
    if os.path.exists(path):
        try:
            shutil.rmtree(path, onerror=handle_readonly)
        except OSError:
            for root, dirs, files in os.walk(path, topdown=False):
                for file in files:
                    try:
                        file_path = os.path.join(root, file)
                        os.chmod(file_path, stat.S_IWRITE)
                        os.unlink(file_path)
                    except:
                        pass

def remove_korean_and_special_chars(text):
    """í•œê¸€, íŠ¹ìˆ˜ë¬¸ì ë° ê³µë°± ì œê±° (ì˜ë¬¸, ìˆ«ì, -, _ ë§Œ í—ˆìš©)"""
    import re
    return re.sub(r'[^a-zA-Z0-9\-_]', '', text)

# =====================================
# ì‚¬ì´ë“œë°” ê³µí†µ í•¨ìˆ˜
# =====================================
def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    with st.sidebar:
        st.markdown(
            """
            <style>
            .bottom-info {
                position: fixed;
                bottom: 0;
                left: 0;
                width: 21rem;
                max-width: 21rem;
                background-color: var(--background-color);
                padding: 1rem;
                border-top: 1px solid var(--border-color);
                z-index: 999;
                box-sizing: border-box;
            }
            .bottom-info hr {
                margin: 0.2rem 0;
                border-color: var(--text-color-light);
                width: 100%;
            }
            </style>
            <div class="bottom-info">
                <hr>
                ğŸ§  <strong>íšŒì‚¬ëª…:</strong> ãˆœíŒŒì‹œë””ì—˜<br>
                ğŸ« <strong>ì—°êµ¬ì‹¤:</strong> visLAB@PNU<br>
                ğŸ‘¨â€ğŸ’» <strong>ì œì‘ì:</strong> (C)Dong2<br>
                ğŸ› ï¸ <strong>ë²„ì „:</strong> V.1.3 (06-03-2025)<br>
                <hr>
            </div>
            """, 
            unsafe_allow_html=True
        )

# =====================================
# Excel ê´€ë ¨ í•¨ìˆ˜ë“¤
# =====================================
def identify_date_columns(df, date_column_name):
    """ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ ì‹ë³„í•˜ëŠ” í•¨ìˆ˜"""
    date_columns = set()
    
    if date_column_name and date_column_name in df.columns:
        date_columns.add(date_column_name)
    
    date_keywords = ['date', 'time', 'datetime', 'timestamp', 'ë‚ ì§œ', 'ì‹œê°„', 'ì¼ì‹œ']
    for col in df.columns:
        col_lower = str(col).lower()
        if any(keyword in col_lower for keyword in date_keywords):
            date_columns.add(col)
    
    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            date_columns.add(col)
    
    return list(date_columns)

def extract_unique_text_values(df, date_columns):
    """DataFrameì—ì„œ ëª¨ë“  ë¬¸ìê°’ë“¤ê³¼ ë¹ˆë„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    text_frequency = {}
    text_columns_dict = {}
    
    columns_to_process = [col for col in df.columns if col not in date_columns]
    
    for column in columns_to_process:
        text_values = df[column].dropna().astype(str)
        
        for value in text_values:
            try:
                float(value)
            except (ValueError, TypeError):
                if value not in ['nan', 'None', '']:
                    if value not in text_frequency:
                        text_frequency[value] = 0
                        text_columns_dict[value] = set()
                    
                    value_count = (text_values == value).sum()
                    text_frequency[value] += value_count
                    text_columns_dict[value].add(column)
    
    return text_frequency, text_columns_dict

def extract_date_info_from_data(df, date_column):
    """ë°ì´í„°ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ íŒŒì¼ëª…ìš© ë¬¸ìì—´ ìƒì„±"""
    try:
        if date_column in df.columns:
            date_series = pd.to_datetime(df[date_column], errors='coerce')
            date_series = date_series.dropna()
            
            if len(date_series) > 0:
                start_date = date_series.min()
                end_date = date_series.max()
                
                try:
                    start_str = start_date.strftime("%Y%m%d_%H%M")
                    end_str = end_date.strftime("%Y%m%d_%H%M")
                    
                    if start_str == end_str:
                        return f"_{start_str}"
                    else:
                        start_date_only = start_date.strftime("%Y%m%d")
                        end_date_only = end_date.strftime("%Y%m%d")
                        
                        if start_date_only == end_date_only:
                            return f"_{start_date_only}"
                        else:
                            return f"_{start_date_only}_{end_date_only}"
                            
                except Exception:
                    start_str = start_date.strftime("%Y%m%d")
                    end_str = end_date.strftime("%Y%m%d")
                    
                    if start_str == end_str:
                        return f"_{start_str}"
                    else:
                        return f"_{start_str}_{end_str}"
        
        return ""
    except Exception:
        return ""

def apply_text_mapping(df, mapping_dict, date_columns):
    """DataFrameì— ë¬¸ì-ìˆ«ì ë§¤í•‘ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜"""
    df_converted = df.copy()
    
    columns_to_process = [col for col in df_converted.columns if col not in date_columns]
    
    for column in columns_to_process:
        for text, number in mapping_dict.items():
            try:
                df_converted[column] = df_converted[column].replace(text, number).infer_objects(copy=False)
            except (AttributeError, TypeError):
                df_converted[column] = df_converted[column].replace(text, number)
        
        try:
            df_converted[column] = pd.to_numeric(df_converted[column], errors='coerce')
        except:
            pass
    
    for date_col in date_columns:
        if date_col in df_converted.columns:
            try:
                df_converted[date_col] = pd.to_datetime(df_converted[date_col], errors='coerce')
            except:
                pass
    
    return df_converted

@st.cache_data(show_spinner=False, max_entries=3, ttl=300)
def load_excel(file, sheet_name, usecols, nrows, date_column, skiprows, skip_next=0):
    """Excel íŒŒì¼ì„ ì½ëŠ” í•¨ìˆ˜"""
    
    if file is None:
        raise ValueError("íŒŒì¼ì´ Noneì…ë‹ˆë‹¤.")
    
    if sheet_name is None or sheet_name == "":
        raise ValueError("ì‹œíŠ¸ëª…ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    def count_rows():    
        if ':' in usecols:
            first_col = usecols.split(':')[0]
        else:
            first_col = usecols

        range_col = f"{first_col}:{first_col}"
        temp_df = pd.read_excel(
            file,
            sheet_name=sheet_name,
            skiprows=skiprows + 1 + skip_next,
            header=None,
            usecols=range_col,  
            engine='openpyxl',
        )
        mask = temp_df.iloc[:, 0].notna() & (temp_df.iloc[:, 0].astype(str).str.strip() != '')
        temp_count = mask.sum()
        final_nrows = temp_count - 10 if temp_count > 10 else temp_count
        return final_nrows

    try:
        if skip_next > 0:
            header_df = pd.read_excel(
                file,
                sheet_name=sheet_name,
                skiprows=skiprows,
                nrows=1,
                usecols=usecols,
                engine='openpyxl'
            )   
            
            column_names = header_df.columns.tolist()
            
            try:
                final_nrows = count_rows()
            except Exception:
                final_nrows = nrows
            
            data_df = pd.read_excel(
                file,
                sheet_name=sheet_name,
                skiprows=skiprows + 1 + skip_next,
                header=None,
                usecols=usecols,
                nrows=final_nrows,
                engine='openpyxl',
                na_values=['I/O Timeout', 'Configure', 'Not Connect', 'Bad', 'Comm Fail']
            )
            
            data_df.columns = column_names
            
        else:
            try:
                final_nrows = count_rows()
            except Exception:
                final_nrows = nrows

            data_df = pd.read_excel(
                file,
                sheet_name=sheet_name,
                usecols=usecols,
                nrows=final_nrows,
                skiprows=skiprows,
                header=0,
                engine='openpyxl',
                na_values=['I/O Timeout', 'Configure', 'Not Connect', 'Bad', 'Comm Fail']
            )
        
        if date_column and date_column in data_df.columns:
            try:
                data_df[date_column] = pd.to_datetime(data_df[date_column], errors='coerce')
            except Exception:
                pass
        
        gc.collect()
        
        return data_df
        
    except Exception as e:
        gc.collect()
        raise RuntimeError(f"Excel ì½ê¸° ì‹¤íŒ¨: {str(e)}")

# =====================================
# CSV ê´€ë ¨ í•¨ìˆ˜ë“¤
# =====================================
@st.cache_data(show_spinner=False)
def replace_999_with_neighbors_mean(df):
   """999 ê°’ì„ ì¸ì ‘ê°’ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´"""
   df = df.copy()
   for col in df.columns:
       values = df[col].values
       for i in range(1, len(values) - 1):
           if values[i] == 999:
               if values[i - 1] != 999 and values[i + 1] != 999:
                   values[i] = (values[i - 1] + values[i + 1]) / 2
               else:
                   values[i] = np.nan
       df[col] = values
   return df

def get_feather_files_in_directory():
    """ì €ì¥ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  .ftr íŒŒì¼ ì°¾ê¸°"""
    default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()
    feather_files = []
    
    try:
        for file in os.listdir(default_root):
            if file.endswith(".ftr"):
                file_path = os.path.join(default_root, file)
                file_size = os.path.getsize(file_path) / (1024 * 1024)
                feather_files.append({
                    "íŒŒì¼ëª…": file,
                    "ê²½ë¡œ": file_path,
                    "í¬ê¸°(MB)": f"{file_size:.2f}"
                })
    except Exception as e:
        st.error(f"íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    return feather_files

def create_zip_download(file_paths):
    """ì—¬ëŸ¬ íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„"""
    import zipfile
    
    zip_buffer = io.BytesIO()
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for file_path in file_paths:
            if os.path.exists(file_path):
                file_name = os.path.basename(file_path)
                zip_file.write(file_path, file_name)
    
    zip_buffer.seek(0)
    return zip_buffer.getvalue()

# =====================================
# íƒ­ 1: Excel â†’ Feather ë³€í™˜ê¸°
# =====================================
def tab_excel_converter():
    """íƒ­ 1: Excel â†’ Feather ë³€í™˜ê¸°"""
    st.header("ğŸ“Š ëŒ€ìš©ëŸ‰ Excel â†’ Feather ë³€í™˜ê¸°")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    session_keys = ['text_mapping', 'text_frequency', 'text_columns', 'date_columns', 
                   'file_loaded', 'df', 'raw_df']
    for key in session_keys:
        if key not in st.session_state:
            st.session_state[key] = {} if key in ['text_mapping', 'text_frequency', 'text_columns'] else []

    uploaded_file = st.file_uploader("ğŸ“‚ Excel íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=["xlsx", "xls"])

    # Excel ì½ê¸° ì„¤ì •
    with st.expander("ğŸ”§ Excel ì½ê¸° ì„¤ì •", expanded=True):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            usecols = st.text_input("ì½ì„ ì»¬ëŸ¼ ë²”ìœ„ (usecols)", value="A:CY")
            skiprows = st.number_input("ê±´ë„ˆë›¸ í–‰ ìˆ˜ (skiprows)", min_value=0, value=3)
        
        with col2:
            date_column = st.text_input("ë‚ ì§œ ì»¬ëŸ¼ëª…", value="Description")
            skip_next = st.number_input("í—¤ë“œí–‰ ë‹¤ìŒ ê±´ë„ˆë›¸ ìˆ˜", min_value=0, value=2)
        
        with col3:
            nrows = st.number_input("ì½ì„ í–‰ ìˆ˜ (nrows)", min_value=1000, max_value=10**7, step=10000, value=3000)

    # ì‹œíŠ¸ ì„ íƒ
    sheet_name = None
    available_sheets = []

    if uploaded_file is not None:
        try:
            excel_file = pd.ExcelFile(uploaded_file)
            available_sheets = excel_file.sheet_names
            
            if len(available_sheets) == 1:
                sheet_name = available_sheets[0]
                st.success(f"ğŸ“‹ ì‹œíŠ¸ ìë™ ì„ íƒ: {sheet_name}")
            elif len(available_sheets) > 1:
                sheet_name = st.selectbox("ì½ì„ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=available_sheets, index=0)
                st.info(f"ì´ {len(available_sheets)}ê°œ ì‹œíŠ¸ ì¤‘ '{sheet_name}' ì„ íƒë¨")
            else:
                st.error("âŒ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"âŒ ì‹œíŠ¸ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

    # Excel ë¡œë”©
    if uploaded_file is not None and sheet_name is not None and st.button("Excel ì½ê¸°"):
        progress_container = st.container()
        status_container = st.container()
        
        try:
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                status_text.text("ğŸš€ Excel íŒŒì¼ ì½ê¸° ì‹œì‘...")
                progress_bar.progress(10)
                time.sleep(0.1)
                
                status_text.text(f"ğŸ“– ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘...")
                progress_bar.progress(30)
                
                df = load_excel(
                    file=uploaded_file,
                    sheet_name=sheet_name,
                    usecols=usecols,
                    nrows=nrows,
                    date_column=date_column,
                    skiprows=skiprows,   
                    skip_next=skip_next   
                )
                
                progress_bar.progress(50)
                status_text.text("ğŸ—“ï¸ ë‚ ì§œ ì»¬ëŸ¼ ì‹ë³„ ì¤‘...")
                
                date_columns = identify_date_columns(df, date_column)
                st.session_state.date_columns = date_columns
                
                progress_bar.progress(60)
                status_text.text("ğŸ” ë°ì´í„° ë¶„ì„ ì¤‘...")
                
                if df is not None and len(df) > 0:
                    st.session_state.raw_df = df.copy()
                    
                    progress_bar.progress(80)
                    status_text.text("ğŸ”¤ ë¬¸ìê°’ ì¶”ì¶œ ì¤‘...")
                    
                    text_frequency, text_columns_dict = extract_unique_text_values(df, date_columns)
                    st.session_state.text_frequency = text_frequency
                    st.session_state.text_columns = text_columns_dict
                    
                    st.session_state.df = df
                    st.session_state.file_loaded = True
                    
                    progress_bar.progress(90)
                    status_text.text("ğŸ“ íŒŒì¼ëª… ìƒì„± ì¤‘...")
                    
                    base_filename = os.path.splitext(uploaded_file.name)[0]
                    date_info = extract_date_info_from_data(df, date_column)
                    sheet_info = f"_{sheet_name}" if sheet_name != "Sheet1" else ""
                    enhanced_filename = f"{base_filename}{sheet_info}{date_info}"
                    st.session_state.last_filename = enhanced_filename
                    
                    progress_bar.progress(100)
                    status_text.text("âœ… ì™„ë£Œ!")
                    
                    time.sleep(0.5)
                    progress_container.empty()
                
            with status_container:
                st.success(f"ğŸ‰ Excel íŒŒì¼ ì½ê¸° ì™„ë£Œ!")
                st.info(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df):,}í–‰ Ã— {len(df.columns)}ì—´")
                
                if date_columns:
                    st.success(f"ğŸ—“ï¸ ì‹ë³„ëœ ë‚ ì§œ ì»¬ëŸ¼: {date_columns}")
                    st.info("ğŸ“Œ ì´ ì»¬ëŸ¼ë“¤ì€ ë¬¸ì-ìˆ«ì ë³€í™˜ì—ì„œ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.")
                
                if text_frequency:
                    st.warning(f"ğŸ”¤ ë°œê²¬ëœ ë¬¸ìê°’ë“¤: {list(text_frequency.keys())}")
                    st.info("ğŸ‘‡ ì•„ë˜ì—ì„œ ê° ë¬¸ìê°’ì— ëŒ€ì‘í•  ìˆ«ìë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
                else:
                    st.success("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ìˆ«ì í˜•íƒœì´ê±°ë‚˜ ë‚ ì§œ í˜•íƒœì…ë‹ˆë‹¤.")
                    
                gc.collect()
                
        except Exception as e:
            progress_container.empty()
            st.error(f"âŒ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ!")
            st.error(f"ğŸ” ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ—‘ï¸ ìºì‹œ í´ë¦¬ì–´"):
                    st.cache_data.clear()
                    st.rerun()
            with col2:
                if st.button("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨"):
                    st.rerun()

    # ë¬¸ì-ìˆ«ì ë§¤í•‘ ì„¤ì •
    if st.session_state.get('file_loaded', False) and st.session_state.get('text_frequency', {}):
        st.markdown("---")
        st.subheader("ğŸ”¢ ë¬¸ì-ìˆ«ì ë³€í™˜ ì„¤ì •")
        
        if st.session_state.date_columns:
            st.info(f"ğŸ›¡ï¸ ë³´í˜¸ë˜ëŠ” ë‚ ì§œ ì»¬ëŸ¼: {st.session_state.date_columns}")
            st.caption("ì´ ì»¬ëŸ¼ë“¤ì€ ë¬¸ì-ìˆ«ì ë³€í™˜ì—ì„œ ìë™ìœ¼ë¡œ ì œì™¸ë˜ì–´ ì›ë³¸ í˜•íƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
        
        st.write("**ë°œê²¬ëœ ë¬¸ìê°’ë“¤ê³¼ ë¹ˆë„ ì •ë³´:**")
        
        frequency_data = []
        for text, freq in st.session_state.text_frequency.items():
            columns_list = list(st.session_state.text_columns[text])
            frequency_data.append({
                "ë¬¸ìê°’": text,
                "ë¹ˆë„": f"{freq:,}",
                "ì¶œí˜„ ì»¬ëŸ¼": ", ".join(columns_list) if len(columns_list) <= 3 else f"{', '.join(columns_list[:3])}... (ì´ {len(columns_list)}ê°œ)"
            })
        
        frequency_df = pd.DataFrame(frequency_data).sort_values('ë¹ˆë„')
        st.dataframe(frequency_df, use_container_width=True)
        
        number_options = [0, 1, 5, 10, 25, 50, 75, 100]
        
        st.markdown("---")
        st.write("**ìˆ«ì ë§¤í•‘ ì„¤ì •:**")
        
        mapping_dict = {}
        sorted_texts = sorted(st.session_state.text_frequency.keys(), 
                             key=lambda x: st.session_state.text_frequency[x], reverse=True)
        
        cols = st.columns(2)
        for i, text in enumerate(sorted_texts):
            with cols[i % 2]:
                if text.upper() in ['OFF', 'STOP', 'FALSE', '0']:
                    default_idx = 0
                elif text.upper() in ['ON', 'RUNNING', 'TRUE', '1']:
                    default_idx = 1
                else:
                    default_idx = 1
                
                freq = st.session_state.text_frequency[text]
                selected_number = st.selectbox(
                    f"{text} ({freq}íšŒ) â†’ ",
                    options=number_options,
                    index=default_idx,
                    key=f"mapping_{text}"
                )
                mapping_dict[text] = selected_number
        
        if st.button("ğŸ”„ ë¬¸ì-ìˆ«ì ë³€í™˜ ì ìš©"):
            try:
                converted_df = apply_text_mapping(st.session_state.raw_df, mapping_dict, st.session_state.date_columns)
                st.session_state.df = converted_df
                st.session_state.text_mapping = mapping_dict
                
                st.success("âœ… ë¬¸ì-ìˆ«ì ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                st.write("**ì ìš©ëœ ë§¤í•‘:**")
                for text, number in mapping_dict.items():
                    st.write(f"â€¢ {text} â†’ {number}")
                
                numeric_columns = st.session_state.df.select_dtypes(include=[np.number]).columns
                datetime_columns = st.session_state.df.select_dtypes(include=['datetime64']).columns
                
                st.info(f"âœ… ìˆ«ì ì»¬ëŸ¼ ìˆ˜: {len(numeric_columns)}/{len(st.session_state.df.columns)}")
                st.info(f"ğŸ—“ï¸ ë‚ ì§œ ì»¬ëŸ¼ ìˆ˜: {len(datetime_columns)}/{len(st.session_state.df.columns)}")
                
            except Exception as e:
                st.error(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")

    # ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ ì„¹ì…˜
    if st.session_state.get('file_loaded', False) and st.session_state.get('df') is not None:
        df = st.session_state.df
        st.markdown("---")
        st.success("âœ… Excel ë¡œë”© ì™„ë£Œ!")

        # ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        st.subheader("ğŸ§¾ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸")
        with st.expander(f"ì „ì²´ ì»¬ëŸ¼ ë³´ê¸° (ì´ {len(df.columns)}ê°œ)", expanded=True):
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
            object_cols = df.select_dtypes(include=['object']).columns.tolist()
            
            col_info = []
            for i, col in enumerate(df.columns):
                if col in numeric_cols:
                    col_type = "ğŸ”¢ ìˆ«ì"
                elif col in datetime_cols:
                    col_type = "ğŸ—“ï¸ ë‚ ì§œ"
                elif col in object_cols:
                    col_type = "ğŸ”¤ í…ìŠ¤íŠ¸"
                else:
                    col_type = "â“ ê¸°íƒ€"
                
                col_info.append(f"{i+1}. {col} ({col_type})")
            
            st.markdown(
                f"""
                <div style='max-height: 300px; overflow-y: scroll; padding: 10px; border: 1px solid #ccc; background-color: #f9f9f9'>
                {"<br>".join(col_info)}
                </div>
                """,
                unsafe_allow_html=True
            )

        # ì œê±°í•  ì»¬ëŸ¼ ì„ íƒ
        st.subheader("ğŸ—‘ï¸ ì œê±°í•  ì»¬ëŸ¼ ì„ íƒ")
        
        removable_columns = [col for col in df.columns.tolist() if col not in st.session_state.date_columns]
        
        if st.session_state.date_columns:
            st.info(f"ğŸ›¡ï¸ ë‚ ì§œ ì»¬ëŸ¼ {st.session_state.date_columns}ì€(ëŠ”) ë³´í˜¸ë˜ì–´ ì œê±° ì˜µì…˜ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
        
        cols_to_drop = st.multiselect(
            "ë°ì´í„°í”„ë ˆì„ì—ì„œ ì œê±°í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
            removable_columns,
            help="ë‚ ì§œ ì»¬ëŸ¼ì€ ìë™ìœ¼ë¡œ ë³´í˜¸ë˜ì–´ ì„ íƒ ëª©ë¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤."
        )

        if st.button("ì„ íƒí•œ ì»¬ëŸ¼ ì œê±°í•˜ê¸°"):
            if cols_to_drop:
                safe_cols_to_drop = [col for col in cols_to_drop if col not in st.session_state.date_columns]
                
                if safe_cols_to_drop:
                    df = df.drop(columns=safe_cols_to_drop)
                    st.session_state.df = df
                    st.success(f"âœ… ì„ íƒí•œ {len(safe_cols_to_drop)}ê°œ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ!")
                    st.info(f"ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
                    
                    if len(safe_cols_to_drop) != len(cols_to_drop):
                        protected_count = len(cols_to_drop) - len(safe_cols_to_drop)
                        st.warning(f"ğŸ›¡ï¸ {protected_count}ê°œ ë‚ ì§œ ì»¬ëŸ¼ì€ ë³´í˜¸ë˜ì–´ ì œê±°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ğŸ›¡ï¸ ì„ íƒí•œ ëª¨ë“  ì»¬ëŸ¼ì´ ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼ì…ë‹ˆë‹¤.")
            else:
                st.warning("â— ì œê±°í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.")

        # ë³€í™˜ ì „/í›„ ë¹„êµ
        if st.session_state.text_frequency and 'raw_df' in st.session_state:
            st.markdown("---")
            st.subheader("ğŸ‘€ ë°ì´í„° ë³€í™˜ ë¹„êµ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ë³€í™˜ ì „ (ì›ë³¸):**")
                st.dataframe(st.session_state.raw_df.head(), use_container_width=True)
            
            with col2:
                st.write("**ë³€í™˜ í›„ (ìˆ«ì/ë‚ ì§œ):**")
                st.dataframe(df.head(), use_container_width=True)
                
            if st.session_state.date_columns:
                st.info("ğŸ›¡ï¸ ë‚ ì§œ ì»¬ëŸ¼ë“¤ì€ ì›ë³¸ í˜•íƒœë¥¼ ìœ ì§€í•˜ë©° ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ì €ì¥ ì„¤ì •
        st.markdown("---")
        st.subheader("ğŸ’¾ Feather ì €ì¥ ì„¤ì •")
        default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()

        default_filename = st.session_state.get('last_filename', 'data')
        save_name = st.text_input(
            "ğŸ“„ ì €ì¥ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)", 
            value=default_filename,
            help="ë‚ ì§œ ì •ë³´ì™€ ì‹œíŠ¸ëª…ì´ ìë™ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤"
        )    

        # FTR ì €ì¥ ë²„íŠ¼
        if st.button("ğŸ’¾ Featherë¡œ ì €ì¥í•˜ê¸°"):
            save_path = os.path.join(default_root, save_name + ".ftr")
            try:
                if df is None or df.empty:
                    st.error("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                else:
                    df_to_save = df.reset_index(drop=True)
                    df_to_save.to_feather(save_path)
                    st.success(f"âœ… Feather íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ:\n`{save_path}`")
                    st.info(f"ğŸ“Š ì €ì¥ëœ ë°ì´í„°: {len(df_to_save)}í–‰ Ã— {len(df_to_save.columns)}ì—´")
                    
                    if st.session_state.date_columns:
                        preserved_date_cols = [col for col in st.session_state.date_columns if col in df_to_save.columns]
                        if preserved_date_cols:
                            st.success(f"ğŸ—“ï¸ ë³´ì¡´ëœ ë‚ ì§œ ì»¬ëŸ¼: {preserved_date_cols}")
                            
            except Exception as e:
                st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

        # Feather ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
        st.subheader("ğŸ’¾ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ")

        default_download_filename = st.session_state.get('last_filename', 'ftr_data')
            
        download_name = st.text_input(
            "ğŸ“„ ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)", 
            value=default_download_filename,
            help="ë‚ ì§œ ì •ë³´ì™€ ì‹œíŠ¸ëª…ì´ ìë™ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤"
        )

        try:
            buffer = io.BytesIO()
            
            if df is None or df.empty:
                st.error("âŒ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                df_to_save = df.reset_index(drop=True)
                df_to_save.to_feather(buffer)
                buffer.seek(0)
                
                st.download_button(
                    label="ğŸ“¥ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=buffer.getvalue(),
                    file_name=f"{download_name}.ftr",
                    mime="application/octet-stream"
                )
                
                st.success(f"âœ… ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ: {download_name}.ftr")
                
                if st.session_state.date_columns:
                    preserved_date_cols = [col for col in st.session_state.date_columns if col in df_to_save.columns]
                    if preserved_date_cols:
                        st.info(f"ğŸ—“ï¸ ë‹¤ìš´ë¡œë“œ íŒŒì¼ì— ë³´ì¡´ëœ ë‚ ì§œ ì»¬ëŸ¼: {preserved_date_cols}")
            
        except Exception as e:
            st.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì‹¤íŒ¨: {e}")

        # ê³ ì† Plotly ì‹œê°í™”
        st.markdown("---")
        st.subheader("âš¡ Plotly ê³ ì† ì‹œê°í™” (WebGL)")
        num_cols = df.select_dtypes(include='number').columns
        
        if len(num_cols) > 0:
            visualizable_columns = [col for col in df.columns.tolist() 
                                   if col not in st.session_state.date_columns and pd.api.types.is_numeric_dtype(df[col])]
            
            if visualizable_columns:
                selected_columns = st.multiselect(
                    'ì‹œê°í™”í•  ìˆ«ì ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”',
                    visualizable_columns,
                    default=visualizable_columns[:2] if len(visualizable_columns) >= 2 else visualizable_columns[:1]
                )            
                
                if selected_columns:
                    downsample_rate = st.slider("ğŸ“‰ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ (1/N)", 1, 50, 10)
                    
                    fig = go.Figure()
                    
                    for col in selected_columns:
                        if pd.api.types.is_numeric_dtype(df[col]):
                            downsampled_y = df[col][::downsample_rate]
                            fig.add_trace(go.Scattergl(
                                y=downsampled_y,
                                mode='lines',
                                name=str(col)
                            ))
                    
                    fig.update_layout(
                        title=f"ì„ íƒí•œ ì»¬ëŸ¼ ì‹œê°í™” (1/{downsample_rate} ë‹¤ìš´ìƒ˜í”Œë§)",
                        xaxis=dict(rangeslider=dict(visible=False)),
                        margin=dict(l=20, r=20, t=40, b=20),
                        height=300
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    if st.session_state.date_columns:
                        available_date_cols = [col for col in st.session_state.date_columns if col in df.columns]
                        if available_date_cols:
                            st.info("ğŸ’¡ ì‹œê°„ì¶• ì‹œê°í™”ë¥¼ ì›í•˜ë©´ ì•„ë˜ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ Xì¶•ìœ¼ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            
                            use_date_axis = st.checkbox("ğŸ—“ï¸ ë‚ ì§œë¥¼ Xì¶•ìœ¼ë¡œ ì‚¬ìš©")
                            if use_date_axis:
                                date_col_for_x = st.selectbox("Xì¶•ìœ¼ë¡œ ì‚¬ìš©í•  ë‚ ì§œ ì»¬ëŸ¼ ì„ íƒ:", available_date_cols)
                                
                                if date_col_for_x and selected_columns:
                                    fig_time = go.Figure()
                                    
                                    for col in selected_columns:
                                        if pd.api.types.is_numeric_dtype(df[col]):
                                            downsampled_df = df.iloc[::downsample_rate]
                                            fig_time.add_trace(go.Scattergl(
                                                x=downsampled_df[date_col_for_x],
                                                y=downsampled_df[col],
                                                mode='lines',
                                                name=str(col)
                                            ))
                                    
                                    fig_time.update_layout(
                                        title=f"ì‹œê°„ì¶• ì‹œê°í™” (X: {date_col_for_x})",
                                        xaxis_title=date_col_for_x,
                                        yaxis_title="ê°’",
                                        margin=dict(l=20, r=20, t=40, b=20),
                                        height=400
                                    )
                                    st.plotly_chart(fig_time, use_container_width=True)
                else:
                    st.info("ì‹œê°í™”í•  ìˆ«ì ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            else:
                st.info("ì‹œê°í™” ê°€ëŠ¥í•œ ìˆ«ì ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ ì»¬ëŸ¼ì€ ì œì™¸ë¨)")
        else:
            st.info("ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ëª¨ë“  ì‹œíŠ¸ì— ì¼ê´„ ì ìš© ê¸°ëŠ¥
        st.markdown("---")
        st.header("ğŸ”„ ëª¨ë“  ì‹œíŠ¸ì— ì¼ê´„ ì ìš©")
        
        if uploaded_file is not None:
            st.subheader("ğŸ“‹ í˜„ì¬ ì ìš©í•  ì„¤ì • ìš”ì•½")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ğŸ”¢ ë¬¸ì-ìˆ«ì ë§¤í•‘ ì„¤ì •:**")
                if st.session_state.text_mapping:
                    for text, number in st.session_state.text_mapping.items():
                        st.write(f"â€¢ {text} â†’ {number}")
                else:
                    st.write("ì„¤ì •ëœ ë§¤í•‘ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
                st.write("**ğŸ›¡ï¸ ë³´í˜¸ë˜ëŠ” ë‚ ì§œ ì»¬ëŸ¼:**")
                if st.session_state.date_columns:
                    for col in st.session_state.date_columns:
                        st.write(f"â€¢ {col}")
                else:
                    st.write("ì‹ë³„ëœ ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            with col2:
                st.write("**ğŸ—‘ï¸ ì œê±°í•  ì»¬ëŸ¼ ì„¤ì •:**")
                if 'cols_to_drop' in locals() and cols_to_drop:
                    for col in cols_to_drop:
                        st.write(f"â€¢ {col}")
                else:
                    st.write("ì œê±°í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            if len(available_sheets) > 0:
                st.write(f"**ğŸ“‹ ì²˜ë¦¬ ëŒ€ìƒ ì‹œíŠ¸ ({len(available_sheets)}ê°œ)**")
            else:
                st.error("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
            if len(available_sheets) > 1:
                st.markdown("---")
                if st.button("ğŸš€ ëª¨ë“  ì‹œíŠ¸ì— ë™ì¼í•œ ì²˜ë¦¬ ì ìš© ë° ì €ì¥", type="primary"):
                    
                    current_mapping = st.session_state.text_mapping.copy()
                    current_cols_to_drop = cols_to_drop.copy() if 'cols_to_drop' in locals() else []
                    current_date_columns = st.session_state.date_columns.copy()
                    
                    st.info(f"ğŸ”„ {len(available_sheets)}ê°œ ì‹œíŠ¸ì— ì¼ê´„ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    success_files = []
                    error_files = []

                    default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()
                    for file_path in glob.glob(os.path.join(default_root, "*")):
                        try:
                            if os.path.isfile(file_path):
                                os.remove(file_path)
                            elif os.path.isdir(file_path):
                                shutil.rmtree(file_path)
                        except Exception as e:
                            print(f'ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}')

                    
                    for idx, target_sheet in enumerate(available_sheets):
                        try:
                            status_text.text(f"ì²˜ë¦¬ ì¤‘: {target_sheet} ({idx+1}/{len(available_sheets)})")
                            
                            sheet_df = load_excel(
                                file=uploaded_file,
                                sheet_name=target_sheet,
                                usecols=usecols,
                                nrows=nrows,
                                date_column=date_column,
                                skiprows=skiprows,
                                skip_next=skip_next
                            )
                            
                            sheet_date_columns = identify_date_columns(sheet_df, date_column)
                            
                            if current_mapping:
                                sheet_df = apply_text_mapping(sheet_df, current_mapping, sheet_date_columns)
                            
                            if current_cols_to_drop:
                                cols_to_remove = [col for col in current_cols_to_drop 
                                                if col in sheet_df.columns and col not in sheet_date_columns]
                                if cols_to_remove:
                                    sheet_df = sheet_df.drop(columns=cols_to_remove)

                            base_filename = os.path.splitext(uploaded_file.name)[0]
                            date_info = extract_date_info_from_data(sheet_df, date_column)
                            sheet_info = f"_{target_sheet}" if target_sheet != "Sheet1" else ""

                            safe_base = remove_korean_and_special_chars(base_filename)
                            safe_sheet = remove_korean_and_special_chars(sheet_info)
                            safe_date_info = remove_korean_and_special_chars(date_info)

                            timestamp_suffix = str(int(time.time() * 1000))[-6:]
                            final_filename = f"{safe_date_info}_{timestamp_suffix}"
                            
                            save_path = os.path.join(default_root, final_filename + ".ftr")
                            
                            sheet_df.reset_index(drop=True).to_feather(save_path)
                            success_files.append((target_sheet, save_path, len(sheet_df), sheet_date_columns))
                            
                        except Exception as e:
                            error_files.append((target_sheet, str(e)))
                        
                        progress_bar.progress((idx + 1) / len(available_sheets))
                    
                    status_text.text("ì²˜ë¦¬ ì™„ë£Œ!")
                    
                    if success_files:
                        st.success(f"âœ… {len(success_files)}ê°œ ì‹œíŠ¸ ì²˜ë¦¬ ì™„ë£Œ!")
                        
                        success_data = []
                        for sheet, path, rows, date_cols in success_files:
                            success_data.append({
                                "ì‹œíŠ¸ëª…": sheet,
                                "í–‰ ìˆ˜": f"{rows:,}",
                                "ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼": ", ".join(date_cols) if date_cols else "ì—†ìŒ",
                                "íŒŒì¼ ê²½ë¡œ": path
                            })
                        
                        st.dataframe(pd.DataFrame(success_data), use_container_width=True)
                    
                    if error_files:
                        st.error(f"âŒ {len(error_files)}ê°œ ì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨:")
                        for sheet, error in error_files:
                            st.write(f"â€¢ {sheet}: {error}")
            
            else:
                st.info("ğŸ’¡ ì‹œíŠ¸ê°€ 1ê°œë¿ì´ë¯€ë¡œ ì¼ê´„ ì²˜ë¦¬ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # ì €ì¥ëœ ëª¨ë“  Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
        st.markdown("---")
        st.header("ğŸ“¦ ì €ì¥ëœ Feather íŒŒì¼ ì¼ê´„ ë‹¤ìš´ë¡œë“œ")
        
        if st.button("ğŸ” ì €ì¥ëœ Feather íŒŒì¼ ì¡°íšŒ"):
            feather_files = get_feather_files_in_directory()
            
            if feather_files:
                st.write(f"**ğŸ“ ë°œê²¬ëœ Feather íŒŒì¼ ({len(feather_files)}ê°œ):**")
                
                files_df = pd.DataFrame(feather_files)
                st.dataframe(files_df, use_container_width=True)
                
                total_size = sum(float(f["í¬ê¸°(MB)"]) for f in feather_files)
                st.info(f"ğŸ“Š ì´ íŒŒì¼ í¬ê¸°: {total_size:.2f} MB")
                
                if len(feather_files) > 0:
                    try:
                        file_paths = [f["ê²½ë¡œ"] for f in feather_files]
                        zip_data = create_zip_download(file_paths)
                        
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        zip_filename = f"feather_files_{timestamp}.zip"
                        
                        st.download_button(
                            label=f"ğŸ“¥ ëª¨ë“  Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({len(feather_files)}ê°œ íŒŒì¼)",
                            data=zip_data,
                            file_name=zip_filename,
                            mime="application/zip"
                        )
                        
                        st.success(f"âœ… {len(feather_files)}ê°œ íŒŒì¼ì´ ZIPìœ¼ë¡œ ì••ì¶•ë˜ì–´ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ë¨")
                        st.info("ğŸ›¡ï¸ ëª¨ë“  íŒŒì¼ì˜ ë‚ ì§œ ì»¬ëŸ¼ì´ ì›ë³¸ í˜•íƒœë¡œ ë³´ì¡´ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        
                    except Exception as e:
                        st.error(f"âŒ ZIP ìƒì„± ì‹¤íŒ¨: {e}")
            else:
                st.warning("ğŸ“‚ ì €ì¥ëœ Feather íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ ë¨¼ì € 'Featherë¡œ ì €ì¥í•˜ê¸°' ë˜ëŠ” 'ëª¨ë“  ì‹œíŠ¸ì— ë™ì¼í•œ ì²˜ë¦¬ ì ìš©'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

    else:
        st.info("ğŸ“‚ .xlsx íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# =====================================
# íƒ­ 2: CSV â†’ Feather ë³€í™˜ê¸°
# =====================================
def tab_csv_converter():
    """íƒ­ 2: CSV â†’ Feather ë³€í™˜ê¸°"""
    st.header("ğŸ“Š CSV íŒŒì¼ ë³‘í•© ë° Feather ë³€í™˜ ë„êµ¬")
    st.write("ì—¬ëŸ¬ CSV íŒŒì¼ì„ ì½ì–´ì„œ ì‹œê°„ ì¸ë±ìŠ¤ë¥¼ ì¡°ì •í•˜ê³ , ë…¸ì´ì¦ˆë¥¼ ì œê±°í•œ í›„ Feather íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

    # íŒŒì¼ ì—…ë¡œë“œ UI
    st.subheader("ğŸ“ CSV íŒŒì¼ ì—…ë¡œë“œ")
    st.write("ì²˜ë¦¬í•  CSV íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”. (Ctrl ë˜ëŠ” Shift í‚¤ë¥¼ ì‚¬ìš©í•´ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)")

    uploaded_files = st.file_uploader("CSV íŒŒì¼ ì„ íƒ", type="csv", accept_multiple_files=True, key="csv_uploader")

    if uploaded_files:
        st.success(f"âœ… {len(uploaded_files)}ê°œì˜ CSV íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        with st.expander("ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡", expanded=False):
            for file in uploaded_files:
                st.write(f"- {file.name} ({file.size} bytes)")
        
        # ì„ì‹œ í´ë” ìƒì„±
        folder_path = os.path.join(os.getcwd(), "data", "temp_uploads")

        st.session_state['folder_path'] = folder_path
        st.session_state['uploaded_files_count'] = len(uploaded_files)
        st.session_state['uploaded_files_names'] = [file.name for file in uploaded_files]
        st.session_state['files_uploaded'] = True

        if os.path.exists(folder_path):
            safe_rmtree(folder_path)
        os.makedirs(folder_path, exist_ok=True)
        
        for uploaded_file in uploaded_files:
            with open(os.path.join(folder_path, uploaded_file.name), "wb") as f:
                f.write(uploaded_file.getbuffer())
        
        st.info(f"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì„ì‹œ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {folder_path}")
        
        csv_files = [file.name for file in uploaded_files]
        st.session_state['csv_files'] = csv_files

        if os.path.exists(folder_path):
            actual_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
            st.session_state['actual_csv_files'] = actual_files
            st.write(f"ğŸ“ ì‹¤ì œ ì €ì¥ëœ CSV íŒŒì¼ ìˆ˜: {len(actual_files)}")

        # CSV íŒŒì¼ ë¶„ì„
        st.subheader("ğŸ“Š CSV íŒŒì¼ ë¶„ì„")
        
        selected_file = st.selectbox(
            "í—¤ë”ë¥¼ í™•ì¸í•  íŒŒì¼ ì„ íƒ",
            csv_files,
            help="ì„ íƒí•œ íŒŒì¼ì˜ í—¤ë”ì™€ ë¯¸ë¦¬ë³´ê¸°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤",
            key="csv_analysis_selector"
        )
        
        if selected_file:
            try:
                selected_file_path = os.path.join(folder_path, selected_file)
                df_preview = pd.read_csv(selected_file_path, nrows=100)
                
                st.write(f"**ì„ íƒëœ íŒŒì¼: {selected_file}**")
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.write("**ğŸ“‹ ì»¬ëŸ¼ í—¤ë”:**")
                    headers_df = pd.DataFrame({
                        "ì»¬ëŸ¼ëª…": df_preview.columns,
                        "ë°ì´í„° íƒ€ì…": df_preview.dtypes.astype(str),
                        "ìƒ˜í”Œ ê°’": [str(df_preview[col].iloc[0]) if not df_preview[col].empty else "N/A" 
                                  for col in df_preview.columns]
                    })
                    st.dataframe(headers_df, use_container_width=True)
                
                with col2:
                    st.write("**ğŸ“ˆ íŒŒì¼ ì •ë³´:**")
                    st.write(f"- ì´ ì»¬ëŸ¼ ìˆ˜: {len(df_preview.columns)}")
                    st.write(f"- ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜: {len(df_preview)}")
                    st.write(f"- íŒŒì¼ í¬ê¸°: {os.path.getsize(selected_file_path):,} bytes")
                
                st.write("**ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰):**")
                st.dataframe(df_preview.head(), use_container_width=True)
                
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")

        # ì‹œê°„ ì„¤ì •ë¶€
        df_head = None
        for csv_file in csv_files:
            try:
                file_path = os.path.join(folder_path, csv_file)
                df_head = pd.read_csv(file_path, nrows=100)
                break
            except Exception as e:
                st.warning(f"âš ï¸ íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {csv_file}\n{str(e)}")

        if df_head is not None:
            st.subheader("ì‹œê°„ ì»¬ëŸ¼ ì„¤ì •")
            col1, col2, col3 = st.columns(3)

            with col1:
                year_col = st.selectbox("Year ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), 
                                       index=0 if "year" not in df_head.columns else list(df_head.columns).index("year")+1,
                                       key="year_col_select")
                if year_col is None:
                    year_col = st.text_input("Year ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="year", key="year_col_input")
                month_col = st.selectbox("Month ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), 
                                        index=0 if "month" not in df_head.columns else list(df_head.columns).index("month")+1,
                                        key="month_col_select")
                if month_col is None:
                    month_col = st.text_input("Month ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="month", key="month_col_input")

            with col2:
                day_col = st.selectbox("Day ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), 
                                      index=0 if "day" not in df_head.columns else list(df_head.columns).index("day")+1,
                                      key="day_col_select")
                if day_col is None:
                    day_col = st.text_input("Day ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="day", key="day_col_input")
                hour_col = st.selectbox("Hour ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), 
                                       index=0 if "hour" not in df_head.columns else list(df_head.columns).index("hour")+1,
                                       key="hour_col_select")
                if hour_col is None:
                    hour_col = st.text_input("Hour ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="hour", key="hour_col_input")

            with col3:
                minute_col = st.selectbox("Minute ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), 
                                         index=0 if "minute" not in df_head.columns else list(df_head.columns).index("minute")+1,
                                         key="minute_col_select")
                if minute_col is None:
                    minute_col = st.text_input("Minute ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="minute", key="minute_col_input")
                second_col = st.selectbox("Second ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), 
                                         index=0 if "second" not in df_head.columns else list(df_head.columns).index("second")+1,
                                         key="second_col_select")
                if second_col is None:
                    second_col = st.text_input("Second ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="second", key="second_col_input")
                    
            time_columns = {
                'year': year_col,
                'month': month_col, 
                'day': day_col,
                'hour': hour_col,
                'minute': minute_col,
                'second': second_col
            }
            
            st.session_state['time_columns'] = time_columns
        else:
            st.error("ì½ì„ ìˆ˜ ìˆëŠ” CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

    else:
        st.warning("âš ï¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬ ì˜µì…˜
    with st.expander("ğŸ“ CSV ë°ì´í„° ì²˜ë¦¬ ì˜µì…˜", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            sampling_rate = st.selectbox("ë¦¬ìƒ˜í”Œë§ ì£¼ê¸°:", ["1s", "5s", "10s", "30s", "1min"], index=1)
            sampling_method = st.selectbox("ë¦¬ìƒ˜í”Œë§ ë°©ë²•:", ["median", "mean", "min", "max"], index=0)
        
        with col2:
            remove_spikes = st.checkbox("ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ(999) ì œê±°", value=True)
            timestamp = datetime.now().strftime("%y%m%d%H%M")
            output_filename = st.text_input("ì¶œë ¥ íŒŒì¼ëª…:", f"processed_data_{timestamp}.ftr")

    # íƒ­ ë¶„ë¦¬
    tab1, tab2 = st.tabs(["ğŸ”„ ë°ì´í„° ì²˜ë¦¬", "ğŸ“Š ë°ì´í„° ì‹œê°í™”"])

    # íƒ­ 1: ë°ì´í„° ì²˜ë¦¬
    with tab1:
        if st.session_state.get('processing_complete', False):
            if st.button("ğŸ”„ ë‹¤ì‹œ ì²˜ë¦¬", help="ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë‹¤ì‹œ ì²˜ë¦¬"):
                keys_to_clear = ['processing_complete', 'resampled_df', 'processing_results', 'folder_path']
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
            
            st.markdown("---")
            
            if 'processing_results' in st.session_state:
                results = st.session_state['processing_results']
                
                st.success(f"ğŸ‰ Feather íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.write(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {results['file_path']}")
                st.write(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {results['file_size']:.2f} MB")
                st.write(f"ğŸ“ˆ ë°ì´í„° í–‰ ìˆ˜: {results['resampled_rows']:,} (ì›ë³¸ ëŒ€ë¹„ {results['reduction_ratio']:.1f}%)")
                
                if os.path.exists(results['file_path']):
                    with open(results['file_path'], 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=f,
                            file_name=results['filename'],
                            mime="application/octet-stream",
                            help="ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ Feather í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                            type="primary",
                            key="download_persistent_state"
                        )
                else:
                    st.error("âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                
                with st.expander("ğŸ“‹ ì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5í–‰)", expanded=False):
                    if 'resampled_df' in st.session_state:
                        st.dataframe(st.session_state['resampled_df'].head())
                    else:
                        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                st.info("ğŸ’¡ 'ë°ì´í„° ì‹œê°í™”' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
        else:
            st.info("ğŸ“‚ ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

            with st.expander("ğŸ” í˜„ì¬ ì„¸ì…˜ ìƒíƒœ (ë””ë²„ê¹…)", expanded=False):
                st.write("ì„¸ì…˜ ìƒíƒœ í‚¤ë“¤:", list(st.session_state.keys()))
                
                if 'files_uploaded' in st.session_state:
                    st.write("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œë¨")
                else:
                    st.write("âŒ íŒŒì¼ ì—…ë¡œë“œ ì •ë³´ ì—†ìŒ")
                    
                if 'folder_path' in st.session_state:
                    folder_path = st.session_state['folder_path']
                    st.write("ì €ì¥ëœ í´ë” ê²½ë¡œ:", folder_path)
                    if os.path.exists(folder_path):
                        files = os.listdir(folder_path)
                        csv_files = [f for f in files if f.endswith('.csv')]
                        st.write("í´ë” ë‚´ CSV íŒŒì¼ë“¤:", csv_files)
                        st.write(f"CSV íŒŒì¼ ìˆ˜: {len(csv_files)}")
                    else:
                        st.write("âŒ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                else:
                    st.write("âŒ folder_pathê°€ ì„¸ì…˜ì— ì—†ìŒ")
                    if 'files_uploaded' in st.session_state:
                        folder_path = os.path.join(os.getcwd(), "data", "temp_uploads")
                        if os.path.exists(folder_path):
                            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
                            if csv_files:
                                st.session_state['folder_path'] = folder_path
                                st.session_state['csv_files'] = csv_files
                                st.write("âœ… folder_path ë³µêµ¬ ì™„ë£Œ!")
                                st.rerun()

            can_process = False
            folder_path = None
            csv_files = []
            time_columns = {}
            
            if ('folder_path' in st.session_state and 
                'time_columns' in st.session_state and 
                os.path.exists(st.session_state['folder_path'])):
                
                folder_path = st.session_state['folder_path']
                time_columns = st.session_state['time_columns']
                csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
                if csv_files:
                    can_process = True
            
            elif not can_process:
                default_folder = os.path.join(os.getcwd(), "data", "temp_uploads")
                if os.path.exists(default_folder):
                    csv_files = [f for f in os.listdir(default_folder) if f.endswith('.csv')]
                    if csv_files:
                        folder_path = default_folder
                        st.session_state['folder_path'] = folder_path
                        st.session_state['csv_files'] = csv_files
                        
                        if 'time_columns' not in st.session_state:
                            time_columns = {
                                'year': 'year',
                                'month': 'month', 
                                'day': 'day',
                                'hour': 'hour',
                                'minute': 'minute',
                                'second': 'second'
                            }
                            st.session_state['time_columns'] = time_columns
                        else:
                            time_columns = st.session_state['time_columns']
                        
                        can_process = True
            
            if can_process:
                st.success(f"âœ… ì²˜ë¦¬ ê°€ëŠ¥: {len(csv_files)}ê°œ CSV íŒŒì¼ ë°œê²¬")
            else:
                st.error("âŒ ì²˜ë¦¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

            if st.button("ğŸ”„ ì²˜ë¦¬ ì‹œì‘", type="primary", disabled=not can_process):
                try:
                    if not os.path.exists(folder_path):
                        st.error(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
                        st.stop()
                    
                    if not csv_files:
                        st.error("âŒ ì§€ì •ëœ í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    st.info(f"ğŸ“‚ ì´ {len(csv_files)} ê°œì˜ CSV íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    all_data = []

                    for i, file in enumerate(csv_files):
                        status_text.text(f"ì²˜ë¦¬ ì¤‘: {file} ({i+1}/{len(csv_files)})")
                        progress_bar.progress((i + 1) / len(csv_files))
                        
                        try:
                            df = pd.read_csv(os.path.join(folder_path, file), low_memory=False)
                            
                            valid_time_columns = {k: v for k, v in time_columns.items() if v is not None}
                            
                            if valid_time_columns:
                                missing_columns = []
                                for key, col_name in valid_time_columns.items():
                                    if col_name not in df.columns:
                                        missing_columns.append(col_name)

                                if missing_columns:
                                    st.warning(f"íŒŒì¼ {file}ì—ì„œ ë‹¤ìŒ ì‹œê°„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
                                    continue
                                else:
                                    if 'year' in valid_time_columns:
                                        if df[valid_time_columns['year']].max() < 100:
                                            df[valid_time_columns['year']] = df[valid_time_columns['year']] + 2000
                                    
                                    time_col_list = [valid_time_columns[col] for col in ['year', 'month', 'day', 'hour', 'minute', 'second'] 
                                                    if col in valid_time_columns]
                                    
                                    df['timestamp'] = pd.to_datetime(df[time_col_list])
                                    df = df.set_index('timestamp')
                                    df.drop(columns=list(valid_time_columns.values()), inplace=True)

                            all_data.append(df)
                            
                        except Exception as e:
                            st.warning(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file}\n{str(e)}")    
                    
                    if not all_data:
                        st.error("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    status_text.text("íŒŒì¼ ë³‘í•© ì¤‘...")
                    
                    merged_df = pd.concat(all_data)
                    
                    status_text.text("ë°ì´í„° ì •ë ¬ ë° ì¤‘ë³µ ì œê±° ì¤‘...")
                    merged_df = merged_df.sort_index()
                    merged_df = merged_df[~merged_df.index.duplicated(keep='first')]
                    
                    if remove_spikes:
                        status_text.text("ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ(999) ì œê±° ì¤‘...")
                        merged_df = replace_999_with_neighbors_mean(merged_df)
                    
                    status_text.text(f"{sampling_rate} ì£¼ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§ ì¤‘...")
                    if sampling_method == "median":
                        resampled_df = merged_df.resample(sampling_rate).median()
                    elif sampling_method == "mean":
                        resampled_df = merged_df.resample(sampling_rate).mean()
                    elif sampling_method == "min":
                        resampled_df = merged_df.resample(sampling_rate).min()
                    else:
                        resampled_df = merged_df.resample(sampling_rate).max()
                    
                    status_text.text("Feather íŒŒì¼ ì €ì¥ ì¤‘...")
                    
                    save_dir = os.path.dirname(os.path.join(folder_path, output_filename))
                    if not os.path.exists(save_dir):
                        os.makedirs(save_dir, exist_ok=True)
                    
                    resampled_df_save = resampled_df.reset_index()
                    save_path = os.path.join(folder_path, output_filename)
                    resampled_df_save.to_feather(save_path)
                    
                    file_size = os.path.getsize(save_path) / (1024 * 1024)
                    
                    st.session_state['resampled_df'] = resampled_df
                    st.session_state['processing_complete'] = True
                    st.session_state['processing_results'] = {
                        'merged_rows': len(merged_df),
                        'merged_cols': len(merged_df.columns),
                        'time_range': f"{merged_df.index.min()} ~ {merged_df.index.max()}",
                        'resampled_rows': len(resampled_df),
                        'reduction_ratio': len(resampled_df)/len(merged_df)*100,
                        'file_path': save_path,
                        'filename': output_filename,
                        'file_size': file_size
                    }
                    
                    status_text.text("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                    st.success(f"ğŸ‰ Feather íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.write(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {save_path}")
                    st.write(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
                    st.write(f"ğŸ“ˆ ë°ì´í„° í–‰ ìˆ˜: {len(resampled_df):,} (ì›ë³¸ ëŒ€ë¹„ {len(resampled_df)/len(merged_df)*100:.1f}%)")
                    
                    if os.path.exists(save_path):
                        with open(save_path, 'rb') as f:
                            st.download_button(
                                label="ğŸ“¥ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=f,
                                file_name=output_filename,
                                mime="application/octet-stream",
                                help="ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ Feather í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                                type="primary",
                                key="download_after_processing"
                            )
                    
                    with st.expander("ğŸ“‹ ì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5í–‰)", expanded=False):
                        st.dataframe(resampled_df.head())
                    
                    st.info("ğŸ’¡ 'ë°ì´í„° ì‹œê°í™”' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                    
                except Exception as e:
                    st.error(f"âŒ ì „ì²´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    keys_to_clear = ['processing_complete', 'resampled_df', 'processing_results']
                    for key in keys_to_clear:
                        if key in st.session_state:
                            del st.session_state[key]

    # íƒ­ 2: ë°ì´í„° ì‹œê°í™”
    with tab2:
        if 'resampled_df' in st.session_state and st.session_state['resampled_df'] is not None:
            st.subheader("ğŸ“Š ì²˜ë¦¬ëœ ë°ì´í„° ì‹œê°í™”")
            
            df = st.session_state['resampled_df']
            
            # ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„° ë™ì‹œ ê´€ì°°
            st.title("ğŸš€ ì‹ í˜¸ ê´€ì°° ë° ìƒí˜¸ ê´€ê³„ ë³´ê¸°")
            
            st.success(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ! Shape: {df.shape}")

            selected_cols = st.multiselect("Plotí•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”", df.columns.tolist(), key="csv_viz_columns")

            if selected_cols:
                st.subheader("ğŸ“‰ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ ì„¤ì • (1/N)")
                downsample_rate = st.slider("ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨", min_value=1, max_value=100, value=10, key="csv_downsample")

                crosshair = st.checkbox("â–¶ï¸ ì‹­ìì„  Hover í™œì„±í™”", value=True, key="csv_crosshair")

                fig = go.Figure()

                for col in selected_cols:
                    y = df[col].iloc[::downsample_rate]
                    x = df.index[::downsample_rate]
                    fig.add_trace(go.Scattergl(
                        x=x,
                        y=y,
                        mode='lines',
                        name=col,
                        showlegend=True,
                        hoverinfo='x',
                        hovertemplate=''
                    ))

                fig.update_layout(
                    title="ğŸ“Š Plotly ê·¸ë˜í”„ (ë‹¤ìš´ìƒ˜í”Œë§ ì ìš©)",
                    dragmode="zoom",
                    xaxis=dict(
                        rangeslider=dict(visible=False)
                    ),
                    height=600
                )

                if crosshair:
                    fig.update_layout(
                        hovermode="x",
                        xaxis=dict(
                            showspikes=True,
                            spikemode='across',
                            spikesnap='cursor',
                            spikecolor="red",
                            spikethickness=1
                        ),
                        yaxis=dict(
                            showspikes=True,
                            spikemode='across',
                            spikesnap='cursor',
                            spikecolor="blue",
                            spikethickness=1
                        )
                    )

                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ì‹œê°í™”í•  ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            st.info("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë°ì´í„° ì²˜ë¦¬' íƒ­ì—ì„œ CSV íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")

# =====================================
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# =====================================
def main():
    st.title("ğŸš€ ë°ì´í„° ë³€í™˜ í†µí•© ë„êµ¬")
    
    # ì‚¬ì´ë“œë°” ë Œë”ë§
    render_sidebar()
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Excel â†’ Feather ë³€í™˜ê¸°", "ğŸ“ˆ CSV â†’ Feather ë³€í™˜ê¸°", "ğŸ“‹ ì‚¬ìš©ë²• ì•ˆë‚´"])
    
    with tab1:
        tab_excel_converter()
    
    with tab2:
        tab_csv_converter()
    
    with tab3:
        render_usage_guide()

def render_usage_guide():
    """ì‚¬ìš©ë²• ì•ˆë‚´ íƒ­"""
    st.header("ğŸ“‹ í”„ë¡œê·¸ë¨ ê¸°ëŠ¥ ì•ˆë‚´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ” ì£¼ìš” ê¸°ëŠ¥")
        st.markdown("""
        **Tab 1: Excel â†’ Feather ë³€í™˜ê¸°**
        - ëŒ€ìš©ëŸ‰ Excel íŒŒì¼ ì²˜ë¦¬ ë° Feather ë³€í™˜
        - ë‚ ì§œ ì»¬ëŸ¼ ìë™ ì‹ë³„ ë° ë³´í˜¸
        - ë¬¸ì-ìˆ«ì ìë™ ë§¤í•‘ ë³€í™˜
        - ëª¨ë“  ì‹œíŠ¸ ì¼ê´„ ì²˜ë¦¬ ê¸°ëŠ¥
        - ZIP ì••ì¶• ë‹¤ìš´ë¡œë“œ ì§€ì›
        
        **Tab 2: CSV â†’ Feather ë³€í™˜ê¸°**  
        - ë‹¤ì¤‘ CSV íŒŒì¼ ë³‘í•© ì²˜ë¦¬
        - ì‹œê°„ ì¸ë±ìŠ¤ ìë™ ì¡°ì •
        - ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ(999) ì œê±°
        - ë¦¬ìƒ˜í”Œë§ ë° ë°ì´í„° ì •ì œ
        - ì‹¤ì‹œê°„ ë°ì´í„° ì‹œê°í™”
        """)
    
    with col2:
        st.subheader("âš™ï¸ ê³ ê¸‰ ê¸°ëŠ¥")
        st.markdown("""
        **ë°ì´í„° ì „ì²˜ë¦¬**
        - NaN/Inf ê°’ ìë™ ì²˜ë¦¬ ë° ë³´ê°„
        - ë¬¸ìê°’ ë¹ˆë„ ë¶„ì„ ë° ë§¤í•‘
        - ë‚ ì§œ ì»¬ëŸ¼ ìë™ ë³´í˜¸ ë©”ì»¤ë‹ˆì¦˜
        - ì»¬ëŸ¼ ì„ íƒì  ì œê±° ê¸°ëŠ¥
        
        **ì‹œê°í™” ë„êµ¬**
        - Plotly ê¸°ë°˜ ê³ ì„±ëŠ¥ WebGL ë Œë”ë§
        - ë‹¤ìš´ìƒ˜í”Œë§ì„ í†µí•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
        - ì‹­ìì„  Hover ë° ì¸í„°ë™í‹°ë¸Œ ì¤Œ/íŒ¬
        - ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë™ì‹œ ê´€ì°°
        - ì‹œê°„ì¶• ê¸°ë°˜ ì‹œê°í™” ì§€ì›
        """)
    
    st.markdown("---")
    st.subheader("ğŸ“ ì‚¬ìš© ìˆœì„œ")
    
    st.markdown("""
    **Excel â†’ Feather ë³€í™˜ ì‹œ:**
    1. Excel íŒŒì¼ ì—…ë¡œë“œ ë° ì½ê¸° ì„¤ì •
    2. ì‹œíŠ¸ ì„ íƒ (ìë™ ê°ì§€)
    3. ë¬¸ì-ìˆ«ì ë§¤í•‘ ì„¤ì • (í•„ìš”ì‹œ)
    4. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° (ì„ íƒì‚¬í•­)
    5. Feather íŒŒì¼ë¡œ ì €ì¥ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
    6. ëª¨ë“  ì‹œíŠ¸ ì¼ê´„ ì²˜ë¦¬ (ë‹¤ì¤‘ ì‹œíŠ¸ì¸ ê²½ìš°)
    
    **CSV â†’ Feather ë³€í™˜ ì‹œ:**
    1. ë‹¤ì¤‘ CSV íŒŒì¼ ì—…ë¡œë“œ
    2. ì‹œê°„ ì»¬ëŸ¼ ì„¤ì • (year, month, day ë“±)
    3. ë¦¬ìƒ˜í”Œë§ ì˜µì…˜ ì„¤ì •
    4. ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰
    5. ì‹œê°í™” íƒ­ì—ì„œ ê²°ê³¼ í™•ì¸
    6. Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    """)
    
    st.markdown("---")
    st.info("ğŸ’¡ **ì‚¬ìš© íŒ**: ê° íƒ­ì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ë¯€ë¡œ, í•„ìš”ì— ë”°ë¼ ì›í•˜ëŠ” ë³€í™˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë‹¤ìš´ìƒ˜í”Œë§ì„ ì ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    st.markdown("""
    <div style='text-align: center; color: #666; margin-top: 2rem;'>
        <small>ì´ ë„êµ¬ëŠ” ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ì¸ Feather í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.</small>
    </div>
    """, unsafe_allow_html=True)

# =====================================
# ì•± ì‹¤í–‰
# =====================================
if __name__ == "__main__":
    main()