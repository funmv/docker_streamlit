import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.graph_objects as go
from datetime import datetime
import time
import stat
import shutil
import gc 
import matplotlib.pyplot as plt 
import glob
# import pdb
# import io  # âœ… io ëª¨ë“ˆ ëª…ì‹œì  import í™•ì¸
# import zipfile


# í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    from matplotlib import font_manager, rc
    # Windows í™˜ê²½
    font_name = font_manager.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
    rc('font', family=font_name)
    plt.rcParams['axes.unicode_minus'] = False
except:
    try:
        # Linux í™˜ê²½
        from matplotlib import font_manager, rc
        font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
        font_name = font_manager.FontProperties(fname=font_path).get_name()
        rc('font', family=font_name)  
        plt.rcParams['axes.unicode_minus'] = False
    except:
        # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        plt.rcParams['axes.unicode_minus'] = False

# matplotlib ê²½ê³  ì œê±°ë¥¼ ìœ„í•œ ì„¤ì •
plt.rcParams['figure.max_open_warning'] = 50



# âœ… WebSocket ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ì„¤ì •
st.set_page_config(
    page_title="Excel â†’ Feather ë³€í™˜ê¸°", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# âœ… FutureWarning í•´ê²°ì„ ìœ„í•œ ì„¤ì • (ë” ì•ˆì „í•œ ë°©ë²•ìœ¼ë¡œ ìˆ˜ì •)
try:
    pd.set_option('future.no_silent_downcasting', True)
except Exception:
    # êµ¬ë²„ì „ pandasì—ì„œëŠ” ì´ ì˜µì…˜ì´ ì—†ì„ ìˆ˜ ìˆìŒ
    pass

# UI ì…ë ¥
st.title("ğŸ“Š ëŒ€ìš©ëŸ‰ Excel â†’ Feather ë³€í™˜ê¸°")
uploaded_file = st.file_uploader("ğŸ“‚ Excel íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=["xlsx", "xls"])

st.sidebar.header("ğŸ”§ Excel ì½ê¸° ì„¤ì •")

# âœ… 1. ì‹œíŠ¸ ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€ (1ê°œ ì‹œíŠ¸ ì˜¤ë¥˜ í•´ê²°)
sheet_name = None
available_sheets = []

if uploaded_file is not None:
    try:
        # Excel íŒŒì¼ì˜ ì‹œíŠ¸ëª… ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        excel_file = pd.ExcelFile(uploaded_file)
        available_sheets = excel_file.sheet_names
        
        if len(available_sheets) == 1:
            # âœ… 2. ì‹œíŠ¸ê°€ 1ê°œì¸ ê²½ìš° ìë™ìœ¼ë¡œ ì„ íƒ (ì˜¤ë¥˜ ë°©ì§€)
            sheet_name = available_sheets[0]
            st.sidebar.success(f"ğŸ“‹ ì‹œíŠ¸ ìë™ ì„ íƒ: {sheet_name}")
        elif len(available_sheets) > 1:
            # ì‹œíŠ¸ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš° ì„ íƒ ì˜µì…˜ ì œê³µ
            st.sidebar.subheader("ğŸ“‹ ì‹œíŠ¸ ì„ íƒ")
            sheet_name = st.sidebar.selectbox(
                "ì½ì„ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                options=available_sheets,
                index=0
            )
            st.sidebar.info(f"ì´ {len(available_sheets)}ê°œ ì‹œíŠ¸ ì¤‘ '{sheet_name}' ì„ íƒë¨")
        else:
            st.sidebar.error("âŒ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.sidebar.error(f"âŒ ì‹œíŠ¸ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.sidebar.info("ğŸ’¡ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

usecols = st.sidebar.text_input("ì½ì„ ì»¬ëŸ¼ ë²”ìœ„ (usecols)", value="A:CY")
date_column = st.sidebar.text_input(
    "ë‚ ì§œ ì»¬ëŸ¼ëª…", 
    value="Description",
    help="Excel íŒŒì¼ì—ì„œ ë‚ ì§œë¡œ ë³€í™˜í•  ì»¬ëŸ¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì´ ì»¬ëŸ¼ì€ ë¬¸ì-ìˆ«ì ë³€í™˜ì—ì„œ ìë™ ì œì™¸ë©ë‹ˆë‹¤)"
)
skiprows = st.sidebar.number_input(
    "ê±´ë„ˆë›¸ í–‰ ìˆ˜ (skiprows)", 
    min_value=0, 
    value=3,
    help="Excel íŒŒì¼ ìƒë‹¨ì—ì„œ í—¤ë”ì™€ ë°ì´í„°ë¥¼ ì½ê¸° ì „ì— ê±´ë„ˆë›¸ í–‰ ìˆ˜ (ë©”íƒ€ ì •ë³´ ë“±)"
)
skip_next = st.sidebar.number_input(
    "í—¤ë“œí–‰ ë‹¤ìŒ ê±´ë„ˆë›¸ ìˆ˜ (skip_next)", 
    min_value=0, 
    value=2,
    help="Excel íŒŒì¼ ìƒë‹¨ì—ì„œ í—¤ë”ì™€ ë°ì´í„°ë¥¼ ì½ê¸° ì „ì— ê±´ë„ˆë›¸ í–‰ ìˆ˜ (ë©”íƒ€ ì •ë³´ ë“±)"
)
nrows = st.sidebar.number_input(
    "ì½ì„ í–‰ ìˆ˜ (nrows)", 
    min_value=1000, 
    max_value=10**7, 
    step=10000, 
    value=3000, #518400,
    help="í° ê°’ì„ ì…ë ¥í•˜ë©´ ì‹œíŠ¸ì˜ ë§ˆì§€ë§‰ í–‰ê¹Œì§€ ìë™ìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤"
)

# âœ… ë‚ ì§œ ì»¬ëŸ¼ì„ ë” íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€
def identify_date_columns(df, date_column_name):
    """ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ ì‹ë³„í•˜ëŠ” í•¨ìˆ˜ - ëª…ì‹œì  ì§€ì •ê³¼ ìë™ ê°ì§€"""
    date_columns = set()
    
    # 1. ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œ ë‚ ì§œ ì»¬ëŸ¼
    if date_column_name and date_column_name in df.columns:
        date_columns.add(date_column_name)
    
    # 2. ìë™ ê°ì§€: ì»¬ëŸ¼ëª…ì— ë‚ ì§œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°
    date_keywords = ['date', 'time', 'datetime', 'timestamp', 'ë‚ ì§œ', 'ì‹œê°„', 'ì¼ì‹œ']
    for col in df.columns:
        col_lower = str(col).lower()
        if any(keyword in col_lower for keyword in date_keywords):
            date_columns.add(col)
    
    # 3. ìë™ ê°ì§€: ë°ì´í„° íƒ€ì…ì´ datetimeì¸ ê²½ìš°
    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            date_columns.add(col)
    
    return list(date_columns)

# âœ… 2. ë¬¸ì-ìˆ«ì ë³€í™˜ ì„¤ì •ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'text_mapping' not in st.session_state:
    st.session_state.text_mapping = {}
if 'text_frequency' not in st.session_state:
    st.session_state.text_frequency = {}
if 'text_columns' not in st.session_state:
    st.session_state.text_columns = {}
if 'date_columns' not in st.session_state:
    st.session_state.date_columns = []

# âœ… 3. ë¬¸ìê°’ ì¶”ì¶œ ë° ë§¤í•‘ í•¨ìˆ˜ (ë‚ ì§œ ì»¬ëŸ¼ ì™„ì „ ì œì™¸)
def extract_unique_text_values(df, date_columns):
    """DataFrameì—ì„œ ëª¨ë“  ë¬¸ìê°’ë“¤ê³¼ ë¹ˆë„ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ - ë‚ ì§œ ì»¬ëŸ¼ ì œì™¸"""
    text_frequency = {}
    text_columns_dict = {}  # ê° ë¬¸ìê°’ì´ ì–´ëŠ ì»¬ëŸ¼ì—ì„œ ë‚˜íƒ€ë‚¬ëŠ”ì§€ ì¶”ì 
    
    # ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ ì œì™¸í•œ ì»¬ëŸ¼ë“¤ë§Œ ì²˜ë¦¬
    columns_to_process = [col for col in df.columns if col not in date_columns]
    
    st.info(f"ğŸ—“ï¸ ë‚ ì§œ ì»¬ëŸ¼ìœ¼ë¡œ ì‹ë³„ë˜ì–´ ë¬¸ì ë³€í™˜ì—ì„œ ì œì™¸ëœ ì»¬ëŸ¼: {date_columns}")
    st.info(f"ğŸ”¤ ë¬¸ì-ìˆ«ì ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼ ìˆ˜: {len(columns_to_process)}/{len(df.columns)}")
    
    for column in columns_to_process:
        # ê° ì»¬ëŸ¼ì—ì„œ ë¬¸ìì—´ ê°’ë“¤ ì°¾ê¸°
        text_values = df[column].dropna().astype(str)
        
        # ìˆ«ìê°€ ì•„ë‹Œ ê°’ë“¤ë§Œ ì¶”ì¶œ
        for value in text_values:
            # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
            try:
                float(value)
            except (ValueError, TypeError):
                # ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
                if value not in ['nan', 'None', '']:
                    # ë¹ˆë„ ì¹´ìš´íŠ¸
                    if value not in text_frequency:
                        text_frequency[value] = 0
                        text_columns_dict[value] = set()
                    
                    # í•´ë‹¹ ê°’ì˜ ë¹ˆë„ì™€ ì»¬ëŸ¼ ì •ë³´ ì—…ë°ì´íŠ¸
                    value_count = (text_values == value).sum()
                    text_frequency[value] += value_count
                    text_columns_dict[value].add(column)
    
    return text_frequency, text_columns_dict

# âœ… ë‚ ì§œ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ ì¶”ê°€ (í•œê¸€ ì œê±°)
def extract_date_info_from_data(df, date_column):
    """ë°ì´í„°ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ íŒŒì¼ëª…ìš© ë¬¸ìì—´ ìƒì„± (í•œê¸€ ì œê±°)"""
    try:
        if date_column in df.columns:
            date_series = pd.to_datetime(df[date_column], errors='coerce')
            date_series = date_series.dropna()
            
            if len(date_series) > 0:
                start_date = date_series.min()
                end_date = date_series.max()
                
                # âœ… 1. í•œê¸€ ì œê±°: 24ì‹œê°„ í˜•ì‹ ì‚¬ìš©, ì˜ë¬¸ ë¡œì¼€ì¼ ì„¤ì •
                # ë‚ ì§œ í˜•ì‹: YYYYMMDD_HHMMSS (ì‹œê°„ ì •ë³´ë„ í¬í•¨)
                try:
                    # ì‹œê°„ ì •ë³´ í¬í•¨í•œ ìƒì„¸ í˜•ì‹
                    start_str = start_date.strftime("%Y%m%d_%H%M")
                    end_str = end_date.strftime("%Y%m%d_%H%M")
                    
                    if start_str == end_str:
                        # ê°™ì€ ë‚ ì§œ/ì‹œê°„ì¸ ê²½ìš°
                        return f"_{start_str}"
                    else:
                        # ë‚ ì§œ/ì‹œê°„ ë²”ìœ„ì¸ ê²½ìš° (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ì‹œì‘-ë ë‚ ì§œë§Œ)
                        start_date_only = start_date.strftime("%Y%m%d")
                        end_date_only = end_date.strftime("%Y%m%d")
                        
                        if start_date_only == end_date_only:
                            # ê°™ì€ ë‚ ì´ì§€ë§Œ ì‹œê°„ì´ ë‹¤ë¥¸ ê²½ìš°
                            return f"_{start_date_only}"
                        else:
                            # ë‹¤ë¥¸ ë‚ ì§œ ë²”ìœ„
                            return f"_{start_date_only}_{end_date_only}"
                            
                except Exception:
                    # strftime ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ í˜•ì‹ ì‚¬ìš©
                    start_str = start_date.strftime("%Y%m%d")
                    end_str = end_date.strftime("%Y%m%d")
                    
                    if start_str == end_str:
                        return f"_{start_str}"
                    else:
                        return f"_{start_str}_{end_str}"
        
        return ""  # ë‚ ì§œ ì •ë³´ ì—†ìŒ
    except Exception:
        return ""  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜

# âœ… 4. ë¬¸ì-ìˆ«ì ë³€í™˜ ì ìš© í•¨ìˆ˜ (ë‚ ì§œ ì»¬ëŸ¼ ì™„ì „ ë³´í˜¸)
def apply_text_mapping(df, mapping_dict, date_columns):
    """DataFrameì— ë¬¸ì-ìˆ«ì ë§¤í•‘ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜ - ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸"""
    df_converted = df.copy()
    
    # ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ ì œì™¸í•œ ì»¬ëŸ¼ë“¤ë§Œ ì²˜ë¦¬
    columns_to_process = [col for col in df_converted.columns if col not in date_columns]
    
    for column in columns_to_process:
        # ê° ì…€ì„ í™•ì¸í•˜ì—¬ ë§¤í•‘ ì ìš©
        for text, number in mapping_dict.items():
            # âœ… FutureWarning í•´ê²°: ë” ì•ˆì „í•œ ë°©ë²•ìœ¼ë¡œ ìˆ˜ì •
            try:
                # ìµœì‹  pandas ë°©ì‹
                df_converted[column] = df_converted[column].replace(text, number).infer_objects(copy=False)
            except (AttributeError, TypeError):
                # êµ¬ë²„ì „ pandas ë˜ëŠ” í˜¸í™˜ì„± ë¬¸ì œ ì‹œ ê¸°ë³¸ ë°©ì‹ ì‚¬ìš©
                df_converted[column] = df_converted[column].replace(text, number)
        
        # ìµœì¢…ì ìœ¼ë¡œ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
        try:
            df_converted[column] = pd.to_numeric(df_converted[column], errors='coerce')
        except:
            pass
    
    # ë‚ ì§œ ì»¬ëŸ¼ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜, datetime íƒ€ì…ìœ¼ë¡œ í™•ì‹¤íˆ ë³€í™˜
    for date_col in date_columns:
        if date_col in df_converted.columns:
            try:
                df_converted[date_col] = pd.to_datetime(df_converted[date_col], errors='coerce')
            except:
                pass  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
    
    return df_converted

# ìºì‹œëœ Excel ë¡œë”: # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²½ìš°ì˜ í•¨ìˆ˜
@st.cache_data(show_spinner=False, max_entries=3, ttl=300)  # âœ… show_spinner=Falseë¡œ ë³€ê²½
def load_excel(file, sheet_name, usecols, nrows, date_column, skiprows, skip_next=0):
    """Excel íŒŒì¼ì„ ì½ëŠ” í•¨ìˆ˜ - ë‹¨ì¼ ì‹œíŠ¸ ì²˜ë¦¬ ê°œì„ """
    
    # âœ… íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
    if file is None:
        raise ValueError("íŒŒì¼ì´ Noneì…ë‹ˆë‹¤.")
    
    if sheet_name is None or sheet_name == "":
        raise ValueError("ì‹œíŠ¸ëª…ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


    def count_rows():    
        if ':' in usecols:
            first_col = usecols.split(':')[0]  # 'A'
        else:
            first_col = usecols  # ì´ë¯¸ ë‹¨ì¼ ì»¬ëŸ¼ì¸ ê²½ìš°

        range_col = f"{first_col}:{first_col}"
        temp_df = pd.read_excel(
            file,
            sheet_name=sheet_name,
            skiprows=skiprows + 1 + skip_next,
            header=None,
            usecols=range_col,  
            engine='openpyxl',
        )
        mask = temp_df.iloc[:, 0].notna() & (temp_df.iloc[:, 0].astype(str).str.strip() != '')
        temp_count = mask.sum()
        print(f"ë°ì´í„° {sheet_name} í–‰ ê°œìˆ˜: {temp_count}")   
        final_nrows = temp_count - 10 if temp_count > 10 else temp_count
        return final_nrows

    
    try:
        if skip_next > 0:
            # í—¤ë”ë§Œ ë¨¼ì € ì½ê¸°
            header_df = pd.read_excel(
                file,
                sheet_name=sheet_name,
                skiprows=skiprows,
                nrows=1,
                usecols=usecols,
                engine='openpyxl'
            )   
            
            # í—¤ë” ì»¬ëŸ¼ëª… ì¶”ì¶œ
            column_names = header_df.columns.tolist()
            
            # âœ… ì‹¤ì œ ë°ì´í„° í–‰ ìˆ˜ í™•ì¸ (ê°„ì†Œí™”)
            try:
                final_nrows = count_rows()
                # final_nrows = nrows
            except Exception:
                final_nrows = nrows
            
            # ì‹¤ì œ ë°ì´í„° ì½ê¸°
            data_df = pd.read_excel(
                file,
                sheet_name=sheet_name,
                skiprows=skiprows + 1 + skip_next,
                header=None,
                usecols=usecols,
                nrows=final_nrows,
                engine='openpyxl',
                na_values=['I/O Timeout', 'Configure', 'Not Connect', 'Bad', 'Comm Fail']
            )
            
            # ì¶”ì¶œí•œ í—¤ë”ëª… ì ìš©
            data_df.columns = column_names
            
        else:
            # âœ… skip_nextê°€ 0ì¸ ê²½ìš° ë‹¨ìˆœí™”ëœ ì²˜ë¦¬
            try:
                final_nrows = count_rows()
            except Exception:
                final_nrows = nrows

            data_df = pd.read_excel(
                file,
                sheet_name=sheet_name,
                usecols=usecols,
                nrows=final_nrows, # nrows,
                skiprows=skiprows,
                header=0,
                engine='openpyxl',
                na_values=['I/O Timeout', 'Configure', 'Not Connect', 'Bad', 'Comm Fail']
            )
        
        # âœ… ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        if date_column and date_column in data_df.columns:
            try:
                data_df[date_column] = pd.to_datetime(data_df[date_column], errors='coerce')
            except Exception:
                pass  # ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
        return data_df
        
    except Exception as e:
        # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        raise RuntimeError(f"Excel ì½ê¸° ì‹¤íŒ¨: {str(e)}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'file_loaded' not in st.session_state:
    st.session_state.file_loaded = False
if 'df' not in st.session_state:
    st.session_state.df = None
if 'raw_df' not in st.session_state:
    st.session_state.raw_df = None

# Excel ë¡œë”© ë¶€ë¶„ - ë””ë²„ê¹…ê³¼ íƒ€ì„ì•„ì›ƒ ì¶”ê°€
if uploaded_file is not None and sheet_name is not None and st.button("Excel ì½ê¸°"):
    # âœ… ì—°ê²° ìƒíƒœ í™•ì¸ ë° ì§„í–‰ ìƒí™© ê´€ë¦¬
    progress_container = st.container()
    status_container = st.container()
    
    try:
        with progress_container:
            # âœ… ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ (WebSocket ë¶€í•˜ ìµœì†Œí™”)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("ğŸš€ Excel íŒŒì¼ ì½ê¸° ì‹œì‘...")
            progress_bar.progress(10)
            time.sleep(0.1)  # UI ì—…ë°ì´íŠ¸ ì‹œê°„ í™•ë³´
            
            status_text.text(f"ğŸ“– ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘...")
            progress_bar.progress(30)
            
            # ì‹¤ì œ íŒŒì¼ ì½ê¸°
            df = load_excel(
                file=uploaded_file,
                sheet_name=sheet_name,
                usecols=usecols,
                nrows=nrows,
                date_column=date_column,
                skiprows=skiprows,   
                skip_next=skip_next   
            )
            
            progress_bar.progress(50)
            status_text.text("ğŸ—“ï¸ ë‚ ì§œ ì»¬ëŸ¼ ì‹ë³„ ì¤‘...")
            
            # âœ… ë‚ ì§œ ì»¬ëŸ¼ë“¤ ì‹ë³„
            date_columns = identify_date_columns(df, date_column)
            st.session_state.date_columns = date_columns
            
            progress_bar.progress(60)
            status_text.text("ğŸ” ë°ì´í„° ë¶„ì„ ì¤‘...")
            
            # ì²˜ë¦¬ ì™„ë£Œ í™•ì¸
            if df is not None and len(df) > 0:
                # âœ… ì›ë³¸ ë°ì´í„° ì €ì¥
                st.session_state.raw_df = df.copy()
                
                progress_bar.progress(80)
                status_text.text("ğŸ”¤ ë¬¸ìê°’ ì¶”ì¶œ ì¤‘...")
                
                # âœ… ë¬¸ìê°’ë“¤ê³¼ ë¹ˆë„ ì¶”ì¶œ (ë‚ ì§œ ì»¬ëŸ¼ ì œì™¸)
                text_frequency, text_columns_dict = extract_unique_text_values(df, date_columns)
                st.session_state.text_frequency = text_frequency
                st.session_state.text_columns = text_columns_dict
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.df = df
                st.session_state.file_loaded = True
                
                progress_bar.progress(90)
                status_text.text("ğŸ“ íŒŒì¼ëª… ìƒì„± ì¤‘...")
                
                # íŒŒì¼ ì—…ë¡œë“œ ì‹œ íŒŒì¼ëª… ì €ì¥
                base_filename = os.path.splitext(uploaded_file.name)[0]
                
                # âœ… 1. ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë° íŒŒì¼ëª… ìƒì„±
                date_info = extract_date_info_from_data(df, date_column)
                sheet_info = f"_{sheet_name}" if sheet_name != "Sheet1" else ""
                
                # ìµœì¢… íŒŒì¼ëª…: ì›ë³¸íŒŒì¼ëª…_ì‹œíŠ¸ëª…_ë‚ ì§œì •ë³´
                enhanced_filename = f"{base_filename}{sheet_info}{date_info}"
                st.session_state.last_filename = enhanced_filename
                
                progress_bar.progress(100)
                status_text.text("âœ… ì™„ë£Œ!")
                
                # âœ… ì™„ë£Œ í›„ ì§„í–‰ë¥  ì œê±°í•˜ê³  ê²°ê³¼ í‘œì‹œ (WebSocket ë¶€í•˜ ê°ì†Œ)
                time.sleep(0.5)
                progress_container.empty()
                
        with status_container:
            st.success(f"ğŸ‰ Excel íŒŒì¼ ì½ê¸° ì™„ë£Œ!")
            st.info(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df):,}í–‰ Ã— {len(df.columns)}ì—´")
            
            # âœ… ë‚ ì§œ ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ
            if date_columns:
                st.success(f"ğŸ—“ï¸ ì‹ë³„ëœ ë‚ ì§œ ì»¬ëŸ¼: {date_columns}")
                st.info("ğŸ“Œ ì´ ì»¬ëŸ¼ë“¤ì€ ë¬¸ì-ìˆ«ì ë³€í™˜ì—ì„œ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.")
            
            # âœ… ë°œê²¬ëœ ë¬¸ìê°’ë“¤ê³¼ ë¹ˆë„ í‘œì‹œ
            if text_frequency:
                st.warning(f"ğŸ”¤ ë°œê²¬ëœ ë¬¸ìê°’ë“¤: {list(text_frequency.keys())}")
                st.info("ğŸ‘‡ ì•„ë˜ì—ì„œ ê° ë¬¸ìê°’ì— ëŒ€ì‘í•  ìˆ«ìë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            else:
                st.success("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ìˆ«ì í˜•íƒœì´ê±°ë‚˜ ë‚ ì§œ í˜•íƒœì…ë‹ˆë‹¤.")
                
                # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
    except Exception as e:
        # âœ… ì—ëŸ¬ ë°œìƒ ì‹œ ì§„í–‰ë¥  ì œê±°
        progress_container.empty()
        
        st.error(f"âŒ íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ!")
        st.error(f"ğŸ” ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
        
        # ìºì‹œ í´ë¦¬ì–´ ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ ìºì‹œ í´ë¦¬ì–´"):
                st.cache_data.clear()
                st.rerun()
        with col2:
            if st.button("ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨"):
                st.rerun()

# âœ… ë¬¸ì-ìˆ«ì ë§¤í•‘ ì„¤ì • UI (ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸ ê°•í™”)
if st.session_state.file_loaded and st.session_state.text_frequency:
    st.markdown("---")
    st.subheader("ğŸ”¢ ë¬¸ì-ìˆ«ì ë³€í™˜ ì„¤ì •")
    
    # âœ… ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸ ìƒíƒœ í‘œì‹œ
    if st.session_state.date_columns:
        st.info(f"ğŸ›¡ï¸ ë³´í˜¸ë˜ëŠ” ë‚ ì§œ ì»¬ëŸ¼: {st.session_state.date_columns}")
        st.caption("ì´ ì»¬ëŸ¼ë“¤ì€ ë¬¸ì-ìˆ«ì ë³€í™˜ì—ì„œ ìë™ìœ¼ë¡œ ì œì™¸ë˜ì–´ ì›ë³¸ í˜•íƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
    
    # âœ… 1. ë¹ˆë„ ì •ë³´ì™€ ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ
    st.write("**ë°œê²¬ëœ ë¬¸ìê°’ë“¤ê³¼ ë¹ˆë„ ì •ë³´:**")
    
    # ë¹ˆë„ ì •ë³´ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œ
    frequency_data = []
    for text, freq in st.session_state.text_frequency.items():
        columns_list = list(st.session_state.text_columns[text])
        frequency_data.append({
            "ë¬¸ìê°’": text,
            "ë¹ˆë„": f"{freq:,}",
            "ì¶œí˜„ ì»¬ëŸ¼": ", ".join(columns_list) if len(columns_list) <= 3 else f"{', '.join(columns_list[:3])}... (ì´ {len(columns_list)}ê°œ)"
        })
    
    # ë¹ˆë„ ê¸°ì¤€ ì •ë ¬ (ë‚®ì€ ë¹ˆë„ë¶€í„°)
    frequency_df = pd.DataFrame(frequency_data).sort_values('ë¹ˆë„')
    st.dataframe(frequency_df, use_container_width=True)
    
    # ë¹ˆë„ê°€ ë‚®ì€ ê°’ë“¤ (10ê°œ ë¯¸ë§Œ) ë³„ë„ í‘œì‹œ
    low_freq_items = [(text, freq, st.session_state.text_columns[text]) 
                      for text, freq in st.session_state.text_frequency.items() if freq < 10]
    
    if low_freq_items:
        st.warning("âš ï¸ ë¹ˆë„ê°€ ë‚®ì€ ë¬¸ìê°’ë“¤ (10íšŒ ë¯¸ë§Œ):")
        for text, freq, columns in low_freq_items:
            st.write(f"â€¢ **{text}** ({freq}íšŒ) â†’ ì»¬ëŸ¼: {list(columns)}")
    
    # ìˆ«ì ì„ íƒ ì˜µì…˜
    number_options = [0, 1, 5, 10, 25, 50, 75, 100]
    
    st.markdown("---")
    st.write("**ìˆ«ì ë§¤í•‘ ì„¤ì •:**")
    
    # 2ì—´ë¡œ ë°°ì¹˜í•˜ì—¬ ë§¤í•‘ ì„¤ì •
    mapping_dict = {}
    
    # ë¬¸ìê°’ë“¤ì„ ë¹ˆë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ
    sorted_texts = sorted(st.session_state.text_frequency.keys(), 
                         key=lambda x: st.session_state.text_frequency[x], reverse=True)
    
    cols = st.columns(2)
    for i, text in enumerate(sorted_texts):
        with cols[i % 2]:
            # ê¸°ë³¸ê°’ ì„¤ì • (ì¼ë°˜ì ì¸ ë§¤í•‘)
            if text.upper() in ['OFF', 'STOP', 'FALSE', '0']:
                default_idx = 0  # 0
            elif text.upper() in ['ON', 'RUNNING', 'TRUE', '1']:
                default_idx = 1  # 1
            else:
                default_idx = 1  # ê¸°ë³¸ê°’ì€ 1
            
            freq = st.session_state.text_frequency[text]
            selected_number = st.selectbox(
                f"{text} ({freq}íšŒ) â†’ ",
                options=number_options,
                index=default_idx,
                key=f"mapping_{text}"
            )
            mapping_dict[text] = selected_number
    
    # ë§¤í•‘ ì ìš© ë²„íŠ¼
    if st.button("ğŸ”„ ë¬¸ì-ìˆ«ì ë³€í™˜ ì ìš©"):
        try:
            # ì›ë³¸ ë°ì´í„°ì— ë§¤í•‘ ì ìš© (ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸)
            converted_df = apply_text_mapping(st.session_state.raw_df, mapping_dict, st.session_state.date_columns)
            st.session_state.df = converted_df
            st.session_state.text_mapping = mapping_dict
            
            st.success("âœ… ë¬¸ì-ìˆ«ì ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ë³€í™˜ ê²°ê³¼ ìš”ì•½
            st.write("**ì ìš©ëœ ë§¤í•‘:**")
            for text, number in mapping_dict.items():
                st.write(f"â€¢ {text} â†’ {number}")
            
            # ë³€í™˜ í›„ ë°ì´í„° íƒ€ì… í™•ì¸
            numeric_columns = st.session_state.df.select_dtypes(include=[np.number]).columns
            datetime_columns = st.session_state.df.select_dtypes(include=['datetime64']).columns
            
            st.info(f"âœ… ìˆ«ì ì»¬ëŸ¼ ìˆ˜: {len(numeric_columns)}/{len(st.session_state.df.columns)}")
            st.info(f"ğŸ—“ï¸ ë‚ ì§œ ì»¬ëŸ¼ ìˆ˜: {len(datetime_columns)}/{len(st.session_state.df.columns)}")
            
        except Exception as e:
            st.error(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")

# ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ ì„¹ì…˜
if st.session_state.file_loaded and st.session_state.df is not None:
    df = st.session_state.df
    st.markdown("---")
    st.success("âœ… Excel ë¡œë”© ì™„ë£Œ!")

    # ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤ ë°•ìŠ¤
    st.subheader("ğŸ§¾ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ìŠ¤í¬ë¡¤ ë°•ìŠ¤)")
    with st.expander(f"ì „ì²´ ì»¬ëŸ¼ ë³´ê¸° (ì´ {len(df.columns)}ê°œ)", expanded=True):
        # ì»¬ëŸ¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ í‘œì‹œ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
        object_cols = df.select_dtypes(include=['object']).columns.tolist()
        
        col_info = []
        for i, col in enumerate(df.columns):
            if col in numeric_cols:
                col_type = "ğŸ”¢ ìˆ«ì"
            elif col in datetime_cols:
                col_type = "ğŸ—“ï¸ ë‚ ì§œ"
            elif col in object_cols:
                col_type = "ğŸ”¤ í…ìŠ¤íŠ¸"
            else:
                col_type = "â“ ê¸°íƒ€"
            
            col_info.append(f"{i+1}. {col} ({col_type})")
        
        # HTMLì„ í™œìš©í•œ ìŠ¤í¬ë¡¤ ë°•ìŠ¤
        st.markdown(
            f"""
            <div style='max-height: 300px; overflow-y: scroll; padding: 10px; border: 1px solid #ccc; background-color: #f9f9f9'>
            {"<br>".join(col_info)}
            </div>
            """,
            unsafe_allow_html=True
        )        

    # íƒ€ì… ì²´í¬ ë° ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼ í‘œì‹œ
    object_cols = df.columns[df.dtypes.eq(object)]
    if len(object_cols) > 0:
        st.markdown("ğŸ§ª `object` íƒ€ì…ì¸ ì»¬ëŸ¼ (ì¶”ê°€ ì²˜ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ):")
        st.write(object_cols.tolist())
    
    # ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼ í‘œì‹œ
    if st.session_state.date_columns:
        protected_cols = [col for col in st.session_state.date_columns if col in df.columns]
        if protected_cols:
            st.success(f"ğŸ›¡ï¸ ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼: {protected_cols}")

    # âœ… ì¶”ê°€: ì œê±°í•  ì»¬ëŸ¼ ì„ íƒ ê¸°ëŠ¥ (ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸)
    st.subheader("ğŸ—‘ï¸ ì œê±°í•  ì»¬ëŸ¼ ì„ íƒ")
    
    # ë‚ ì§œ ì»¬ëŸ¼ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì œê±° ëŒ€ìƒì—ì„œ ì œì™¸
    removable_columns = [col for col in df.columns.tolist() if col not in st.session_state.date_columns]
    
    if st.session_state.date_columns:
        st.info(f"ğŸ›¡ï¸ ë‚ ì§œ ì»¬ëŸ¼ {st.session_state.date_columns}ì€(ëŠ”) ë³´í˜¸ë˜ì–´ ì œê±° ì˜µì…˜ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
    
    cols_to_drop = st.multiselect(
        "ë°ì´í„°í”„ë ˆì„ì—ì„œ ì œê±°í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
        removable_columns,
        help="ë‚ ì§œ ì»¬ëŸ¼ì€ ìë™ìœ¼ë¡œ ë³´í˜¸ë˜ì–´ ì„ íƒ ëª©ë¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤."
    )

    # âœ… ì¶”ê°€: ì»¬ëŸ¼ ì œê±° ë²„íŠ¼
    if st.button("ì„ íƒí•œ ì»¬ëŸ¼ ì œê±°í•˜ê¸°"):
        if cols_to_drop:
            # ë‚ ì§œ ì»¬ëŸ¼ì´ ì‹¤ìˆ˜ë¡œ í¬í•¨ë˜ì§€ ì•Šì•˜ëŠ”ì§€ ì¬í™•ì¸
            safe_cols_to_drop = [col for col in cols_to_drop if col not in st.session_state.date_columns]
            
            if safe_cols_to_drop:
                df = df.drop(columns=safe_cols_to_drop)
                st.session_state.df = df  # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.success(f"âœ… ì„ íƒí•œ {len(safe_cols_to_drop)}ê°œ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ!")
                st.info(f"ë‚¨ì€ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
                
                if len(safe_cols_to_drop) != len(cols_to_drop):
                    protected_count = len(cols_to_drop) - len(safe_cols_to_drop)
                    st.warning(f"ğŸ›¡ï¸ {protected_count}ê°œ ë‚ ì§œ ì»¬ëŸ¼ì€ ë³´í˜¸ë˜ì–´ ì œê±°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ğŸ›¡ï¸ ì„ íƒí•œ ëª¨ë“  ì»¬ëŸ¼ì´ ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼ì…ë‹ˆë‹¤.")
        else:
            st.warning("â— ì œê±°í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.")

    # ë³€í™˜ ì „/í›„ ë¹„êµ (ë¬¸ìê°’ì´ ìˆì—ˆë˜ ê²½ìš°)
    if st.session_state.text_frequency and 'raw_df' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ‘€ ë°ì´í„° ë³€í™˜ ë¹„êµ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ë³€í™˜ ì „ (ì›ë³¸):**")
            st.dataframe(st.session_state.raw_df.head(), use_container_width=True)
        
        with col2:
            st.write("**ë³€í™˜ í›„ (ìˆ«ì/ë‚ ì§œ):**")
            st.dataframe(df.head(), use_container_width=True)
            
        # ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸ ìƒíƒœ í™•ì¸
        if st.session_state.date_columns:
            st.info("ğŸ›¡ï¸ ë‚ ì§œ ì»¬ëŸ¼ë“¤ì€ ì›ë³¸ í˜•íƒœë¥¼ ìœ ì§€í•˜ë©° ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ì €ì¥ ì„¤ì •
    st.markdown("---")
    st.subheader("ğŸ’¾ Feather ì €ì¥ ì„¤ì •")
    default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()

    # âœ… 1. ì„¸ì…˜ ìƒíƒœì—ì„œ ë‚ ì§œ ì •ë³´ê°€ í¬í•¨ëœ íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
    default_filename = st.session_state.get('last_filename', 'data')
    save_name = st.text_input(
        "ğŸ“„ ì €ì¥ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)", 
        value=default_filename,
        help="ë‚ ì§œ ì •ë³´ì™€ ì‹œíŠ¸ëª…ì´ ìë™ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤"
    )    

    # FTR ì €ì¥ ë²„íŠ¼
    if st.button("ğŸ’¾ Featherë¡œ ì €ì¥í•˜ê¸°"):
        save_path = os.path.join(default_root, save_name + ".ftr")
        try:
            # DataFrame ìœ íš¨ì„± ê²€ì‚¬ ë° ì•ˆì „í•œ ì €ì¥
            if df is None or df.empty:
                st.error("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            else:
                df_to_save = df.reset_index(drop=True)
                df_to_save.to_feather(save_path)
                st.success(f"âœ… Feather íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ:\n`{save_path}`")
                st.info(f"ğŸ“Š ì €ì¥ëœ ë°ì´í„°: {len(df_to_save)}í–‰ Ã— {len(df_to_save.columns)}ì—´")
                
                # ë‚ ì§œ ì»¬ëŸ¼ ë³´ì¡´ í™•ì¸
                if st.session_state.date_columns:
                    preserved_date_cols = [col for col in st.session_state.date_columns if col in df_to_save.columns]
                    if preserved_date_cols:
                        st.success(f"ğŸ—“ï¸ ë³´ì¡´ëœ ë‚ ì§œ ì»¬ëŸ¼: {preserved_date_cols}")
                        
        except Exception as e:
            st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            st.error(f"ë””ë²„ê¹… ì •ë³´: DataFrame shape={df.shape if df is not None else 'None'}")

    # Feather ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
    st.subheader("ğŸ’¾ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ")

    # âœ… 2. íŒŒì¼ëª… ì…ë ¥ - ë‚ ì§œ ì •ë³´ê°€ í¬í•¨ëœ íŒŒì¼ëª… ì‚¬ìš©
    default_download_filename = st.session_state.get('last_filename', 'ftr_data')
        
    download_name = st.text_input(
        "ğŸ“„ ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)", 
        value=default_download_filename,
        help="ë‚ ì§œ ì •ë³´ì™€ ì‹œíŠ¸ëª…ì´ ìë™ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤"
    )

    try:
        # âœ… io ëª¨ë“ˆ ì˜¤ë¥˜ í•´ê²°: ëª¨ë“ˆ ì¬import ë° ì•ˆì „í•œ ì²˜ë¦¬
        import io as io_module  # ëª…ì‹œì  import
        
        # ë©”ëª¨ë¦¬ì— ì„ì‹œë¡œ íŒŒì¼ ì €ì¥
        buffer = io_module.BytesIO()
        
        # DataFrame ìœ íš¨ì„± ê²€ì‚¬
        if df is None or df.empty:
            st.error("âŒ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else:
            # Feather í˜•ì‹ìœ¼ë¡œ ì €ì¥
            df_to_save = df.reset_index(drop=True)
            df_to_save.to_feather(buffer)
            buffer.seek(0)
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(
                label="ğŸ“¥ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=buffer.getvalue(),  # getvalue() ì‚¬ìš©ìœ¼ë¡œ ë” ì•ˆì „í•˜ê²Œ
                file_name=f"{download_name}.ftr",
                mime="application/octet-stream"
            )
            
            # ì„±ê³µ ë©”ì‹œì§€
            st.success(f"âœ… ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ: {download_name}.ftr")
            
            # ë‚ ì§œ ì»¬ëŸ¼ ë³´ì¡´ í™•ì¸
            if st.session_state.date_columns:
                preserved_date_cols = [col for col in st.session_state.date_columns if col in df_to_save.columns]
                if preserved_date_cols:
                    st.info(f"ğŸ—“ï¸ ë‹¤ìš´ë¡œë“œ íŒŒì¼ì— ë³´ì¡´ëœ ë‚ ì§œ ì»¬ëŸ¼: {preserved_date_cols}")
        
    except ImportError:
        st.error("âŒ io ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Python í™˜ê²½ì„ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        st.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        # ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        st.error(f"ë””ë²„ê¹… ì •ë³´:")
        st.error(f"- DataFrame shape: {df.shape if df is not None else 'None'}")
        st.error(f"- DataFrame columns: {len(df.columns) if df is not None else 'N/A'}")
        st.error(f"- DataFrame dtypes: {df.dtypes.to_dict() if df is not None else 'N/A'}")
        st.error(f"- ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        
        # ëŒ€ì•ˆ ì œì‹œ
        st.info("ğŸ’¡ ëŒ€ì•ˆ: ì„œë²„ ì €ì¥ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê±°ë‚˜ CSV í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ë³´ì„¸ìš”.")

    # ê³ ì† Plotly ì‹œê°í™” (GPU í•„ìš”)
    st.markdown("---")
    st.subheader("âš¡ Plotly ê³ ì† ì‹œê°í™” (WebGL)")
    num_cols = df.select_dtypes(include='number').columns
    
    if len(num_cols) > 0:
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ì•„ë‹Œ ìˆ«ì ì»¬ëŸ¼ë“¤ë§Œ ì‹œê°í™” ëŒ€ìƒìœ¼ë¡œ ì œê³µ
        visualizable_columns = [col for col in df.columns.tolist() 
                               if col not in st.session_state.date_columns and pd.api.types.is_numeric_dtype(df[col])]
        
        if visualizable_columns:
            selected_columns = st.multiselect(
                'ì‹œê°í™”í•  ìˆ«ì ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”',
                visualizable_columns,
                default=visualizable_columns[:2] if len(visualizable_columns) >= 2 else visualizable_columns[:1]
            )            
            
            if selected_columns:
                downsample_rate = st.slider("ğŸ“‰ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ (1/N)", 1, 50, 10)
                
                # ì—¬ëŸ¬ ì»¬ëŸ¼ì— ëŒ€í•œ íŠ¸ë ˆì´ìŠ¤ë¥¼ ê°ê° ì¶”ê°€
                fig = go.Figure()
                
                for col in selected_columns:
                    if pd.api.types.is_numeric_dtype(df[col]):
                        downsampled_y = df[col][::downsample_rate]
                        fig.add_trace(go.Scattergl(
                            y=downsampled_y,
                            mode='lines',
                            name=str(col)  # ê° ì»¬ëŸ¼ëª…ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                        ))
                
                fig.update_layout(
                    title=f"ì„ íƒí•œ ì»¬ëŸ¼ ì‹œê°í™” (1/{downsample_rate} ë‹¤ìš´ìƒ˜í”Œë§)",
                    xaxis=dict(rangeslider=dict(visible=False)),
                    margin=dict(l=20, r=20, t=40, b=20),
                    height=300
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° Xì¶• ì˜µì…˜ ì œê³µ
                if st.session_state.date_columns:
                    available_date_cols = [col for col in st.session_state.date_columns if col in df.columns]
                    if available_date_cols:
                        st.info("ğŸ’¡ ì‹œê°„ì¶• ì‹œê°í™”ë¥¼ ì›í•˜ë©´ ì•„ë˜ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ Xì¶•ìœ¼ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        
                        use_date_axis = st.checkbox("ğŸ—“ï¸ ë‚ ì§œë¥¼ Xì¶•ìœ¼ë¡œ ì‚¬ìš©")
                        if use_date_axis:
                            date_col_for_x = st.selectbox("Xì¶•ìœ¼ë¡œ ì‚¬ìš©í•  ë‚ ì§œ ì»¬ëŸ¼ ì„ íƒ:", available_date_cols)
                            
                            if date_col_for_x and selected_columns:
                                # ë‚ ì§œë¥¼ Xì¶•ìœ¼ë¡œ í•˜ëŠ” ì‹œê°í™”
                                fig_time = go.Figure()
                                
                                for col in selected_columns:
                                    if pd.api.types.is_numeric_dtype(df[col]):
                                        downsampled_df = df.iloc[::downsample_rate]  # ì „ì²´ í–‰ì„ ë‹¤ìš´ìƒ˜í”Œë§
                                        fig_time.add_trace(go.Scattergl(
                                            x=downsampled_df[date_col_for_x],
                                            y=downsampled_df[col],
                                            mode='lines',
                                            name=str(col)
                                        ))
                                
                                fig_time.update_layout(
                                    title=f"ì‹œê°„ì¶• ì‹œê°í™” (X: {date_col_for_x})",
                                    xaxis_title=date_col_for_x,
                                    yaxis_title="ê°’",
                                    margin=dict(l=20, r=20, t=40, b=20),
                                    height=400
                                )
                                st.plotly_chart(fig_time, use_container_width=True)
            else:
                st.info("ì‹œê°í™”í•  ìˆ«ì ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.")
        else:
            st.info("ì‹œê°í™” ê°€ëŠ¥í•œ ìˆ«ì ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ ì»¬ëŸ¼ì€ ì œì™¸ë¨)")
    else:
        st.info("ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ====================================================================== 
    # âœ… 1. ëª¨ë“  ì‹œíŠ¸ì— ì¼ê´„ ì ìš© ê¸°ëŠ¥ ì¶”ê°€ (ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸ ê°•í™”)
    st.markdown("---")
    st.header("ğŸ”„ ëª¨ë“  ì‹œíŠ¸ì— ì¼ê´„ ì ìš©")
    
    if uploaded_file is not None:
        # í˜„ì¬ ì„¤ì • ìš”ì•½ í‘œì‹œ
        st.subheader("ğŸ“‹ í˜„ì¬ ì ìš©í•  ì„¤ì • ìš”ì•½")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ”¢ ë¬¸ì-ìˆ«ì ë§¤í•‘ ì„¤ì •:**")
            if st.session_state.text_mapping:
                for text, number in st.session_state.text_mapping.items():
                    st.write(f"â€¢ {text} â†’ {number}")
            else:
                st.write("ì„¤ì •ëœ ë§¤í•‘ì´ ì—†ìŠµë‹ˆë‹¤.")
                
            st.write("**ğŸ›¡ï¸ ë³´í˜¸ë˜ëŠ” ë‚ ì§œ ì»¬ëŸ¼:**")
            if st.session_state.date_columns:
                for col in st.session_state.date_columns:
                    st.write(f"â€¢ {col}")
            else:
                st.write("ì‹ë³„ëœ ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.write("**ğŸ—‘ï¸ ì œê±°í•  ì»¬ëŸ¼ ì„¤ì •:**")
            if 'cols_to_drop' in locals() and cols_to_drop:
                for col in cols_to_drop:
                    st.write(f"â€¢ {col}")
            else:
                st.write("ì œê±°í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œíŠ¸ ëª©ë¡ í‘œì‹œ
        if len(available_sheets) > 0:  # âœ… 2. ì‹œíŠ¸ ëª©ë¡ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹¤í–‰
            st.write(f"**ğŸ“‹ ì²˜ë¦¬ ëŒ€ìƒ ì‹œíŠ¸ ({len(available_sheets)}ê°œ)**")
            # for i, sheet in enumerate(available_sheets, 1):
            #     status = "âœ… í˜„ì¬ ì²˜ë¦¬ë¨" if sheet == sheet_name else "â³ ëŒ€ê¸°ì¤‘"
            #     st.write(f"{i}. {sheet} {status}")
        else:
            st.error("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        # ì¼ê´„ ì²˜ë¦¬ ì‹¤í–‰ ë²„íŠ¼
        if len(available_sheets) > 1:  # ì‹œíŠ¸ê°€ 2ê°œ ì´ìƒì¸ ê²½ìš°ì—ë§Œ í‘œì‹œ
            st.markdown("---")
            if st.button("ğŸš€ ëª¨ë“  ì‹œíŠ¸ì— ë™ì¼í•œ ì²˜ë¦¬ ì ìš© ë° ì €ì¥", type="primary"):
                
                # í˜„ì¬ ì„¤ì • ì €ì¥
                current_mapping = st.session_state.text_mapping.copy()
                current_cols_to_drop = cols_to_drop.copy() if 'cols_to_drop' in locals() else []
                current_date_columns = st.session_state.date_columns.copy()
                
                st.info(f"ğŸ”„ {len(available_sheets)}ê°œ ì‹œíŠ¸ì— ì¼ê´„ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                success_files = []
                error_files = []

                default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()
                # ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬ ì‹œ ëª¨ë‘ ì œê±°
                for file_path in glob.glob(os.path.join(default_root, "*")):
                    try:
                        if os.path.isfile(file_path):
                            os.remove(file_path)
                        elif os.path.isdir(file_path):
                            shutil.rmtree(file_path)
                    except Exception as e:
                        print(f'ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}')

                
                for idx, target_sheet in enumerate(available_sheets):   #### Kang [:3]
                    try:
                        status_text.text(f"ì²˜ë¦¬ ì¤‘: {target_sheet} ({idx+1}/{len(available_sheets)})")
                        
                        # ê° ì‹œíŠ¸ ì½ê¸°
                        sheet_df = load_excel(
                            file=uploaded_file,
                            sheet_name=target_sheet,
                            usecols=usecols,
                            nrows=nrows,
                            date_column=date_column,
                            skiprows=skiprows,
                            skip_next=skip_next
                        )
                        
                        # ê° ì‹œíŠ¸ë³„ë¡œ ë‚ ì§œ ì»¬ëŸ¼ ì¬ì‹ë³„ (ì‹œíŠ¸ë§ˆë‹¤ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                        sheet_date_columns = identify_date_columns(sheet_df, date_column)
                        
                        # ë¬¸ì-ìˆ«ì ë§¤í•‘ ì ìš© (ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸)
                        if current_mapping:
                            sheet_df = apply_text_mapping(sheet_df, current_mapping, sheet_date_columns)
                        
                        # ì»¬ëŸ¼ ì œê±° ì ìš© (ë‚ ì§œ ì»¬ëŸ¼ ë³´í˜¸)
                        if current_cols_to_drop:
                            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì¤‘ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì´ ì•„ë‹Œ ê²ƒë§Œ ì œê±°
                            cols_to_remove = [col for col in current_cols_to_drop 
                                            if col in sheet_df.columns and col not in sheet_date_columns]
                            if cols_to_remove:
                                sheet_df = sheet_df.drop(columns=cols_to_remove)



                        # âœ… 1. íŒŒì¼ëª… ìƒì„± (í•œê¸€ ì œê±°ëœ ë‚ ì§œ ì •ë³´ ì‚¬ìš©)
                        base_filename = os.path.splitext(uploaded_file.name)[0]
                        date_info = extract_date_info_from_data(sheet_df, date_column)
                        sheet_info = f"_{target_sheet}" if target_sheet != "Sheet1" else ""

                        # íŒŒì¼ëª…ì—ì„œ í•œê¸€, íŠ¹ìˆ˜ë¬¸ì ë° ê³µë°± ì œê±° (ì˜ë¬¸, ìˆ«ì, -, _ ë§Œ í—ˆìš©)
                        def remove_korean_and_special_chars(text):
                            # í•œê¸€ ë²”ìœ„: ã„±-ã…, ã…-ã…£, ê°€-í£
                            import re
                            # ì˜ë¬¸ì, ìˆ«ì, í•˜ì´í”ˆ, ì–¸ë”ìŠ¤ì½”ì–´ë§Œ í—ˆìš©
                            return re.sub(r'[^a-zA-Z0-9\-_]', '', text)

                        safe_base = remove_korean_and_special_chars(base_filename)
                        safe_sheet = remove_korean_and_special_chars(sheet_info)
                        safe_date_info = remove_korean_and_special_chars(date_info)

                        timestamp_suffix = str(int(time.time() * 1000))[-6:]  # ë§ˆì§€ë§‰ 8ìë¦¬ë§Œ ì‚¬ìš©
                        # final_filename = f"{safe_sheet}{safe_date_info}_{timestamp_suffix}"
                        final_filename = f"{safe_date_info}_{timestamp_suffix}"
                        
                        # Feather íŒŒì¼ ì €ì¥
                        save_path = os.path.join(default_root, final_filename + ".ftr")
                        
                        sheet_df.reset_index(drop=True).to_feather(save_path)
                        success_files.append((target_sheet, save_path, len(sheet_df), sheet_date_columns))
                        
                    except Exception as e:
                        error_files.append((target_sheet, str(e)))
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                    progress_bar.progress((idx + 1) / len(available_sheets))
                
                # ê²°ê³¼ ìš”ì•½
                status_text.text("ì²˜ë¦¬ ì™„ë£Œ!")
                
                if success_files:
                    st.success(f"âœ… {len(success_files)}ê°œ ì‹œíŠ¸ ì²˜ë¦¬ ì™„ë£Œ!")
                    
                    # ì„±ê³µí•œ íŒŒì¼ë“¤ ì •ë³´ í‘œì‹œ
                    success_data = []
                    for sheet, path, rows, date_cols in success_files:
                        success_data.append({
                            "ì‹œíŠ¸ëª…": sheet,
                            "í–‰ ìˆ˜": f"{rows:,}",
                            "ë³´í˜¸ëœ ë‚ ì§œ ì»¬ëŸ¼": ", ".join(date_cols) if date_cols else "ì—†ìŒ",
                            "íŒŒì¼ ê²½ë¡œ": path
                        })
                    
                    st.dataframe(pd.DataFrame(success_data), use_container_width=True)
                
                if error_files:
                    st.error(f"âŒ {len(error_files)}ê°œ ì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨:")
                    for sheet, error in error_files:
                        st.write(f"â€¢ {sheet}: {error}")
        
        else:
            st.info("ğŸ’¡ ì‹œíŠ¸ê°€ 1ê°œë¿ì´ë¯€ë¡œ ì¼ê´„ ì²˜ë¦¬ ê¸°ëŠ¥ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # ====================================================================== 
    # âœ… 2. ì €ì¥ëœ ëª¨ë“  Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
    st.markdown("---")
    st.header("ğŸ“¦ ì €ì¥ëœ Feather íŒŒì¼ ì¼ê´„ ë‹¤ìš´ë¡œë“œ")
    
    def get_feather_files_in_directory():
        """ì €ì¥ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  .ftr íŒŒì¼ ì°¾ê¸°"""
        default_root = "/app/data" if os.path.exists("/app/data") else os.getcwd()
        feather_files = []
        
        try:
            for file in os.listdir(default_root):
                if file.endswith(".ftr"):
                    file_path = os.path.join(default_root, file)
                    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
                    feather_files.append({
                        "íŒŒì¼ëª…": file,
                        "ê²½ë¡œ": file_path,
                        "í¬ê¸°(MB)": f"{file_size:.2f}"
                    })
        except Exception as e:
            st.error(f"íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        
        return feather_files
    
    def create_zip_download(file_paths):
        """ì—¬ëŸ¬ íŒŒì¼ì„ ZIPìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„"""
        import zipfile
        import io as io_module
        
        zip_buffer = io_module.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    file_name = os.path.basename(file_path)
                    zip_file.write(file_path, file_name)
        
        zip_buffer.seek(0)
        return zip_buffer.getvalue()
    
    # Feather íŒŒì¼ ëª©ë¡ ì¡°íšŒ ë²„íŠ¼
    if st.button("ğŸ” ì €ì¥ëœ Feather íŒŒì¼ ì¡°íšŒ"):
        feather_files = get_feather_files_in_directory()
        
        if feather_files:
            st.write(f"**ğŸ“ ë°œê²¬ëœ Feather íŒŒì¼ ({len(feather_files)}ê°œ):**")
            
            # íŒŒì¼ ëª©ë¡ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
            files_df = pd.DataFrame(feather_files)
            st.dataframe(files_df, use_container_width=True)
            
            # ì „ì²´ í¬ê¸° ê³„ì‚°
            total_size = sum(float(f["í¬ê¸°(MB)"]) for f in feather_files)
            st.info(f"ğŸ“Š ì´ íŒŒì¼ í¬ê¸°: {total_size:.2f} MB")
            
            # ZIP ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            if len(feather_files) > 0:
                try:
                    file_paths = [f["ê²½ë¡œ"] for f in feather_files]
                    zip_data = create_zip_download(file_paths)
                    
                    # âœ… 1. íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ (í•œê¸€ ì œê±°)
                    from datetime import datetime
                    # 24ì‹œê°„ í˜•ì‹ ì‚¬ìš©í•˜ì—¬ í•œê¸€(ì˜¤ì „/ì˜¤í›„) ì œê±°
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    zip_filename = f"feather_files_{timestamp}.zip"
                    
                    st.download_button(
                        label=f"ğŸ“¥ ëª¨ë“  Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({len(feather_files)}ê°œ íŒŒì¼)",
                        data=zip_data,
                        file_name=zip_filename,
                        mime="application/zip"
                    )
                    
                    st.success(f"âœ… {len(feather_files)}ê°œ íŒŒì¼ì´ ZIPìœ¼ë¡œ ì••ì¶•ë˜ì–´ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ë¨")
                    st.info("ğŸ›¡ï¸ ëª¨ë“  íŒŒì¼ì˜ ë‚ ì§œ ì»¬ëŸ¼ì´ ì›ë³¸ í˜•íƒœë¡œ ë³´ì¡´ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                except Exception as e:
                    st.error(f"âŒ ZIP ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.warning("ğŸ“‚ ì €ì¥ëœ Feather íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ë¨¼ì € 'Featherë¡œ ì €ì¥í•˜ê¸°' ë˜ëŠ” 'ëª¨ë“  ì‹œíŠ¸ì— ë™ì¼í•œ ì²˜ë¦¬ ì ìš©'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

else:
    st.info("ğŸ“‚ .xlsx íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    










def safe_rmtree(path):
    def handle_readonly(func, path, exc):
        os.chmod(path, stat.S_IWRITE)  # ì½ê¸°ì „ìš© í•´ì œ
        func(path)
    
    if os.path.exists(path):
        try:
            shutil.rmtree(path, onerror=handle_readonly)
        except OSError:
            # ì‹¤íŒ¨ì‹œ í´ë” ë‚´ìš©ë§Œ ì‚­ì œ
            for root, dirs, files in os.walk(path, topdown=False):
                for file in files:
                    try:
                        file_path = os.path.join(root, file)
                        os.chmod(file_path, stat.S_IWRITE)
                        os.unlink(file_path)
                    except:
                        pass


# ======================================================================
st.title("ğŸ“Š CSV íŒŒì¼ ë³‘í•© ë° Feather ë³€í™˜ ë„êµ¬")
st.write("ì—¬ëŸ¬ CSV íŒŒì¼ì„ ì½ì–´ì„œ ì‹œê°„ ì¸ë±ìŠ¤ë¥¼ ì¡°ì •í•˜ê³ , ë…¸ì´ì¦ˆë¥¼ ì œê±°í•œ í›„ Feather íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

# íŒŒì¼ ì—…ë¡œë“œ UI
st.subheader("ğŸ“ CSV íŒŒì¼ ì—…ë¡œë“œ")
st.write("ì²˜ë¦¬í•  CSV íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”. (Ctrl ë˜ëŠ” Shift í‚¤ë¥¼ ì‚¬ìš©í•´ ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)")

uploaded_files = st.file_uploader("CSV íŒŒì¼ ì„ íƒ", type="csv", accept_multiple_files=True)

if uploaded_files:
    st.success(f"âœ… {len(uploaded_files)}ê°œì˜ CSV íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
    with st.expander("ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡", expanded=False):
        for file in uploaded_files:
            st.write(f"- {file.name} ({file.size} bytes)")
    

    # ì„ì‹œ í´ë” ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì œê±° í›„ ìƒˆë¡œ ìƒì„±)
    folder_path = os.path.join(os.getcwd(), "data", "temp_uploads")

    # âœ… ì„¸ì…˜ ìƒíƒœ ì €ì¥ì„ ë” í™•ì‹¤í•˜ê²Œ
    st.session_state['folder_path'] = folder_path
    st.session_state['uploaded_files_count'] = len(uploaded_files)
    st.session_state['uploaded_files_names'] = [file.name for file in uploaded_files]
    st.session_state['files_uploaded'] = True  # ì—…ë¡œë“œ ì™„ë£Œ í”Œë˜ê·¸ ì¶”ê°€

    if os.path.exists(folder_path):
        # shutil.rmtree(folder_path)  # ê¸°ì¡´ í´ë” ì‚­ì œ
        safe_rmtree(folder_path)
    os.makedirs(folder_path, exist_ok=True)  # ìƒˆ í´ë” ìƒì„±
    
    for uploaded_file in uploaded_files:
        with open(os.path.join(folder_path, uploaded_file.name), "wb") as f:
            f.write(uploaded_file.getbuffer())
    
    st.info(f"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì„ì‹œ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {folder_path}")
    
    # ì´í›„ ì²˜ë¦¬ë¥¼ ìœ„í•´ íŒŒì¼ ëª©ë¡ ì¤€ë¹„
    csv_files = [file.name for file in uploaded_files]
    st.session_state['csv_files'] = csv_files  

    # âœ… í´ë” ë° íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ì¬ì €ì¥
    if os.path.exists(folder_path):
        actual_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
        st.session_state['actual_csv_files'] = actual_files
        st.write(f"ğŸ“ ì‹¤ì œ ì €ì¥ëœ CSV íŒŒì¼ ìˆ˜: {len(actual_files)}")    

    #-----------------------(20250523 ì¶”ê°€ - ì‹œì‘)------------------------------------
    # CSV íŒŒì¼ ë¶„ì„
    st.subheader("ğŸ“Š CSV íŒŒì¼ ë¶„ì„")
    
    # íŒŒì¼ ì„ íƒ
    selected_file = st.selectbox(
        "í—¤ë”ë¥¼ í™•ì¸í•  íŒŒì¼ ì„ íƒ",
        csv_files,
        help="ì„ íƒí•œ íŒŒì¼ì˜ í—¤ë”ì™€ ë¯¸ë¦¬ë³´ê¸°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤"
    )
    
    if selected_file:
        try:
            # ì„ íƒëœ íŒŒì¼ ì½ê¸°
            selected_file_path = os.path.join(folder_path, selected_file)
            df_preview = pd.read_csv(selected_file_path, nrows=100)  # ë¯¸ë¦¬ë³´ê¸°ìš©ìœ¼ë¡œ 100í–‰ë§Œ ì½ê¸°
            
            st.write(f"**ì„ íƒëœ íŒŒì¼: {selected_file}**")
            
            # í—¤ë” ì •ë³´ í‘œì‹œ
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write("**ğŸ“‹ ì»¬ëŸ¼ í—¤ë”:**")
                headers_df = pd.DataFrame({
                    "ì»¬ëŸ¼ëª…": df_preview.columns,
                    "ë°ì´í„° íƒ€ì…": df_preview.dtypes.astype(str),
                    "ìƒ˜í”Œ ê°’": [str(df_preview[col].iloc[0]) if not df_preview[col].empty else "N/A" 
                              for col in df_preview.columns]
                })
                st.dataframe(headers_df, use_container_width=True)
            
            with col2:
                st.write("**ğŸ“ˆ íŒŒì¼ ì •ë³´:**")
                st.write(f"- ì´ ì»¬ëŸ¼ ìˆ˜: {len(df_preview.columns)}")
                st.write(f"- ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜: {len(df_preview)}")
                st.write(f"- íŒŒì¼ í¬ê¸°: {os.path.getsize(selected_file_path):,} bytes")
            
            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            st.write("**ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰):**")
            st.dataframe(df_preview.head(), use_container_width=True)
            
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")



    # ===================(ì‹œê°„ ì„¤ì •ë¶€ ì…ë ¥ - ì‹œì‘)=====================================
    df_head = None
    for csv_file in csv_files:
        try:
            file_path = os.path.join(folder_path, csv_file)
            
            # íŒŒì¼ì˜ ì²« 100í–‰ê³¼ ë§ˆì§€ë§‰ 100í–‰ì„ ì½ì–´ì„œ ì‹œê°„ ë²”ìœ„ í™•ì¸
            df_head = pd.read_csv(file_path, nrows=100)
            break
        except Exception as e:
            st.warning(f"âš ï¸ íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {csv_file}\n{str(e)}")   

    if df_head is not None:
        # Streamlit ì…ë ¥ ë°›ê¸°
        st.subheader("ì‹œê°„ ì»¬ëŸ¼ ì„¤ì •")
        col1, col2, col3 = st.columns(3)

        with col1:
            year_col = st.selectbox("Year ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), index=0 if "year" not in df_head.columns else list(df_head.columns).index("year")+1)
            if year_col is None:
                year_col = st.text_input("Year ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="year")
            month_col = st.selectbox("Month ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), index=0 if "month" not in df_head.columns else list(df_head.columns).index("month")+1)
            if month_col is None:
                month_col = st.text_input("Month ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="month")

        with col2:
            day_col = st.selectbox("Day ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), index=0 if "day" not in df_head.columns else list(df_head.columns).index("day")+1)
            if day_col is None:
                day_col = st.text_input("Day ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="day")
            hour_col = st.selectbox("Hour ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), index=0 if "hour" not in df_head.columns else list(df_head.columns).index("hour")+1)
            if hour_col is None:
                hour_col = st.text_input("Hour ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="hour")

        with col3:
            minute_col = st.selectbox("Minute ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), index=0 if "minute" not in df_head.columns else list(df_head.columns).index("minute")+1)
            if minute_col is None:
                minute_col = st.text_input("Minute ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="minute")
            second_col = st.selectbox("Second ì»¬ëŸ¼ëª…", options=[None] + list(df_head.columns), index=0 if "second" not in df_head.columns else list(df_head.columns).index("second")+1)
            if second_col is None:
                second_col = st.text_input("Second ì»¬ëŸ¼ëª… ì§ì ‘ ì…ë ¥", value="second")
                
        time_columns = {
            'year': year_col,
            'month': month_col, 
            'day': day_col,
            'hour': hour_col,
            'minute': minute_col,
            'second': second_col
        }
    else:
        st.error("ì½ì„ ìˆ˜ ìˆëŠ” CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    # ===================(ì‹œê°„ ì„¤ì •ë¶€ ì…ë ¥ - ë)=====================================            

else:
    st.warning("âš ï¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")



# ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬ ì˜µì…˜
with st.sidebar:
    st.markdown("---")
    st.sidebar.header("ğŸ“ CSV ë°ì´í„° ì²˜ë¦¬ ì˜µì…˜")
    sampling_rate = st.sidebar.selectbox("ë¦¬ìƒ˜í”Œë§ ì£¼ê¸°:", ["1s", "5s", "10s", "30s", "1min"], index=1)
    sampling_method = st.sidebar.selectbox("ë¦¬ìƒ˜í”Œë§ ë°©ë²•:", ["median", "mean", "min", "max"], index=0)
    remove_spikes = st.sidebar.checkbox("ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ(999) ì œê±°", value=True)

    # íŒŒì¼ëª… ì„¤ì •
    timestamp = datetime.now().strftime("%y%m%d%H%M")
    output_filename = st.sidebar.text_input("ì¶œë ¥ íŒŒì¼ëª…:", f"processed_data_{timestamp}.ftr")


# ---------- ì‚¬ìš©ì ì…ë ¥ ----------
with st.sidebar:
    st.markdown("---")
    st.markdown("ğŸ§  **íšŒì‚¬ëª…:** ãˆœíŒŒì‹œë””ì—˜")
    st.markdown("ğŸ« **ì—°êµ¬ì‹¤:** visLAB@PNU")
    st.markdown("ğŸ‘¨â€ğŸ’» **ì œì‘ì:** (C)Dong2")
    st.markdown("ğŸ› ï¸ **ë²„ì „:** V.1.1 (05-20-2025)")
    st.markdown("---")




# ======================================================================       
# í•¨ìˆ˜ ì •ì˜
@st.cache_data(show_spinner=False)
def replace_999_with_neighbors_mean(df):
   df = df.copy()
   for col in df.columns:
       values = df[col].values
       for i in range(1, len(values) - 1):
           if values[i] == 999:
               if values[i - 1] != 999 and values[i + 1] != 999:
                   values[i] = (values[i - 1] + values[i + 1]) / 2
               else:
                   values[i] = np.nan  # ì•ë’¤ë„ 999ë©´ ë³´ë¥˜
       df[col] = values
   return df




# ======================================================================       
# íƒ­ ë¶„ë¦¬
tab1, tab2 = st.tabs(["ğŸ”„ ë°ì´í„° ì²˜ë¦¬", "ğŸ“Š ë°ì´í„° ì‹œê°í™”"])




# íƒ­ ì²˜ë¦¬ ë¶€ë¶„ - tab1 ìˆ˜ì •
with tab1:
    if st.session_state.get('processing_complete', False):
        # ì¬ì²˜ë¦¬ ë²„íŠ¼ (ë§¨ ìœ„ì— í‘œì‹œ)
        if st.button("ğŸ”„ ë‹¤ì‹œ ì²˜ë¦¬", help="ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ë‹¤ì‹œ ì²˜ë¦¬"):
            keys_to_clear = ['processing_complete', 'resampled_df', 'processing_results', 'folder_path']
            for key in keys_to_clear:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()
        
        st.markdown("---")
        
        # ì²˜ë¦¬ ê²°ê³¼ í•­ìƒ í‘œì‹œ
        if 'processing_results' in st.session_state:
            results = st.session_state['processing_results']
            
            st.success(f"ğŸ‰ Feather íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.write(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {results['file_path']}")
            st.write(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {results['file_size']:.2f} MB")
            st.write(f"ğŸ“ˆ ë°ì´í„° í–‰ ìˆ˜: {results['resampled_rows']:,} (ì›ë³¸ ëŒ€ë¹„ {results['reduction_ratio']:.1f}%)")
            
            if os.path.exists(results['file_path']):
                with open(results['file_path'], 'rb') as f:
                    st.download_button(
                        label="ğŸ“¥ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=f,
                        file_name=results['filename'],
                        mime="application/octet-stream",
                        help="ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ Feather í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                        type="primary",
                        key="download_persistent_state"
                    )
            else:
                st.error("âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            
            with st.expander("ğŸ“‹ ì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5í–‰)", expanded=False):
                if 'resampled_df' in st.session_state:
                    st.dataframe(st.session_state['resampled_df'].head())
                else:
                    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            st.info("ğŸ’¡ 'ë°ì´í„° ì‹œê°í™”' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    
    else:
        st.info("ğŸ“‚ ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

        # âœ… ê°•í™”ëœ ë””ë²„ê¹… ì •ë³´
        with st.expander("ğŸ” í˜„ì¬ ì„¸ì…˜ ìƒíƒœ (ë””ë²„ê¹…)", expanded=False):
            st.write("ì„¸ì…˜ ìƒíƒœ í‚¤ë“¤:", list(st.session_state.keys()))
            
            if 'files_uploaded' in st.session_state:
                st.write("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œë¨")
            else:
                st.write("âŒ íŒŒì¼ ì—…ë¡œë“œ ì •ë³´ ì—†ìŒ")
                
            if 'folder_path' in st.session_state:
                folder_path = st.session_state['folder_path']
                st.write("ì €ì¥ëœ í´ë” ê²½ë¡œ:", folder_path)
                if os.path.exists(folder_path):
                    files = os.listdir(folder_path)
                    csv_files = [f for f in files if f.endswith('.csv')]
                    st.write("í´ë” ë‚´ CSV íŒŒì¼ë“¤:", csv_files)
                    st.write(f"CSV íŒŒì¼ ìˆ˜: {len(csv_files)}")
                else:
                    st.write("âŒ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            else:
                st.write("âŒ folder_pathê°€ ì„¸ì…˜ì— ì—†ìŒ")
                # âœ… folder_path ë³µêµ¬ ì‹œë„
                if 'files_uploaded' in st.session_state:
                    folder_path = os.path.join(os.getcwd(), "data", "temp_uploads")
                    if os.path.exists(folder_path):
                        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
                        if csv_files:
                            st.session_state['folder_path'] = folder_path
                            st.session_state['csv_files'] = csv_files
                            st.write("âœ… folder_path ë³µêµ¬ ì™„ë£Œ!")
                            st.rerun()

        # âœ… ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦ ê°•í™”
        can_process = False
        folder_path = None
        csv_files = []
        time_columns = {}
        
        # 1. ì„¸ì…˜ì—ì„œ í•„ìš”í•œ ì •ë³´ í™•ì¸
        if ('folder_path' in st.session_state and 
            'time_columns' in st.session_state and 
            os.path.exists(st.session_state['folder_path'])):
            
            folder_path = st.session_state['folder_path']
            time_columns = st.session_state['time_columns']
            csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
            if csv_files:
                can_process = True
        
        # 2. ì„¸ì…˜ ì •ë³´ ë¶€ì¡±ì‹œ ê¸°ë³¸ ê²½ë¡œ í™•ì¸
        elif not can_process:
            default_folder = os.path.join(os.getcwd(), "data", "temp_uploads")
            if os.path.exists(default_folder):
                csv_files = [f for f in os.listdir(default_folder) if f.endswith('.csv')]
                if csv_files:
                    folder_path = default_folder
                    # ì„¸ì…˜ ìƒíƒœ ë³µêµ¬
                    st.session_state['folder_path'] = folder_path
                    st.session_state['csv_files'] = csv_files
                    
                    # time_columns ê¸°ë³¸ê°’ ì„¤ì •
                    if 'time_columns' not in st.session_state:
                        time_columns = {
                            'year': 'year',
                            'month': 'month', 
                            'day': 'day',
                            'hour': 'hour',
                            'minute': 'minute',
                            'second': 'second'
                        }
                        st.session_state['time_columns'] = time_columns
                    else:
                        time_columns = st.session_state['time_columns']
                    
                    can_process = True
        
        if can_process:
            st.success(f"âœ… ì²˜ë¦¬ ê°€ëŠ¥: {len(csv_files)}ê°œ CSV íŒŒì¼ ë°œê²¬")
        else:
            st.error("âŒ ì²˜ë¦¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

        # âœ… ì™„ì „í•œ ì²˜ë¦¬ ë²„íŠ¼ ë¡œì§ (ì›ë³¸ ìœ ì§€)
        if st.button("ğŸ”„ ì²˜ë¦¬ ì‹œì‘", type="primary", disabled=not can_process):
            try:
                # ì…ë ¥ í´ë” ìœ íš¨ì„± ê²€ì‚¬
                if not os.path.exists(folder_path):
                    st.error(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
                    st.stop()
                
                if not csv_files:
                    st.error("âŒ ì§€ì •ëœ í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                
                st.info(f"ğŸ“‚ ì´ {len(csv_files)} ê°œì˜ CSV íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # íŒŒì¼ ì²˜ë¦¬ ì‹œì‘
                all_data = []

                for i, file in enumerate(csv_files):
                    status_text.text(f"ì²˜ë¦¬ ì¤‘: {file} ({i+1}/{len(csv_files)})")
                    progress_bar.progress((i + 1) / len(csv_files))
                    
                    try:
                        df = pd.read_csv(os.path.join(folder_path, file), low_memory=False)
                        
                        # time_columnsì—ì„œ Noneì´ ì•„ë‹Œ ê°’ë“¤ë§Œ í•„í„°ë§
                        valid_time_columns = {k: v for k, v in time_columns.items() if v is not None}
                        
                        # ìœ íš¨í•œ ì‹œê°„ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹œê°„ ì¸ë±ìŠ¤ ì¡°ì •
                        if valid_time_columns:
                            # ì‹œê°„ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                            missing_columns = []
                            for key, col_name in valid_time_columns.items():
                                if col_name not in df.columns:
                                    missing_columns.append(col_name)

                            if missing_columns:
                                st.warning(f"íŒŒì¼ {file}ì—ì„œ ë‹¤ìŒ ì‹œê°„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
                                continue
                            else:
                                # year ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ê°’ ì¡°ì •
                                if 'year' in valid_time_columns:
                                    if df[valid_time_columns['year']].max() < 100:
                                        df[valid_time_columns['year']] = df[valid_time_columns['year']] + 2000
                                
                                # timestamp ìƒì„±ì„ ìœ„í•œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
                                time_col_list = [valid_time_columns[col] for col in ['year', 'month', 'day', 'hour', 'minute', 'second'] 
                                                if col in valid_time_columns]
                                
                                df['timestamp'] = pd.to_datetime(df[time_col_list])
                                df = df.set_index('timestamp')
                                df.drop(columns=list(valid_time_columns.values()), inplace=True)

                        all_data.append(df)
                        
                    except Exception as e:
                        st.warning(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file}\n{str(e)}")    
                
                # ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
                if not all_data:
                    st.error("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                
                status_text.text("íŒŒì¼ ë³‘í•© ì¤‘...")
                
                # íŒŒì¼ ë³‘í•© 
                merged_df = pd.concat(all_data)
                
                # ì‹œê°„ìˆœ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
                status_text.text("ë°ì´í„° ì •ë ¬ ë° ì¤‘ë³µ ì œê±° ì¤‘...")
                merged_df = merged_df.sort_index()
                merged_df = merged_df[~merged_df.index.duplicated(keep='first')]
                
                # ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ ì œê±°
                if remove_spikes:
                    status_text.text("ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ(999) ì œê±° ì¤‘...")
                    merged_df = replace_999_with_neighbors_mean(merged_df)
                
                # ë¦¬ìƒ˜í”Œë§
                status_text.text(f"{sampling_rate} ì£¼ê¸°ë¡œ ë¦¬ìƒ˜í”Œë§ ì¤‘...")
                if sampling_method == "median":
                    resampled_df = merged_df.resample(sampling_rate).median()
                elif sampling_method == "mean":
                    resampled_df = merged_df.resample(sampling_rate).mean()
                elif sampling_method == "min":
                    resampled_df = merged_df.resample(sampling_rate).min()
                else:  # max
                    resampled_df = merged_df.resample(sampling_rate).max()
                
                # Feather íŒŒì¼ ì €ì¥
                status_text.text("Feather íŒŒì¼ ì €ì¥ ì¤‘...")
                
                save_dir = os.path.dirname(os.path.join(folder_path, output_filename))
                if not os.path.exists(save_dir):
                    os.makedirs(save_dir, exist_ok=True)
                
                # íŒŒì¼ ì €ì¥
                resampled_df_save = resampled_df.reset_index()
                save_path = os.path.join(folder_path, output_filename)
                resampled_df_save.to_feather(save_path)
                
                # íŒŒì¼ í¬ê¸° ê³„ì‚°
                file_size = os.path.getsize(save_path) / (1024 * 1024)  # MB ë‹¨ìœ„
                
                # âœ… ëª¨ë“  ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['resampled_df'] = resampled_df
                st.session_state['processing_complete'] = True
                st.session_state['processing_results'] = {
                    'merged_rows': len(merged_df),
                    'merged_cols': len(merged_df.columns),
                    'time_range': f"{merged_df.index.min()} ~ {merged_df.index.max()}",
                    'resampled_rows': len(resampled_df),
                    'reduction_ratio': len(resampled_df)/len(merged_df)*100,
                    'file_path': save_path,
                    'filename': output_filename,
                    'file_size': file_size
                }
                
                # ì²˜ë¦¬ ì™„ë£Œ ë©”ì‹œì§€ ë° ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ
                status_text.text("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                st.success(f"ğŸ‰ Feather íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.write(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {save_path}")
                st.write(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
                st.write(f"ğŸ“ˆ ë°ì´í„° í–‰ ìˆ˜: {len(resampled_df):,} (ì›ë³¸ ëŒ€ë¹„ {len(resampled_df)/len(merged_df)*100:.1f}%)")
                
                # ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                if os.path.exists(save_path):
                    with open(save_path, 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ Feather íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=f,
                            file_name=output_filename,
                            mime="application/octet-stream",
                            help="ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ Feather í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                            type="primary",
                            key="download_after_processing"
                        )
                
                # ì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ í‘œì‹œ
                with st.expander("ğŸ“‹ ì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5í–‰)", expanded=False):
                    st.dataframe(resampled_df.head())
                
                st.info("ğŸ’¡ 'ë°ì´í„° ì‹œê°í™”' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"âŒ ì „ì²´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒì‹œ ì„¸ì…˜ ìƒíƒœ ì •ë¦¬
                keys_to_clear = ['processing_complete', 'resampled_df', 'processing_results']
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]





