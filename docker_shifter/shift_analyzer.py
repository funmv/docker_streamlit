import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import numpy as np
from typing import List, Dict, Optional, Tuple  
import matplotlib.pyplot as plt
import io
import zipfile
import json                    
from datetime import datetime, timedelta  

# =================================================================================
# Utils ëª¨ë“ˆì—ì„œ í•¨ìˆ˜ import
# =================================================================================
from utils.font_utils import setup_korean_font
from utils.file_utils import (
    load_data_file,
    load_feather_file,
    handle_file_upload,
    handle_batch_file_upload,
    handle_multi_file_upload,
    save_dataframe_to_buffer,
    create_zip_download
)
from utils.data_utils import (
    apply_time_delay,
    get_data_segment
)
from utils.plot_utils import (
    create_multivariate_plot,
    create_combined_plot,
    create_multi_file_plot
)
from utils.batch_utils import (
    process_batch_files,
    split_files_train_val
)
from utils.dnn_utils import (
    create_positional_encoding,
    extract_time_features,
    extract_dnn_samples_optimized,
    extract_time_features_vectorized,
    create_positional_encoding_vectorized,
    extract_dnn_samples,
    process_all_files_for_dnn,
    save_dnn_dataset
)

# matplotlib ê²½ê³  ì œê±°ë¥¼ ìœ„í•œ ì„¤ì •
plt.rcParams['figure.max_open_warning'] = 50

# =================================================================================
# í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™”
# =================================================================================
st.set_page_config(page_title="ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„", layout="wide")
setup_korean_font()


# =================================================================================
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# =================================================================================
def main():
    st.title("ğŸ“ˆ í•™ìŠµìš© ì‹œê³„ì—´ ë°ì´í„° ì¶”ì¶œ íˆ´")
    
    # íƒ­ ìƒì„± - ì¶”í›„ í™•ì¥ì„ ìœ„í•œ êµ¬ì¡°
    # tab1, tab2, tab3 = st.tabs(["ğŸ” ì‹ í˜¸ ê´€ì°°", "ğŸ“Š ì´ë™ ì‹¤í–‰", "ğŸ“¦ ë°ì´í„° ì¶”ì¶œ"])
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” ì‹ í˜¸ ê´€ì°°", "ğŸ“Š ì´ë™ ì‹¤í–‰", "ğŸ“¦ ë°ì´í„° ì¶”ì¶œ", "ğŸ¯ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰"])


    # =================================================================================
    # íƒ­ 1: ì‹ í˜¸ ë¶„ì„ (ë©”ì¸ ê¸°ëŠ¥)
    # =================================================================================
    with tab1:
        st.header("ğŸš€ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ì‹ í˜¸ ê´€ì°° ë° ë¶„ì„")
        
        # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        st.subheader("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown("**FTR/Feather ë˜ëŠ” H5 íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•˜ì„¸ìš”:**")
            uploaded_files = st.file_uploader(
                "FTR/Feather ë˜ëŠ” H5 íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                type=['ftr', 'feather', 'h5', 'hdf5'],
                accept_multiple_files=True
            )
        
        with col2:
            if uploaded_files:
                if st.button("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬", key="upload_btn"):
                    handle_file_upload(uploaded_files)
        
        # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ë¶„ì„ ì‹œì‘
        if 'uploaded_files' in st.session_state and st.session_state.uploaded_files:
            files = st.session_state.uploaded_files
            
            # íŒŒì¼ ì„ íƒ (ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ íŒŒì¼)
            st.subheader("ğŸ“‚ ë¶„ì„í•  íŒŒì¼ ì„ íƒ")
            file_names = [f.name for f in files]
            selected_file_index = st.selectbox(
                "ë¶„ì„í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:",
                range(len(files)),
                format_func=lambda x: file_names[x],
                index=0
            )
            
            # ì„ íƒëœ íŒŒì¼ ë¡œë“œ
            selected_file = files[selected_file_index]
            df = load_data_file(selected_file)
            
            if df is not None:
                st.success(f"âœ… {selected_file.name} ë¡œë”© ì™„ë£Œ! Shape: {df.shape}")
                
                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                    st.dataframe(df.head())
                    st.write(f"**ì»¬ëŸ¼ ì •ë³´:** {list(df.columns)}")
                    st.write(f"**ë°ì´í„° íƒ€ì…:** {df.dtypes.to_dict()}")
                
                # ê¸°ë³¸ ì‹ í˜¸ ê´€ì°°
                st.subheader("ğŸ“ˆ ê¸°ë³¸ ì‹ í˜¸ ê´€ì°°")
                
                # ì»¬ëŸ¼ ì„ íƒ
                selected_cols = st.multiselect(
                    "ğŸ“Š Plotí•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
                    df.columns.tolist(),
                    default=df.columns.tolist()[:3] if len(df.columns) >= 3 else df.columns.tolist()
                )
                
                if selected_cols:
                    # ê¸°ë³¸ ì„¤ì •
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        downsample_rate = st.slider(
                            "ğŸ“‰ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ (1/N)", 
                            min_value=1, max_value=100, value=10
                        )
                    with col2:
                        num_segments = st.selectbox(
                            "ğŸ“Š ë°ì´í„° ë¶„í•  ìˆ˜",
                            options=[1, 2, 3, 4, 5],
                            index=2,  # ê¸°ë³¸ê°’: 3ë“±ë¶„
                            help="ì „ì²´ ë°ì´í„°ë¥¼ ëª‡ ë“±ë¶„í• ì§€ ì„ íƒ"
                        )
                    with col3:
                        selected_segment = st.selectbox(
                            "ğŸ¯ ë¶„ì„ êµ¬ê°„ ì„ íƒ",
                            options=list(range(num_segments)),
                            format_func=lambda x: f"êµ¬ê°„ {x+1}",
                            index=0,  # ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ êµ¬ê°„
                            help="ë¶„ì„í•  êµ¬ê°„ì„ ì„ íƒ"
                        )
                    
                    # ë°ì´í„° êµ¬ê°„ ì •ë³´ í‘œì‹œ
                    total_length = len(df)
                    segment_length = total_length // num_segments
                    start_idx = selected_segment * segment_length
                    end_idx = start_idx + segment_length if selected_segment < num_segments - 1 else total_length
                    
                    st.info(f"ğŸ“Š **ì„ íƒëœ êµ¬ê°„**: {start_idx:,} ~ {end_idx:,} (ì´ {end_idx - start_idx:,}ê°œ í¬ì¸íŠ¸, ì „ì²´ì˜ {((end_idx - start_idx) / total_length * 100):.1f}%)")
                    
                    crosshair = st.checkbox("â–¶ï¸ ì‹­ìì„  Hover í™œì„±í™”", value=True)
                    
                    # ê¸°ë³¸ í”Œë¡¯ ìƒì„±
                    basic_delays = {col: 0 for col in selected_cols}
                    fig_basic = create_multivariate_plot(
                        df, selected_cols, basic_delays, downsample_rate, crosshair,
                        num_segments, selected_segment
                    )
                    fig_basic.update_layout(title="ğŸ“Š ê¸°ë³¸ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ì‹ í˜¸")
                    st.plotly_chart(fig_basic, use_container_width=True)
                
                # ì‹œê°„ ì§€ì—° ë¶„ì„
                st.subheader("â±ï¸ ì‹œê°„ ì§€ì—° ë¶„ì„")
                st.markdown("ì„ íƒëœ ì†ì„±ì— ì‹œê°„ ì§€ì—°ì„ ì ìš©í•˜ì—¬ ì‹ í˜¸ì˜ ìƒí˜¸ê´€ê³„ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                # ì§€ì—° ë¶„ì„ìš© ì»¬ëŸ¼ ì„ íƒ
                delay_cols = st.multiselect(
                    "ğŸ¯ ì§€ì—° ë¶„ì„í•  ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”",
                    df.columns.tolist(),
                    key="delay_analysis_cols"
                )
                
                if delay_cols:                    
                    # ê° ì»¬ëŸ¼ë³„ ì§€ì—°ê°’ ì…ë ¥
                    delays = {}
                    cols_per_row = 3
                    
                    for i in range(0, len(delay_cols), cols_per_row):
                        cols = st.columns(cols_per_row)
                        for j, col_name in enumerate(delay_cols[i:i+cols_per_row]):
                            with cols[j]:
                                delays[col_name] = st.number_input(
                                    f"ğŸ”„ {col_name}",
                                    min_value=-1000,
                                    max_value=1000,
                                    value=0,
                                    step=1,
                                    key=f"delay_{col_name}"
                                )
                    
                    # ì ìš© ë²„íŠ¼ê³¼ í”Œë¡¯
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        if st.button("ğŸš€ ì‹œê°„ ì§€ì—° ì ìš© ë° í”Œë¡¯ ìƒì„±", key="apply_delays_btn"):
                            st.session_state.delays_applied = True
                            st.session_state.current_delays = delays.copy()
                            st.session_state.current_delay_cols = delay_cols.copy()
                    
                    # ì§€ì—° ì ìš©ëœ í”Œë¡¯ í‘œì‹œ
                    if (hasattr(st.session_state, 'delays_applied') and 
                        st.session_state.delays_applied and 
                        hasattr(st.session_state, 'current_delays')):
                        
                        st.markdown("---")
                        st.subheader("ğŸ“Š ì‹œê°„ ì§€ì—° ì ìš© ê²°ê³¼")
                        
                        # ì ìš©ëœ ì§€ì—°ê°’ ì •ë³´ í‘œì‹œ
                        delay_info = []
                        for col, delay in st.session_state.current_delays.items():
                            if delay != 0:
                                delay_info.append(f"**{col}**: {delay:+d}")
                        
                        if delay_info:
                            st.info(f"ì ìš©ëœ ì§€ì—°ê°’: {', '.join(delay_info)}")
                        
                        # í•¨ê»˜ í‘œì‹œí•  ê¸°ì¤€ ì»¬ëŸ¼ ì„ íƒ (ê²°ê³¼ í™•ì¸ í›„ ì„ íƒ ê°€ëŠ¥)
                        available_reference_cols = [col for col in df.columns.tolist() 
                                                  if col not in st.session_state.current_delay_cols]
                        
                        reference_cols = st.multiselect(
                            "ğŸ“Š í•¨ê»˜ ë¹„êµí•  ê¸°ì¤€ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš” (ì§€ì—° ì ìš© ì•ˆë¨)",
                            available_reference_cols,
                            key="reference_cols_result"
                        )
                        
                        if reference_cols:
                            st.info(f"ê¸°ì¤€ ì‹ í˜¸ (ì ì„ ): {', '.join(reference_cols)}")
                        
                        # ì§€ì—° ì ìš©ëœ í”Œë¡¯ ìƒì„± (ê¸°ì¤€ ì»¬ëŸ¼ê³¼ í•¨ê»˜)
                        fig_delayed = create_combined_plot(
                            df, 
                            st.session_state.current_delay_cols,
                            st.session_state.current_delays,
                            reference_cols,
                            downsample_rate,
                            crosshair,
                            num_segments,
                            selected_segment
                        )
                        st.plotly_chart(fig_delayed, use_container_width=True)
                        
                        # ì§€ì—° ì ìš©ëœ ë°ì´í„° ì €ì¥/ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ì¶”ê°€
                        st.markdown("---")
                        st.subheader("ğŸ’¾ ì§€ì—° ì ìš© ë°ì´í„° ì €ì¥")
                        st.caption("ì›ë³¸ì—ì„œ shift ì„ íƒëœ íŠ¹ì§•ì„ ì œì™¸í•˜ê³ , shift ì²˜ë¦¬ëœ íŠ¹ì§•ì„ í¬í•¨í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.")
                        
                        # íŒŒì¼ëª…ê³¼ í˜•ì‹ ì„ íƒ
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            default_filename = f"{selected_file.name.split('.')[0]}_shifted"
                            save_filename = st.text_input(
                                "ì €ì¥í•  íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)",
                                value=default_filename
                            )
                        with col2:
                            save_format = st.selectbox(
                                "íŒŒì¼ í˜•ì‹",
                                options=['feather', 'h5'],
                                index=0,
                                help="ì €ì¥í•  íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”"
                            )

                        # ë°ì´í„° ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        if st.button(f"ğŸ”„ ì§€ì—° ì ìš© ë°ì´í„° ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ({save_format.upper()})", key="generate_shifted_data"):
                            try:
                                # ì›ë³¸ ë°ì´í„° ë³µì‚¬
                                shifted_df = df.copy()
                                
                                # shift ì„ íƒëœ íŠ¹ì§•ë“¤ì„ ì§€ì—° ì²˜ë¦¬ëœ ë²„ì „ìœ¼ë¡œ êµì²´
                                for col in st.session_state.current_delay_cols:
                                    delay = st.session_state.current_delays[col]
                                    shifted_series = apply_time_delay(df, col, delay)
                                    
                                    # ì›ë³¸ ì»¬ëŸ¼ì„ ì§€ì—° ì ìš©ëœ ë°ì´í„°ë¡œ êµì²´
                                    shifted_df[col] = shifted_series
                                
                                # ê²°ì¸¡ê°’ ì •ë³´ í‘œì‹œ
                                total_na = shifted_df.isna().sum().sum()
                                if total_na > 0:
                                    st.warning(f"âš ï¸ ì‹œê°„ ì§€ì—°ìœ¼ë¡œ ì¸í•´ {total_na:,}ê°œì˜ ê²°ì¸¡ê°’ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                
                                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                                with st.expander("ğŸ“‹ ìƒì„±ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                                    st.write(f"**Shape**: {shifted_df.shape}")
                                    st.write(f"**ì»¬ëŸ¼**: {list(shifted_df.columns)}")
                                    st.dataframe(shifted_df.head(10))
                                    
                                    # ì§€ì—° ì ìš© ì •ë³´ ìš”ì•½
                                    st.write("**ì§€ì—° ì ìš©ëœ íŠ¹ì§•:**")
                                    for col, delay in st.session_state.current_delays.items():
                                        st.write(f"- {col}: {delay:+d}í‹± ì§€ì—° ì ìš©")
                                    
                                    # ë³€ê²½ë˜ì§€ ì•Šì€ íŠ¹ì§•ë“¤
                                    unchanged_cols = [col for col in df.columns if col not in st.session_state.current_delay_cols]
                                    if unchanged_cols:
                                        st.write("**ì›ë³¸ ìœ ì§€ëœ íŠ¹ì§•:**")
                                        st.write(f"- {', '.join(unchanged_cols)}")
                                
                                # ì„ íƒëœ í˜•ì‹ìœ¼ë¡œ ì €ì¥
                                file_data = save_dataframe_to_buffer(shifted_df, save_format)
                                file_extension = save_format if save_format != 'feather' else 'feather'

                                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                                st.download_button(
                                    label=f"ğŸ’¾ {save_format.upper()} íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                    data=file_data,
                                    file_name=f"{save_filename}.{file_extension}",
                                    mime="application/octet-stream",
                                    help=f"ì§€ì—°ì´ ì ìš©ëœ ë°ì´í„°ë¥¼ {save_format} í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"
                                )
                                
                                st.success(f"âœ… ì§€ì—° ì ìš©ëœ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                
                            except Exception as e:
                                st.error(f"âŒ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        
                        # ì¶”ê°€ ì €ì¥ ì˜µì…˜ (CSV)
                        with st.expander("ğŸ“„ ì¶”ê°€ ì €ì¥ ì˜µì…˜"):
                            st.markdown("**CSV í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ ê°€ëŠ¥:**")
                            if st.button("ğŸ“Š CSV í˜•ì‹ìœ¼ë¡œ ìƒì„±", key="generate_csv"):
                                try:
                                    # ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ë°ì´í„° ìƒì„±
                                    shifted_df = df.copy()
                                    for col in st.session_state.current_delay_cols:
                                        delay = st.session_state.current_delays[col]
                                        shifted_series = apply_time_delay(df, col, delay)
                                        shifted_df[col] = shifted_series
                                    
                                    # CSVë¡œ ë³€í™˜
                                    csv_buffer = io.StringIO()
                                    shifted_df.to_csv(csv_buffer, index=True)
                                    csv_data = csv_buffer.getvalue()
                                    
                                    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                                    st.download_button(
                                        label="ğŸ“„ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                        data=csv_data,
                                        file_name=f"{save_filename}.csv",
                                        mime="text/csv",
                                        help="ì§€ì—°ì´ ì ìš©ëœ ë°ì´í„°ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"
                                    )
                                    
                                except Exception as e:
                                    st.error(f"âŒ CSV ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # =================================================================================
    # íƒ­ 2: ë°°ì¹˜ ì§€ì—° ì²˜ë¦¬ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
    # =================================================================================
    with tab2:
        st.header("ğŸ”„ ë°°ì¹˜ ì§€ì—° ì²˜ë¦¬")
        st.markdown("ì—¬ëŸ¬ ê°œì˜ FTR/Feather ë˜ëŠ” H5 íŒŒì¼ì— ë™ì¼í•œ ì§€ì—° ì„¤ì •ì„ ì¼ê´„ ì ìš©í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

        # ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        st.subheader("ğŸ“ ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ")
        col1, col2 = st.columns([3, 1])

        with col1:
            st.markdown("**ì—¬ëŸ¬ ê°œì˜ FTR/Feather ë˜ëŠ” H5 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:**")
            batch_uploaded_files = st.file_uploader(
                "ë°°ì¹˜ ì²˜ë¦¬í•  FTR/Feather ë˜ëŠ” H5 íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                type=['ftr', 'feather', 'h5', 'hdf5'],
                accept_multiple_files=True,
                key="batch_file_uploader"
            )
        
        with col2:
            if batch_uploaded_files:
                if st.button("ğŸ“¤ ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬", key="batch_upload_btn"):
                    handle_batch_file_upload(batch_uploaded_files)
        
        # ë°°ì¹˜ íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ì²˜ë¦¬ ì‹œì‘
        if 'batch_uploaded_files' in st.session_state and st.session_state.batch_uploaded_files:
            batch_files = st.session_state.batch_uploaded_files
            
            st.success(f"âœ… {len(batch_files)}ê°œ íŒŒì¼ì´ ë°°ì¹˜ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ íŠ¹ì§• ëª©ë¡ í™•ì¸
            first_file = batch_files[0]
            reference_df = load_feather_file(first_file)
            
            if reference_df is not None:
                st.subheader("ğŸ“Š ê¸°ì¤€ íŒŒì¼ ì •ë³´")
                st.info(f"**ê¸°ì¤€ íŒŒì¼**: {first_file.name} (Shape: {reference_df.shape})")
                
                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“‹ ê¸°ì¤€ íŒŒì¼ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                    st.dataframe(reference_df.head())
                    st.write(f"**ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì§•**: {list(reference_df.columns)}")
                
                # íŠ¹ì§• ì„ íƒ
                st.subheader("ğŸ¯ ì§€ì—° ì ìš©í•  íŠ¹ì§• ì„ íƒ")
                selected_features = st.multiselect(
                    "ë°°ì¹˜ ì²˜ë¦¬ì— ì ìš©í•  íŠ¹ì§•ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                    reference_df.columns.tolist(),
                    default=[reference_df.columns[0]] if len(reference_df.columns) > 0 else [],
                    key="batch_feature_selection"
                )
                
                if selected_features:
                    # ì§€ì—°ê°’ ì„¤ì •
                    st.subheader("â±ï¸ ì§€ì—°ê°’ ì„¤ì •")
                    st.caption("ëª¨ë“  íŒŒì¼ì— ë™ì¼í•œ ì§€ì—°ê°’ì´ ì ìš©ë©ë‹ˆë‹¤. ì–‘ìˆ˜: ë¯¸ë˜â†’í˜„ì¬, ìŒìˆ˜: ê³¼ê±°â†’í˜„ì¬")
                    
                    batch_delays = {}
                    cols_per_row = 3
                    
                    for i in range(0, len(selected_features), cols_per_row):
                        cols = st.columns(cols_per_row)
                        for j, feature_name in enumerate(selected_features[i:i+cols_per_row]):
                            with cols[j]:
                                batch_delays[feature_name] = st.number_input(
                                    f"ğŸ”„ {feature_name}",
                                    min_value=-1000,
                                    max_value=1000,
                                    value=0,
                                    step=1,
                                    key=f"batch_delay_{feature_name}"
                                )
                    
                    # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì • ìš”ì•½
                    st.subheader("ğŸ“‹ ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì • ìš”ì•½")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼:**")
                        for i, file in enumerate(batch_files):
                            st.write(f"{i+1}. {file.name}")
                    
                    with col2:
                        st.markdown("**ì ìš©í•  ì§€ì—° ì„¤ì •:**")
                        for feature, delay in batch_delays.items():
                            if delay != 0:
                                st.write(f"â€¢ {feature}: {delay:+d}í‹±")
                            else:
                                st.write(f"â€¢ {feature}: ì§€ì—° ì—†ìŒ")
                    
                    # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
                    st.markdown("---")
                    col1, col2, col3 = st.columns([1, 2, 1])
                    
                    with col2:
                        if st.button("ğŸš€ ë°°ì¹˜ ì§€ì—° ì²˜ë¦¬ ì‹œì‘", key="start_batch_processing"):
                            st.session_state.batch_processing_done = False
                            
                            with st.spinner("ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                                # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
                                processed_files = process_batch_files(batch_files, selected_features, batch_delays)
                                
                                if processed_files:
                                    st.session_state.processed_batch_files = processed_files
                                    st.session_state.batch_processing_done = True
                                    st.session_state.batch_selected_features = selected_features
                                    st.session_state.batch_delays = batch_delays
                    
                    # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ
                    if (hasattr(st.session_state, 'batch_processing_done') and 
                        st.session_state.batch_processing_done and 
                        hasattr(st.session_state, 'processed_batch_files')):
                        
                        st.markdown("---")
                        st.subheader("âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
                        
                        processed_files = st.session_state.processed_batch_files
                        
                        # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
                        st.success(f"ğŸ‰ {len(processed_files)}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                        # ì²˜ë¦¬ëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
                        with st.expander("ğŸ“Š ì²˜ë¦¬ëœ íŒŒì¼ ìƒì„¸ ì •ë³´"):
                            for i, file_info in enumerate(processed_files):
                                st.markdown(f"**{i+1}. {file_info['original_name']}**")
                                st.write(f"   â€¢ ìƒˆ íŒŒì¼ëª…: {file_info['processed_name']}")
                                st.write(f"   â€¢ ë°ì´í„° í¬ê¸°: {file_info['shape']}")
                                if file_info['applied_delays']:
                                    st.write(f"   â€¢ ì ìš©ëœ ì§€ì—°: {file_info['applied_delays']}")
                                else:
                                    st.write(f"   â€¢ ì ìš©ëœ ì§€ì—°: ì—†ìŒ")
                                st.write("")
                        
                        # í†µê³„ ì •ë³´
                        total_features_processed = sum(len(f['applied_delays']) for f in processed_files)
                        st.info(f"ğŸ“ˆ **ì²˜ë¦¬ í†µê³„**: {len(processed_files)}ê°œ íŒŒì¼, {total_features_processed}ê°œ íŠ¹ì§•ì— ì§€ì—° ì ìš©")
                        
                        # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
                        st.subheader("ğŸ’¾ ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                        
                        # ZIP íŒŒì¼ëª…ê³¼ í˜•ì‹ ì„¤ì •
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            default_zip_name = f"batch_shifted_files_{len(processed_files)}files"
                            zip_filename = st.text_input(
                                "ZIP íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)",
                                value=default_zip_name,
                                key="zip_filename_input"
                            )
                        with col2:
                            batch_save_format = st.selectbox(
                                "íŒŒì¼ í˜•ì‹",
                                options=['feather', 'h5'],
                                index=0,
                                key="batch_save_format",
                                help="ZIP ë‚´ë¶€ íŒŒì¼ì˜ ì €ì¥ í˜•ì‹"
                            )

                        # ZIP ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        if st.button(f"ğŸ“¦ ZIP íŒŒì¼ë¡œ ì¼ê´„ ë‹¤ìš´ë¡œë“œ ({batch_save_format.upper()})", key="download_batch_zip"):
                            try:
                                with st.spinner(f"ğŸ“¦ {batch_save_format.upper()} í˜•ì‹ìœ¼ë¡œ ZIP íŒŒì¼ ìƒì„± ì¤‘..."):
                                    # íŒŒì¼ëª… í™•ì¥ì ì—…ë°ì´íŠ¸
                                    for file_info in processed_files:
                                        original_name = file_info['original_name'].split('.')[0]
                                        file_info['processed_name'] = f"{original_name}_batch_shifted.{batch_save_format}"

                                    zip_data = create_zip_download(processed_files, f"{zip_filename}.zip", batch_save_format)

                                st.download_button(
                                    label=f"ğŸ’¾ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({batch_save_format.upper()})",
                                    data=zip_data,
                                    file_name=f"{zip_filename}.zip",
                                    mime="application/zip",
                                    help=f"ëª¨ë“  ì²˜ë¦¬ëœ íŒŒì¼ì„ {batch_save_format} í˜•ì‹ìœ¼ë¡œ ZIPì— ì••ì¶•í•˜ì—¬ ë‹¤ìš´ë¡œë“œ"
                                )

                                st.success("âœ… ZIP íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

                            except Exception as e:
                                st.error(f"âŒ ZIP íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        
                        # ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                        with st.expander("ğŸ“„ ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"):
                            st.markdown("**ê°œë³„ íŒŒì¼ì„ ë”°ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:**")
                            
                            for i, file_info in enumerate(processed_files):
                                col1, col2 = st.columns([3, 1])
                                
                                with col1:
                                    st.write(f"**{file_info['processed_name']}** ({file_info['shape'][0]:,} Ã— {file_info['shape'][1]})")
                                
                                with col2:
                                    # ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ë°°ì¹˜ì™€ ë™ì¼í•œ í˜•ì‹ ì‚¬ìš©)
                                    file_data = save_dataframe_to_buffer(file_info['dataframe'], batch_save_format)

                                    st.download_button(
                                        label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                        data=file_data,
                                        file_name=file_info['processed_name'],
                                        mime="application/octet-stream",
                                        key=f"individual_download_{i}"
                                    )
    


    # =================================================================================
    # íƒ­ 3: ë‹¤ì¤‘ íŒŒì¼ ì‹œê°í™” (ìƒˆë¡œìš´ ê¸°ëŠ¥)
    # =================================================================================
    with tab3:
        st.header("ğŸ“Š ë‹¤ì¤‘ íŒŒì¼ ì‹œê°í™”")
        st.markdown("ì—¬ëŸ¬ ê°œì˜ FTR/Feather ë˜ëŠ” H5 íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë™ì¼í•œ íŠ¹ì§•ë“¤ì„ ë¹„êµ ì‹œê°í™”í•©ë‹ˆë‹¤.")

        # ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
        st.subheader("ğŸ“ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ")
        col1, col2 = st.columns([3, 1])

        with col1:
            st.markdown("**ì—¬ëŸ¬ ê°œì˜ FTR/Feather ë˜ëŠ” H5 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:**")
            multi_uploaded_files = st.file_uploader(
                "ì‹œê°í™”í•  FTR/Feather ë˜ëŠ” H5 íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                type=['ftr', 'feather', 'h5', 'hdf5'],
                accept_multiple_files=True,
                key="multi_file_uploader"
            )
        
        with col2:
            if multi_uploaded_files:
                if st.button("ğŸ“¤ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬", key="multi_upload_btn"):
                    handle_multi_file_upload(multi_uploaded_files)
        
        # ë‹¤ì¤‘ íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ì‹œê°í™” ì‹œì‘
        if 'multi_uploaded_files' in st.session_state and st.session_state.multi_uploaded_files:
            multi_files = st.session_state.multi_uploaded_files
            
            st.success(f"âœ… {len(multi_files)}ê°œ íŒŒì¼ì´ ë‹¤ì¤‘ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ íŠ¹ì§• ëª©ë¡ í™•ì¸
            first_file = multi_files[0]
            reference_df = load_feather_file(first_file)
            
            if reference_df is not None:
                st.subheader("ğŸ“Š ê¸°ì¤€ íŒŒì¼ ì •ë³´")
                st.info(f"**ê¸°ì¤€ íŒŒì¼**: {first_file.name} (Shape: {reference_df.shape})")
                
                # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
                with st.expander("ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡"):
                    for i, file in enumerate(multi_files):
                        try:
                            temp_df = load_feather_file(file)
                            if temp_df is not None:
                                st.write(f"{i+1}. **{file.name}** - Shape: {temp_df.shape}")
                            else:
                                st.write(f"{i+1}. **{file.name}** - âŒ ë¡œë“œ ì‹¤íŒ¨")
                        except:
                            st.write(f"{i+1}. **{file.name}** - âŒ ë¡œë“œ ì‹¤íŒ¨")
                
                # íŠ¹ì§• ì„ íƒ
                st.subheader("ğŸ¯ ì‹œê°í™”í•  íŠ¹ì§• ì„ íƒ")
                multi_selected_features = st.multiselect(
                    "ë¹„êµí•  íŠ¹ì§•ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                    reference_df.columns.tolist(),
                    default=[reference_df.columns[0]] if len(reference_df.columns) > 0 else [],
                    key="multi_feature_selection",
                    help="ì„ íƒëœ íŠ¹ì§•ë“¤ì´ ì„ íƒëœ íŒŒì¼ë“¤ì—ì„œ ë¹„êµ ì‹œê°í™”ë©ë‹ˆë‹¤."
                )
                
                # í”Œë¡¯í•  íŒŒì¼ ì„ íƒ ì¶”ê°€
                st.subheader("ğŸ“‚ í”Œë¡¯í•  íŒŒì¼ ì„ íƒ")
                file_names = [f.name for f in multi_files]
                selected_file_indices = st.multiselect(
                    "í”Œë¡¯ì— í¬í•¨í•  íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                    range(len(multi_files)),
                    format_func=lambda x: file_names[x],
                    default=[0] if len(multi_files) > 0 else [], 
                    key="multi_file_selection",
                    help="ì„ íƒëœ íŒŒì¼ë“¤ë§Œ í”Œë¡¯ì— í‘œì‹œë©ë‹ˆë‹¤."
                )
                
                # ì„ íƒëœ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
                selected_files = [multi_files[i] for i in selected_file_indices]
                
                if multi_selected_features and selected_files:
                    # ì‹œê°í™” ì„¤ì • (íƒ­1ê³¼ ë™ì¼í•œ êµ¬ì¡°)
                    st.subheader("âš™ï¸ ì‹œê°í™” ì„¤ì •")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        multi_downsample_rate = st.slider(
                            "ğŸ“‰ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ (1/N)", 
                            min_value=1, max_value=100, value=10,
                            key="multi_downsample"
                        )
                    with col2:
                        multi_num_segments = st.selectbox(
                            "ğŸ“Š ë°ì´í„° ë¶„í•  ìˆ˜",
                            options=[1, 2, 3, 4, 5],
                            index=2,  # ê¸°ë³¸ê°’: 3ë“±ë¶„
                            help="ì „ì²´ ë°ì´í„°ë¥¼ ëª‡ ë“±ë¶„í• ì§€ ì„ íƒ",
                            key="multi_segments"
                        )
                    with col3:
                        multi_selected_segment = st.selectbox(
                            "ğŸ¯ ë¶„ì„ êµ¬ê°„ ì„ íƒ",
                            options=list(range(multi_num_segments)),
                            format_func=lambda x: f"êµ¬ê°„ {x+1}",
                            index=0,  # ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ êµ¬ê°„
                            help="ë¶„ì„í•  êµ¬ê°„ì„ ì„ íƒ",
                            key="multi_segment_select"
                        )
                    
                    # ë°ì´í„° êµ¬ê°„ ì •ë³´ í‘œì‹œ (ê¸°ì¤€ íŒŒì¼ ê¸°ì¤€)
                    total_length = len(reference_df)
                    segment_length = total_length // multi_num_segments
                    start_idx = multi_selected_segment * segment_length
                    end_idx = start_idx + segment_length if multi_selected_segment < multi_num_segments - 1 else total_length
                    
                    st.info(f"ğŸ“Š **ì„ íƒëœ êµ¬ê°„**: {start_idx:,} ~ {end_idx:,} (ì´ {end_idx - start_idx:,}ê°œ í¬ì¸íŠ¸, ì „ì²´ì˜ {((end_idx - start_idx) / total_length * 100):.1f}%)")
                    
                    multi_crosshair = st.checkbox("â–¶ï¸ ì‹­ìì„  Hover í™œì„±í™”", value=True, key="multi_crosshair")
                    
                    # ë‹¤ì¤‘ íŒŒì¼ ì‹œê°í™” ìƒì„±
                    st.subheader("ğŸ“ˆ ë‹¤ì¤‘ íŒŒì¼ íŠ¹ì§• ë¹„êµ")
                    
                    try:
                        # ë‹¤ì¤‘ íŒŒì¼ í”Œë¡¯ ìƒì„± (ì„ íƒëœ íŒŒì¼ë“¤ë§Œ)
                        multi_fig = create_multi_file_plot(
                            selected_files,
                            multi_selected_features,
                            multi_downsample_rate,
                            multi_crosshair,
                            multi_num_segments,
                            multi_selected_segment
                        )
                        
                        st.plotly_chart(multi_fig, use_container_width=True)
                        
                        # ì¶”ê°€ ì •ë³´ í‘œì‹œ
                        st.subheader("ğŸ“‹ ì‹œê°í™” ìš”ì•½")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("**ì‹œê°í™”ëœ íŒŒì¼:**")
                            for i, file in enumerate(selected_files):
                                st.write(f"{i+1}. {file.name}")
                        
                        with col2:
                            st.markdown("**ì‹œê°í™”ëœ íŠ¹ì§•:**")
                            for feature in multi_selected_features:
                                st.write(f"â€¢ {feature}")
                        
                        # ë°ì´í„° íŠ¹ì„± ë¶„ì„ (ì„ íƒëœ íŒŒì¼ë“¤ë§Œ)
                        with st.expander("ğŸ“Š íŒŒì¼ë³„ ë°ì´í„° íŠ¹ì„± ë¹„êµ"):
                            comparison_data = []
                            
                            for file in selected_files:
                                try:
                                    df = load_feather_file(file)
                                    if df is not None:
                                        # ì„ íƒëœ êµ¬ê°„ì—ì„œ í†µê³„ ê³„ì‚°
                                        df_segment = get_data_segment(df, multi_num_segments, multi_selected_segment)
                                        
                                        for feature in multi_selected_features:
                                            if feature in df.columns:
                                                feature_data = df_segment[feature]
                                                comparison_data.append({
                                                    'íŒŒì¼ëª…': file.name,
                                                    'íŠ¹ì§•': feature,
                                                    'í‰ê· ': f"{feature_data.mean():.4f}",
                                                    'í‘œì¤€í¸ì°¨': f"{feature_data.std():.4f}",
                                                    'ìµœì†Œê°’': f"{feature_data.min():.4f}",
                                                    'ìµœëŒ€ê°’': f"{feature_data.max():.4f}",
                                                    'ë°ì´í„° í¬ì¸íŠ¸': f"{len(feature_data):,}",
                                                    'ê²°ì¸¡ê°’': int(feature_data.isna().sum())
                                                })
                                except Exception as e:
                                    st.warning(f"âš ï¸ {file.name} í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            
                            if comparison_data:
                                comparison_df = pd.DataFrame(comparison_data)
                                st.dataframe(comparison_df, use_container_width=True)
                            else:
                                st.warning("âš ï¸ ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                    except Exception as e:
                        st.error(f"âŒ ë‹¤ì¤‘ íŒŒì¼ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        
                elif not multi_selected_features:
                    st.info("ğŸ¯ ì‹œê°í™”í•  íŠ¹ì§•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                elif not selected_files:
                    st.info("ğŸ“‚ í”Œë¡¯í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                st.error("âŒ ê¸°ì¤€ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ“ ë‹¤ì¤‘ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì‹œê°í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
        


        # =================================================================================
        # DNN í•™ìŠµ ë°ì´í„° ì¶”ì¶œ ê¸°ëŠ¥ ì¶”ê°€
        # =================================================================================
        if 'multi_uploaded_files' in st.session_state and st.session_state.multi_uploaded_files:
            st.markdown("---")
            st.header("ğŸ¤– DNN í•™ìŠµ ë°ì´í„° ì¶”ì¶œ")
            st.markdown("ì—…ë¡œë“œëœ FTR íŒŒì¼ë“¤ë¡œë¶€í„° DNN í•™ìŠµìš© ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            
            # ë°ì´í„° ì¶”ì¶œ íŒŒë¼ë¯¸í„° ì„¤ì •
            st.subheader("âš™ï¸ ë°ì´í„° ì¶”ì¶œ ì„¤ì •")
            
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
            col1, col2 = st.columns(2)
            with col1:
                start_position = st.number_input(
                    "ğŸ¯ ì‹œì‘ ìœ„ì¹˜ (í‹±)",
                    min_value=0,
                    max_value=100000,
                    value=300,
                    step=1,
                    help="ë°ì´í„° ì¶”ì¶œì„ ì‹œì‘í•  ìœ„ì¹˜ (0ë¶€í„° ì‹œì‘)",
                    key="dnn_start_pos"
                )
                
                lookback_length = st.number_input(
                    "ğŸ“ˆ ê³¼ê±° ì°¸ì¡° ê¸¸ì´ (í‹±)",
                    min_value=1,
                    max_value=1000,
                    value=60,
                    step=1,
                    help="ê° ì‹œì ì—ì„œ ê³¼ê±° ëª‡ í‹±ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í• ì§€",
                    key="dnn_lookback"
                )
            
            with col2:
                end_position = st.number_input(
                    "ğŸ ì¢…ë£Œ ìœ„ì¹˜ (í‹±)",
                    min_value=start_position + 100,
                    max_value=100000,
                    value=start_position + 1700,
                    step=1,
                    help="ë°ì´í„° ì¶”ì¶œì„ ì¢…ë£Œí•  ìœ„ì¹˜",
                    key="dnn_end_pos"
                )
                
                horizon_length = st.number_input(
                    "ğŸ”® ì˜ˆì¸¡ êµ¬ê°„ ê¸¸ì´ (í‹±)",
                    min_value=1,
                    max_value=100,
                    value=24,
                    step=1,
                    help="ë¯¸ë˜ ëª‡ í‹±ì„ ì˜ˆì¸¡ ëŒ€ìƒìœ¼ë¡œ í• ì§€",
                    key="dnn_horizon"
                )
            
            # ì¶”ê°€ íŒŒë¼ë¯¸í„°
            col3, col4 = st.columns(2)
            with col3:
                step_gap = st.number_input(
                    "â­ï¸ ìŠ¤í… ê°„ê²©",
                    min_value=1,
                    max_value=50,
                    value=2,
                    step=1,
                    help="ìƒ˜í”Œ ì¶”ì¶œ ì‹œ ëª‡ í‹±ì”© ê±´ë„ˆë›¸ì§€",
                    key="dnn_step_gap"
                )
            
            with col4:
                train_ratio = st.slider(
                    "ğŸ“ í›ˆë ¨/ê²€ì¦ ë¹„ìœ¨",
                    min_value=0.5,
                    max_value=0.95,
                    value=0.8,
                    step=0.05,
                    help="í›ˆë ¨ìš© íŒŒì¼ì˜ ë¹„ìœ¨ (ë‚˜ë¨¸ì§€ëŠ” ê²€ì¦ìš©)",
                    key="dnn_train_ratio"
                )
            
            # ì‹œê°„ ì •ë³´ ì„¤ì •
            st.subheader("ğŸ• ì‹œê°„ íŠ¹ì§• ì„¤ì •")
            col5, col6 = st.columns(2)
            with col5:
                use_positional_encoding = st.checkbox(
                    "Positional Encoding ì‚¬ìš©",
                    value=True,
                    help="ì‹œê°„ ì •ë³´ì— positional encoding ì¶”ê°€",
                    key="dnn_pos_encoding"
                )
            
            with col6:
                tick_interval = st.number_input(
                    "í‹± ê°„ê²© (ì´ˆ)",
                    min_value=1,
                    max_value=60,
                    value=5,
                    step=1,
                    help="ê° í‹± ê°„ì˜ ì‹œê°„ ê°„ê²©",
                    key="dnn_tick_interval"
                )
            
            # íŒŒë¼ë¯¸í„° ìš”ì•½ í‘œì‹œ
            st.subheader("ğŸ“‹ ì¶”ì¶œ ì„¤ì • ìš”ì•½")
            with st.expander("ğŸ” ìƒì„¸ ì„¤ì • í™•ì¸"):
                summary_data = {
                    'íŒŒë¼ë¯¸í„°': [
                        'ì‹œì‘ ìœ„ì¹˜', 'ì¢…ë£Œ ìœ„ì¹˜', 'ê³¼ê±° ì°¸ì¡° ê¸¸ì´', 'ì˜ˆì¸¡ êµ¬ê°„ ê¸¸ì´',
                        'ìŠ¤í… ê°„ê²©', 'í›ˆë ¨ ë¹„ìœ¨', 'ê²€ì¦ ë¹„ìœ¨', 'Positional Encoding',
                        'í‹± ê°„ê²©', 'ì´ ì—…ë¡œë“œ íŒŒì¼ ìˆ˜'
                    ],
                    'ê°’': [
                        f"{start_position:,}",
                        f"{end_position:,}",
                        f"{lookback_length}",
                        f"{horizon_length}",
                        f"{step_gap}",
                        f"{train_ratio:.1%}",
                        f"{1-train_ratio:.1%}",
                        "ì‚¬ìš©" if use_positional_encoding else "ë¯¸ì‚¬ìš©",
                        f"{tick_interval}ì´ˆ",
                        f"{len(st.session_state.multi_uploaded_files)}ê°œ"
                    ]
                }
                summary_df = pd.DataFrame(summary_data)
                st.dataframe(summary_df, use_container_width=True)
                
                # ì˜ˆìƒ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
                total_samples_per_file = (end_position - start_position - lookback_length - horizon_length) // step_gap
                if total_samples_per_file > 0:
                    estimated_train_samples = total_samples_per_file * int(len(st.session_state.multi_uploaded_files) * train_ratio)
                    estimated_val_samples = total_samples_per_file * (len(st.session_state.multi_uploaded_files) - int(len(st.session_state.multi_uploaded_files) * train_ratio))
                    
                    st.info(f"ğŸ“Š **ì˜ˆìƒ ìƒ˜í”Œ ìˆ˜**: í›ˆë ¨ìš© ~{estimated_train_samples:,}ê°œ, ê²€ì¦ìš© ~{estimated_val_samples:,}ê°œ")
                else:
                    st.warning("âš ï¸ í˜„ì¬ ì„¤ì •ìœ¼ë¡œëŠ” ìƒ˜í”Œì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
            
            # DNN ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰
            st.subheader("ğŸš€ ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰")
            
            # íŒŒì¼ëª… ì„¤ì •
            default_dataset_name = f"dnn_dataset_{lookback_length}to{horizon_length}_{len(st.session_state.multi_uploaded_files)}files"
            dataset_filename = st.text_input(
                "ë°ì´í„°ì…‹ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)",
                value=default_dataset_name,
                help="ìƒì„±ë  ë°ì´í„°ì…‹ íŒŒì¼ì˜ ì´ë¦„",
                key="dnn_dataset_filename"
            )
            
            # ì¶”ì¶œ ë²„íŠ¼
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸ¤– DNN ë°ì´í„° ì¶”ì¶œ ì‹œì‘", key="start_dnn_extraction"):
                    if total_samples_per_file <= 0:
                        st.error("âŒ í˜„ì¬ ì„¤ì •ìœ¼ë¡œëŠ” ìƒ˜í”Œì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.session_state.dnn_extraction_done = False
                        
                        with st.spinner("ğŸ”„ DNN í•™ìŠµ ë°ì´í„° ì¶”ì¶œ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                            try:
                                # íŒŒì¼ë“¤ì„ í›ˆë ¨/ê²€ì¦ìš©ìœ¼ë¡œ ë¶„í• 
                                train_files, val_files = split_files_train_val(
                                    st.session_state.multi_uploaded_files, train_ratio
                                )
                                
                                st.write(f"ğŸ“‚ **íŒŒì¼ ë¶„í•  ì™„ë£Œ**: í›ˆë ¨ìš© {len(train_files)}ê°œ, ê²€ì¦ìš© {len(val_files)}ê°œ")
                                
                                # ëª¨ë“  íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                                dataset = process_all_files_for_dnn(
                                    train_files, val_files,
                                    start_position, end_position,
                                    lookback_length, horizon_length, step_gap
                                )
                                
                                if len(dataset['train_inputs']) > 0 or len(dataset['val_inputs']) > 0:
                                    # ë©”íƒ€ë°ì´í„° ìƒì„±
                                    metadata = {
                                        'extraction_params': {
                                            'start_position': start_position,
                                            'end_position': end_position,
                                            'lookback_length': str(lookback_length),
                                            'horizon_length': str(horizon_length),
                                            'step_gap': str(step_gap),
                                            'train_ratio': train_ratio,
                                            'use_positional_encoding': use_positional_encoding,
                                            'tick_interval': tick_interval
                                        },
                                        'data_info': {
                                            'train_samples': len(dataset['train_inputs']),
                                            'val_samples': len(dataset['val_inputs']),
                                            'input_shape': dataset['train_inputs'].shape if len(dataset['train_inputs']) > 0 else None,
                                            'output_shape': dataset['train_outputs'].shape if len(dataset['train_outputs']) > 0 else None,
                                            'train_files': [f.name for f in train_files],
                                            'val_files': [f.name for f in val_files],
                                            'total_files': len(st.session_state.multi_uploaded_files)
                                        },
                                        'creation_time': datetime.now().isoformat(),
                                        'feature_info': {
                                            'time_features': 3 + (8 if use_positional_encoding else 0),
                                            'time_feature_names': ['hour_norm', 'minute_norm', 'second_norm'] + 
                                                                ([f'pos_enc_{i}' for i in range(8)] if use_positional_encoding else []),
                                            'data_features': len(reference_df.columns) - 1,  # timestamp ì œì™¸
                                            'data_feature_names': [col for col in reference_df.columns if col != 
                                                                (reference_df.columns[0] if 'time' not in reference_df.columns[0].lower() 
                                                                and 'timestamp' not in reference_df.columns[0].lower() 
                                                                else next((col for col in reference_df.columns 
                                                                            if 'time' in col.lower() or 'timestamp' in col.lower()), 
                                                                        reference_df.columns[0]))],
                                            'total_features': len(dataset['train_inputs'].shape) > 2 and dataset['train_inputs'].shape[2] or 0,
                                            'feature_order': 'time_features_first_then_data_features'
                                        }
                                    }

                                    # ì„¸ì…˜ì— ì €ì¥ (ìˆ˜ì •ëœ ë¶€ë¶„)
                                    st.session_state.dnn_dataset = dataset
                                    st.session_state.dnn_metadata = metadata
                                    st.session_state.dnn_extraction_done = True
                                    st.session_state.dnn_dataset_name = dataset_filename  # filenameì„ nameìœ¼ë¡œ ë³€ê²½
                                    
                                else:
                                    st.error("âŒ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                    
                            except Exception as e:
                                st.error(f"âŒ ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # DNN ë°ì´í„° ì¶”ì¶œ ê²°ê³¼ í‘œì‹œ
            if (hasattr(st.session_state, 'dnn_extraction_done') and 
                st.session_state.dnn_extraction_done and 
                hasattr(st.session_state, 'dnn_dataset')):
                
                st.markdown("---")
                st.subheader("âœ… DNN ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                
                dataset = st.session_state.dnn_dataset
                metadata = st.session_state.dnn_metadata
                
                # ì¶”ì¶œ ê²°ê³¼ ìš”ì•½
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ğŸ“ í›ˆë ¨ ìƒ˜í”Œ", f"{len(dataset['train_inputs']):,}")
                with col2:
                    st.metric("ğŸ”¬ ê²€ì¦ ìƒ˜í”Œ", f"{len(dataset['val_inputs']):,}")
                with col3:
                    st.metric("ğŸ“Š ì´ ìƒ˜í”Œ", f"{len(dataset['train_inputs']) + len(dataset['val_inputs']):,}")
                
                # ë°ì´í„° í˜•íƒœ ì •ë³´
                with st.expander("ğŸ“Š ë°ì´í„° í˜•íƒœ ì •ë³´"):
                    if len(dataset['train_inputs']) > 0:
                        st.write(f"**í›ˆë ¨ ì…ë ¥ í˜•íƒœ**: {dataset['train_inputs'].shape}")
                        st.write(f"**í›ˆë ¨ ì¶œë ¥ í˜•íƒœ**: {dataset['train_outputs'].shape}")
                        
                    if len(dataset['val_inputs']) > 0:
                        st.write(f"**ê²€ì¦ ì…ë ¥ í˜•íƒœ**: {dataset['val_inputs'].shape}")
                        st.write(f"**ê²€ì¦ ì¶œë ¥ í˜•íƒœ**: {dataset['val_outputs'].shape}")
                    
                    st.write(f"**ì‹œê°„ íŠ¹ì§• ìˆ˜**: {metadata['feature_info']['time_features']}")
                    st.write(f"**ì „ì²´ íŠ¹ì§• ìˆ˜**: {dataset['train_inputs'].shape[-1] if len(dataset['train_inputs']) > 0 else 'N/A'}")
                
                # íŒŒì¼ë³„ ìƒ˜í”Œ ìˆ˜ ì •ë³´
                with st.expander("ğŸ“ íŒŒì¼ë³„ ìƒ˜í”Œ ì •ë³´"):
                    # í›ˆë ¨ íŒŒì¼ ì •ë³´
                    st.markdown("**í›ˆë ¨ìš© íŒŒì¼:**")
                    train_file_counts = {}
                    for info in dataset['train_info']:
                        file_name = info['file_name']
                        train_file_counts[file_name] = train_file_counts.get(file_name, 0) + 1
                    
                    for file_name, count in train_file_counts.items():
                        st.write(f"  â€¢ {file_name}: {count:,}ê°œ ìƒ˜í”Œ")
                    
                    # ê²€ì¦ íŒŒì¼ ì •ë³´
                    st.markdown("**ê²€ì¦ìš© íŒŒì¼:**")
                    val_file_counts = {}
                    for info in dataset['val_info']:
                        file_name = info['file_name']
                        val_file_counts[file_name] = val_file_counts.get(file_name, 0) + 1
                    
                    for file_name, count in val_file_counts.items():
                        st.write(f"  â€¢ {file_name}: {count:,}ê°œ ìƒ˜í”Œ")
                

                # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (ìˆ˜ì •ëœ ë¶€ë¶„)
                st.subheader("ğŸ’¾ DNN ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")

                if st.button("ğŸ“¦ ë°ì´í„°ì…‹ íŒŒì¼ ìƒì„±", key="generate_dnn_dataset"):
                    try:
                        with st.spinner("ğŸ“¦ ë°ì´í„°ì…‹ íŒŒì¼ ìƒì„± ì¤‘..."):
                            # ìœ„ì ¯ì—ì„œ í˜„ì¬ ê°’ ê°€ì ¸ì˜¤ê¸° (ìˆ˜ì •ëœ ë¶€ë¶„)
                            current_filename = st.session_state.get('dnn_dataset_filename', 'dnn_dataset')
                            dataset_data = save_dnn_dataset(
                                dataset, metadata, current_filename
                            )
                        
                        st.download_button(
                            label="ğŸ’¾ DNN ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ",
                            data=dataset_data,
                            file_name=f"{current_filename}.npy",  # ìˆ˜ì •ëœ ë¶€ë¶„
                            mime="application/octet-stream",
                            help="DNN í•™ìŠµìš© ë°ì´í„°ì…‹ì„ numpy í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"
                        )
                        
                        st.success("âœ… ë°ì´í„°ì…‹ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                        
                        # ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ í‘œì‹œ (NPY í˜•ì‹ì— ë§ê²Œ ìˆ˜ì •)
                        with st.expander("ğŸ Python ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ"):
                            st.code(f"""
                import numpy as np

                # ë°ì´í„°ì…‹ ë¡œë“œ
                dataset = np.load('{current_filename}.npy', allow_pickle=True).item()  # ìˆ˜ì •ëœ ë¶€ë¶„

                # ë°ì´í„° ì ‘ê·¼
                train_inputs = dataset['train_inputs']    # Shape: (samples, lookback, features)
                train_outputs = dataset['train_outputs']  # Shape: (samples, horizon, features)
                val_inputs = dataset['val_inputs']        # Shape: (samples, lookback, features)
                val_outputs = dataset['val_outputs']      # Shape: (samples, horizon, features)

                # ë©”íƒ€ë°ì´í„° í™•ì¸
                metadata = dataset['metadata']
                print("ì¶”ì¶œ íŒŒë¼ë¯¸í„°:", metadata['extraction_params'])
                print("ë°ì´í„° ì •ë³´:", metadata['data_info'])

                # ìƒ˜í”Œ ì •ë³´
                train_info = dataset['train_info']  # ê° ìƒ˜í”Œì˜ ìƒì„¸ ì •ë³´
                val_info = dataset['val_info']      # ê° ìƒ˜í”Œì˜ ìƒì„¸ ì •ë³´

                print(f"í›ˆë ¨ ìƒ˜í”Œ: {{train_inputs.shape[0]:,}}ê°œ")
                print(f"ê²€ì¦ ìƒ˜í”Œ: {{val_inputs.shape[0]:,}}ê°œ")
                print(f"ì…ë ¥ í˜•íƒœ: {{train_inputs.shape}}")
                print(f"ì¶œë ¥ í˜•íƒœ: {{train_outputs.shape}}")

                # PyTorchì—ì„œ ì‚¬ìš© ì˜ˆì‹œ
                # import torch
                # train_dataset = torch.utils.data.TensorDataset(
                #     torch.FloatTensor(train_inputs), 
                #     torch.FloatTensor(train_outputs)
                # )

                # ê°œë³„ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ì‹¶ì€ ê²½ìš°
                # np.save('train_inputs.npy', train_inputs)
                # np.save('train_outputs.npy', train_outputs)
                # np.save('val_inputs.npy', val_inputs)
                # np.save('val_outputs.npy', val_outputs)
                # np.save('metadata.npy', metadata)
                """, language="python")
                        
                    except Exception as e:
                        st.error(f"âŒ ë°ì´í„°ì…‹ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                

                # ë°ì´í„° ì‹œê°í™” ì˜µì…˜ (ìˆ˜ì •ëœ ë¶€ë¶„)
                with st.expander("ğŸ“ˆ ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                    if len(dataset['train_inputs']) > 0:
                        sample_idx = st.selectbox(
                            "ë¯¸ë¦¬ë³¼ ìƒ˜í”Œ ì„ íƒ",
                            range(min(10, len(dataset['train_inputs']))),
                            key="sample_preview_idx"
                        )
                        
                        # ì „ì²´ íŠ¹ì§• ìˆ˜ í™•ì¸
                        total_features = dataset['train_inputs'].shape[2]
                        
                        # ë©”íƒ€ë°ì´í„°ì—ì„œ íŠ¹ì§• ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                        feature_names = []
                        if 'feature_info' in metadata:
                            time_feature_names = metadata['feature_info'].get('time_feature_names', [])
                            data_feature_names = metadata['feature_info'].get('data_feature_names', [])
                            feature_names = time_feature_names + data_feature_names
                        
                        # íŠ¹ì§• ì´ë¦„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì´ë¦„ ì‚¬ìš©
                        if len(feature_names) != total_features:
                            feature_names = [f"Feature {i+1}" for i in range(total_features)]
                        
                        # ì‹œê°í™”í•  íŠ¹ì§• ì„ íƒ (ìµœëŒ€ 10ê°œ)
                        max_features_to_show = min(10, total_features)
                        selected_feature_indices = st.multiselect(
                            f"ì‹œê°í™”í•  íŠ¹ì§• ì„ íƒ (ì „ì²´ {total_features}ê°œ ì¤‘ ìµœëŒ€ {max_features_to_show}ê°œ)",
                            range(total_features),
                            default=list(range(min(5, total_features))),  # ê¸°ë³¸ê°’: ì²˜ìŒ 5ê°œ íŠ¹ì§•
                            format_func=lambda x: f"{x+1}: {feature_names[x]}" if x < len(feature_names) else f"Feature {x+1}",
                            key="preview_feature_selection"
                        )
                        
                        if selected_feature_indices:
                            # ì„ íƒëœ íŠ¹ì§•ì´ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì œí•œ
                            if len(selected_feature_indices) > max_features_to_show:
                                st.warning(f"âš ï¸ ìµœëŒ€ {max_features_to_show}ê°œ íŠ¹ì§•ë§Œ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì²˜ìŒ {max_features_to_show}ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
                                selected_feature_indices = selected_feature_indices[:max_features_to_show]
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**ì…ë ¥ ì‹œí€€ìŠ¤ (Input)**")
                                input_sample = dataset['train_inputs'][sample_idx]
                                st.write(f"í˜•íƒœ: {input_sample.shape}")
                                
                                # ì…ë ¥ ë°ì´í„° ì‹œê°í™” (ì„ íƒëœ íŠ¹ì§•ë§Œ)
                                fig_input = go.Figure()
                                for i, feature_idx in enumerate(selected_feature_indices):
                                    feature_name = feature_names[feature_idx] if feature_idx < len(feature_names) else f'Feature {feature_idx+1}'
                                    fig_input.add_trace(go.Scatter(
                                        y=input_sample[:, feature_idx],
                                        mode='lines+markers',
                                        name=feature_name,
                                        line=dict(width=2)
                                    ))
                                
                                fig_input.update_layout(
                                    title=f"ì…ë ¥ ì‹œí€€ìŠ¤ (ì„ íƒëœ {len(selected_feature_indices)}ê°œ íŠ¹ì§•)",
                                    xaxis_title="Time Steps",
                                    yaxis_title="Feature Values",
                                    height=300
                                )
                                st.plotly_chart(fig_input, use_container_width=True)
                            
                            with col2:
                                st.markdown("**ì¶œë ¥ ì‹œí€€ìŠ¤ (Target)**")
                                output_sample = dataset['train_outputs'][sample_idx]
                                st.write(f"í˜•íƒœ: {output_sample.shape}")
                                
                                # ì¶œë ¥ ë°ì´í„° ì‹œê°í™” (ì„ íƒëœ íŠ¹ì§•ë§Œ)
                                fig_output = go.Figure()
                                for i, feature_idx in enumerate(selected_feature_indices):
                                    feature_name = feature_names[feature_idx] if feature_idx < len(feature_names) else f'Feature {feature_idx+1}'
                                    fig_output.add_trace(go.Scatter(
                                        y=output_sample[:, feature_idx],
                                        mode='lines+markers',
                                        name=feature_name,
                                        line=dict(width=2)
                                    ))
                                
                                fig_output.update_layout(
                                    title=f"ì¶œë ¥ ì‹œí€€ìŠ¤ (ì„ íƒëœ {len(selected_feature_indices)}ê°œ íŠ¹ì§•)",
                                    xaxis_title="Time Steps", 
                                    yaxis_title="Feature Values",
                                    height=300
                                )
                                st.plotly_chart(fig_output, use_container_width=True)
                            
                            # ìƒ˜í”Œ ì •ë³´ í‘œì‹œ
                            sample_info = dataset['train_info'][sample_idx]
                            st.json(sample_info)
                            
                            # ì„ íƒëœ íŠ¹ì§•ë“¤ì˜ í†µê³„ ì •ë³´ (expander ì œê±°)
                            st.markdown("**ğŸ“Š ì„ íƒëœ íŠ¹ì§•ë“¤ì˜ í†µê³„ ì •ë³´**")
                            stats_data = []
                            for feature_idx in selected_feature_indices:
                                input_feature_data = input_sample[:, feature_idx]
                                output_feature_data = output_sample[:, feature_idx]
                                feature_name = feature_names[feature_idx] if feature_idx < len(feature_names) else f'Feature {feature_idx+1}'
                                
                                stats_data.append({
                                    'íŠ¹ì§•': feature_name,
                                    'ì…ë ¥ í‰ê· ': f"{input_feature_data.mean():.4f}",
                                    'ì…ë ¥ í‘œì¤€í¸ì°¨': f"{input_feature_data.std():.4f}",
                                    'ì¶œë ¥ í‰ê· ': f"{output_feature_data.mean():.4f}",
                                    'ì¶œë ¥ í‘œì¤€í¸ì°¨': f"{output_feature_data.std():.4f}",
                                    'ì…ë ¥ ë²”ìœ„': f"{input_feature_data.min():.4f} ~ {input_feature_data.max():.4f}",
                                    'ì¶œë ¥ ë²”ìœ„': f"{output_feature_data.min():.4f} ~ {output_feature_data.max():.4f}"
                                })
                            
                            stats_df = pd.DataFrame(stats_data)
                            st.dataframe(stats_df, use_container_width=True)
                            
                            # ë©”íƒ€ë°ì´í„° ì •ë³´ í‘œì‹œ (ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„)
                            st.markdown("---")
                            st.markdown("**ğŸ“‹ ë°ì´í„°ì…‹ ë©”íƒ€ë°ì´í„° ì •ë³´**")
                            
                            # ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬
                            meta_col1, meta_col2 = st.columns(2)
                            
                            with meta_col1:
                                st.markdown("**ğŸ”§ ì¶”ì¶œ íŒŒë¼ë¯¸í„°**")
                                extraction_params = metadata.get('extraction_params', {})
                                param_df = pd.DataFrame([
                                    {'íŒŒë¼ë¯¸í„°': 'ì‹œì‘ ìœ„ì¹˜', 'ê°’': f"{extraction_params.get('start_position', 'N/A'):,}"},
                                    {'íŒŒë¼ë¯¸í„°': 'ì¢…ë£Œ ìœ„ì¹˜', 'ê°’': f"{extraction_params.get('end_position', 'N/A'):,}"},
                                    {'íŒŒë¼ë¯¸í„°': 'ê³¼ê±° ì°¸ì¡° ê¸¸ì´', 'ê°’': str(extraction_params.get('lookback_length', 'N/A'))},
                                    {'íŒŒë¼ë¯¸í„°': 'ì˜ˆì¸¡ êµ¬ê°„ ê¸¸ì´', 'ê°’': str(extraction_params.get('horizon_length', 'N/A'))},
                                    {'íŒŒë¼ë¯¸í„°': 'ìŠ¤í… ê°„ê²©', 'ê°’': str(extraction_params.get('step_gap', 'N/A'))},
                                    {'íŒŒë¼ë¯¸í„°': 'í›ˆë ¨ ë¹„ìœ¨', 'ê°’': f"{extraction_params.get('train_ratio', 0):.1%}"},
                                    {'íŒŒë¼ë¯¸í„°': 'Positional Encoding', 'ê°’': 'ì‚¬ìš©' if extraction_params.get('use_positional_encoding', False) else 'ë¯¸ì‚¬ìš©'},
                                    {'íŒŒë¼ë¯¸í„°': 'í‹± ê°„ê²©', 'ê°’': f"{extraction_params.get('tick_interval', 'N/A')}ì´ˆ"}
                                ])
                                st.dataframe(param_df, use_container_width=True, hide_index=True)
                            
                            with meta_col2:
                                st.markdown("**ğŸ“Š ë°ì´í„° ì •ë³´**")
                                data_info = metadata.get('data_info', {})
                                feature_info = metadata.get('feature_info', {})
                                info_df = pd.DataFrame([
                                    {'í•­ëª©': 'í›ˆë ¨ ìƒ˜í”Œ ìˆ˜', 'ê°’': f"{data_info.get('train_samples', 0):,}"},
                                    {'í•­ëª©': 'ê²€ì¦ ìƒ˜í”Œ ìˆ˜', 'ê°’': f"{data_info.get('val_samples', 0):,}"},
                                    {'í•­ëª©': 'ì…ë ¥ í˜•íƒœ', 'ê°’': str(data_info.get('input_shape', 'N/A'))},
                                    {'í•­ëª©': 'ì¶œë ¥ í˜•íƒœ', 'ê°’': str(data_info.get('output_shape', 'N/A'))},
                                    {'í•­ëª©': 'ì‹œê°„ íŠ¹ì§• ìˆ˜', 'ê°’': str(feature_info.get('time_features', 'N/A'))},
                                    {'í•­ëª©': 'ë°ì´í„° íŠ¹ì§• ìˆ˜', 'ê°’': str(feature_info.get('data_features', 'N/A'))},
                                    {'í•­ëª©': 'ì „ì²´ íŠ¹ì§• ìˆ˜', 'ê°’': str(feature_info.get('total_features', 'N/A'))},
                                    {'í•­ëª©': 'ìƒì„± ì‹œê°„', 'ê°’': metadata.get('creation_time', 'N/A')[:19] if metadata.get('creation_time') else 'N/A'}
                                ])
                                st.dataframe(info_df, use_container_width=True, hide_index=True)
                            
                            # íŠ¹ì§• ì´ë¦„ ë§¤í•‘ í‘œì‹œ
                            if 'feature_info' in metadata and len(feature_names) == total_features:
                                st.markdown("**ğŸ·ï¸ íŠ¹ì§• ì´ë¦„ ë§¤í•‘**")
                                
                                # ì‹œê°„ íŠ¹ì§•ê³¼ ë°ì´í„° íŠ¹ì§•ì„ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ
                                time_features_count = metadata['feature_info'].get('time_features', 0)
                                
                                feature_mapping = []
                                for i, name in enumerate(feature_names):
                                    feature_type = "ì‹œê°„ íŠ¹ì§•" if i < time_features_count else "ë°ì´í„° íŠ¹ì§•"
                                    feature_mapping.append({
                                        'ì¸ë±ìŠ¤': i,
                                        'íŠ¹ì§•ëª…': name,
                                        'íƒ€ì…': feature_type
                                    })
                                
                                mapping_df = pd.DataFrame(feature_mapping)
                                st.dataframe(mapping_df, use_container_width=True, hide_index=True)
                            
                            # íŒŒì¼ ì •ë³´
                            if 'data_info' in metadata:
                                train_files = metadata['data_info'].get('train_files', [])
                                val_files = metadata['data_info'].get('val_files', [])
                                
                                if train_files or val_files:
                                    st.markdown("**ğŸ“ ì‚¬ìš©ëœ íŒŒì¼ ì •ë³´**")
                                    file_col1, file_col2 = st.columns(2)
                                    
                                    with file_col1:
                                        if train_files:
                                            st.markdown("*í›ˆë ¨ìš© íŒŒì¼:*")
                                            for i, file_name in enumerate(train_files, 1):
                                                st.write(f"{i}. {file_name}")
                                    
                                    with file_col2:
                                        if val_files:
                                            st.markdown("*ê²€ì¦ìš© íŒŒì¼:*")
                                            for i, file_name in enumerate(val_files, 1):
                                                st.write(f"{i}. {file_name}")
                        
                        else:
                            st.info("ğŸ¯ ì‹œê°í™”í•  íŠ¹ì§•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        st.info("ğŸ“Š ì¶”ì¶œëœ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


        

    # =================================================================================
    # íƒ­ 4: ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
    # =================================================================================
    with tab4:
        st.header("ğŸ¯ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰")
        st.markdown("ê¸°ì¤€ íŒŒì¼ì˜ íŠ¹ì • ì˜¨ë„ ì¡°ê±´ê³¼ ìœ ì‚¬í•œ ê¸°ë™ íŒ¨í„´ì„ ë‹¤ë¥¸ íŒŒì¼ë“¤ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

        # ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ (íƒ­3ê³¼ ë™ì¼)
        st.subheader("ğŸ“ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ")
        col1, col2 = st.columns([3, 1])

        with col1:
            st.markdown("**ì—¬ëŸ¬ ê°œì˜ FTR/Feather ë˜ëŠ” H5 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:**")
            search_uploaded_files = st.file_uploader(
                "ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰í•  FTR/Feather ë˜ëŠ” H5 íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                type=['ftr', 'feather', 'h5', 'hdf5'],
                accept_multiple_files=True,
                key="search_file_uploader"
            )
        
        with col2:
            if search_uploaded_files:
                if st.button("ğŸ“¤ ê²€ìƒ‰ìš© íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬", key="search_upload_btn"):
                    st.session_state.search_uploaded_files = search_uploaded_files
                    st.success(f"âœ… {len(search_uploaded_files)}ê°œ íŒŒì¼ì´ ê²€ìƒ‰ìš©ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ê²€ìƒ‰ìš© íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ê²€ìƒ‰ ì‹œì‘
        if 'search_uploaded_files' in st.session_state and st.session_state.search_uploaded_files:
            search_files = st.session_state.search_uploaded_files
            
            st.success(f"âœ… {len(search_files)}ê°œ íŒŒì¼ì´ ê²€ìƒ‰ìš©ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ íŠ¹ì§• ëª©ë¡ í™•ì¸
            first_file = search_files[0]
            reference_df = load_feather_file(first_file)
            
            if reference_df is not None:
                st.subheader("ğŸ“Š ê¸°ì¤€ íŒŒì¼ ì •ë³´")
                st.info(f"**ê¸°ì¤€ íŒŒì¼**: {first_file.name} (Shape: {reference_df.shape})")
                
                # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
                with st.expander("ğŸ“‹ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡"):
                    for i, file in enumerate(search_files):
                        try:
                            temp_df = load_feather_file(file)
                            if temp_df is not None:
                                st.write(f"{i+1}. **{file.name}** - Shape: {temp_df.shape}")
                            else:
                                st.write(f"{i+1}. **{file.name}** - âŒ ë¡œë“œ ì‹¤íŒ¨")
                        except:
                            st.write(f"{i+1}. **{file.name}** - âŒ ë¡œë“œ ì‹¤íŒ¨")
                
                # ê¸°ì¤€ íŒŒì¼ ì„ íƒ
                st.subheader("ğŸ“‚ ê¸°ì¤€ íŒŒì¼ ì„ íƒ")
                file_names = [f.name for f in search_files]
                selected_reference_file_index = st.selectbox(
                    "ê¸°ì¤€ì´ ë  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
                    range(len(search_files)),
                    format_func=lambda x: file_names[x],
                    index=0,  # ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ íŒŒì¼
                    key="reference_file_selection",
                    help="ì„ íƒëœ íŒŒì¼ì˜ tic=80 ì˜¨ë„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ëª¨ë“  íŒŒì¼ê³¼ ë¹„êµí•©ë‹ˆë‹¤."
                )
                
                # ê¸°ì¤€ íŒŒì¼ê³¼ ê²€ìƒ‰ ëŒ€ìƒ íŒŒì¼ë“¤ ì„¤ì •
                reference_file = search_files[selected_reference_file_index]
                search_target_files = [f for i, f in enumerate(search_files) if i != selected_reference_file_index]
                
                if len(search_target_files) >= 1:  # ìµœì†Œ 1ê°œ ì´ìƒì˜ ê²€ìƒ‰ ëŒ€ìƒ íŒŒì¼ í•„ìš”
                    
                    st.subheader("ğŸ¯ ê¸°ì¤€ ì˜¨ë„ ì¡°ê±´ ì„¤ì •")
                    st.info(f"ğŸ¯ **ê¸°ì¤€ íŒŒì¼**: {reference_file.name}")
                    st.info(f"ğŸ” **ê²€ìƒ‰ ëŒ€ìƒ**: {len(search_target_files)}ê°œ íŒŒì¼ (ê¸°ì¤€ íŒŒì¼ ì œì™¸í•œ ëª¨ë“  íŒŒì¼)")
                    
                    # ê¸°ì¤€ íŒŒì¼ ë¡œë“œ
                    ref_df = load_feather_file(reference_file)
                    
                    if ref_df is not None:
                        # í•„ìš”í•œ ì˜¨ë„ íŠ¹ì§•ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                        required_features = ['metal_temp_1st', 'scr_outlet_temp', 'exhaust_gas_temperature']
                        missing_features = [feat for feat in required_features if feat not in ref_df.columns]
                        
                        if missing_features:
                            st.error(f"âŒ ê¸°ì¤€ íŒŒì¼ì—ì„œ í•„ìš”í•œ íŠ¹ì§•ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_features}")
                            st.write(f"**ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼**: {list(ref_df.columns)}")
                        else:
                            # tic=80ì—ì„œ ì˜¨ë„ê°’ ì¶”ì¶œ
                            if len(ref_df) > 80:
                                reference_temps = {
                                    'metal_temp_1st': ref_df.loc[80, 'metal_temp_1st'],
                                    'scr_outlet_temp': ref_df.loc[80, 'scr_outlet_temp'],
                                    'exhaust_gas_temperature': ref_df.loc[80, 'exhaust_gas_temperature']
                                }
                                
                                # ê¸°ì¤€ ì˜¨ë„ê°’ í‘œì‹œ
                                st.subheader("ğŸŒ¡ï¸ ê¸°ì¤€ ì˜¨ë„ê°’ (tic=80)")
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.metric("Metal Temp 1st", f"{reference_temps['metal_temp_1st']:.2f}Â°C")
                                with col2:
                                    st.metric("SCR Outlet Temp", f"{reference_temps['scr_outlet_temp']:.2f}Â°C")
                                with col3:
                                    st.metric("Exhaust Gas Temp", f"{reference_temps['exhaust_gas_temperature']:.2f}Â°C")
                                
                                # ê°€ì¤‘ì¹˜ ì„¤ì •
                                st.subheader("âš–ï¸ ì˜¨ë„ë³„ ê°€ì¤‘ì¹˜ ì„¤ì •")
                                st.markdown("ê° ì˜¨ë„ íŠ¹ì§•ì˜ ì¤‘ìš”ë„ë¥¼ ì„¤ì •í•˜ì„¸ìš”. ë†’ì€ ê°’ì¼ìˆ˜ë¡ í•´ë‹¹ ì˜¨ë„ì˜ ìœ ì‚¬ì„±ì´ ë” ì¤‘ìš”í•˜ê²Œ ê³ ë ¤ë©ë‹ˆë‹¤.")
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    weight_metal = st.slider(
                                        "Metal Temp 1st ê°€ì¤‘ì¹˜",
                                        min_value=0.0,
                                        max_value=2.0,
                                        value=1.0,
                                        step=0.1,
                                        key="weight_metal"
                                    )
                                with col2:
                                    weight_scr = st.slider(
                                        "SCR Outlet Temp ê°€ì¤‘ì¹˜",
                                        min_value=0.0,
                                        max_value=2.0,
                                        value=1.0,
                                        step=0.1,
                                        key="weight_scr"
                                    )
                                with col3:
                                    weight_exhaust = st.slider(
                                        "Exhaust Gas Temp ê°€ì¤‘ì¹˜",
                                        min_value=0.0,
                                        max_value=2.0,
                                        value=1.0,
                                        step=0.1,
                                        key="weight_exhaust"
                                    )
                                
                                # ê°€ì¤‘ì¹˜ ì •ê·œí™” ì˜µì…˜
                                normalize_weights = st.checkbox(
                                    "ê°€ì¤‘ì¹˜ ì •ê·œí™”",
                                    value=True,
                                    help="ê°€ì¤‘ì¹˜ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”í•©ë‹ˆë‹¤."
                                )
                                
                                # ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ ì‹¤í–‰
                                st.subheader("ğŸ” ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰")
                                
                                if st.button("ğŸš€ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ ì‹œì‘", key="start_similarity_search"):
                                    with st.spinner("ğŸ”„ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                                        try:
                                            # ê°€ì¤‘ì¹˜ ì„¤ì •
                                            weights = np.array([weight_metal, weight_scr, weight_exhaust])
                                            if normalize_weights and weights.sum() > 0:
                                                weights = weights / weights.sum()
                                            
                                            # ê¸°ì¤€ ì˜¨ë„ ë²¡í„°
                                            reference_vector = np.array([
                                                reference_temps['metal_temp_1st'],
                                                reference_temps['scr_outlet_temp'],
                                                reference_temps['exhaust_gas_temperature']
                                            ])
                                            
                                            # ê° íŒŒì¼ì—ì„œ tic=80ì˜ ì˜¨ë„ê°’ ì¶”ì¶œ ë° ê±°ë¦¬ ê³„ì‚°
                                            similarity_results = []
                                            
                                            for target_file in search_target_files:
                                                try:
                                                    target_df = load_feather_file(target_file)
                                                    if target_df is not None and len(target_df) > 80:
                                                        # í•„ìš”í•œ íŠ¹ì§•ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                                                        target_missing = [feat for feat in required_features if feat not in target_df.columns]
                                                        if not target_missing:
                                                            # tic=80ì—ì„œ ì˜¨ë„ê°’ ì¶”ì¶œ
                                                            target_temps = np.array([
                                                                target_df.loc[80, 'metal_temp_1st'],
                                                                target_df.loc[80, 'scr_outlet_temp'],
                                                                target_df.loc[80, 'exhaust_gas_temperature']
                                                            ])
                                                            
                                                            # ê°€ì¤‘ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                                                            weighted_diff = weights * (reference_vector - target_temps)
                                                            euclidean_distance = np.sqrt(np.sum(weighted_diff ** 2))
                                                            
                                                            similarity_results.append({
                                                                'file_name': target_file.name,
                                                                'distance': euclidean_distance,
                                                                'metal_temp_1st': target_temps[0],
                                                                'scr_outlet_temp': target_temps[1],
                                                                'exhaust_gas_temperature': target_temps[2],
                                                                'file_object': target_file
                                                            })
                                                        else:
                                                            st.warning(f"âš ï¸ {target_file.name}ì—ì„œ ëˆ„ë½ëœ íŠ¹ì§•: {target_missing}")
                                                    else:
                                                        st.warning(f"âš ï¸ {target_file.name}: ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (tic=80 ì´ìƒ í•„ìš”)")
                                                        
                                                except Exception as e:
                                                    st.warning(f"âš ï¸ {target_file.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                            
                                            # ê±°ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 5ê°œ ì„ íƒ
                                            if similarity_results:
                                                similarity_results.sort(key=lambda x: x['distance'])
                                                top_5_similar = similarity_results[:5]
                                                
                                                # ê²°ê³¼ ì €ì¥
                                                st.session_state.similarity_results = similarity_results
                                                st.session_state.top_5_similar = top_5_similar
                                                st.session_state.reference_temps = reference_temps
                                                st.session_state.search_weights = weights
                                                st.session_state.search_completed = True
                                                
                                            else:
                                                st.error("âŒ ê²€ìƒ‰ ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                                                
                                        except Exception as e:
                                            st.error(f"âŒ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                
                                # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                                if (hasattr(st.session_state, 'search_completed') and 
                                    st.session_state.search_completed and 
                                    hasattr(st.session_state, 'top_5_similar')):
                                    
                                    st.markdown("---")
                                    st.subheader("ğŸ† ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ ê²°ê³¼")
                                    
                                    top_5_similar = st.session_state.top_5_similar
                                    reference_temps = st.session_state.reference_temps
                                    search_weights = st.session_state.search_weights
                                    
                                    if top_5_similar:
                                        # ê²€ìƒ‰ ì„¤ì • ìš”ì•½
                                        st.info(f"ğŸ¯ **ê¸°ì¤€ íŒŒì¼**: {reference_file.name} | **ê°€ì¤‘ì¹˜**: Metal({search_weights[0]:.1f}), SCR({search_weights[1]:.1f}), Exhaust({search_weights[2]:.1f})")
                                        
                                        # ìƒìœ„ 5ê°œ ê²°ê³¼ í‘œì‹œ
                                        st.markdown("### ğŸ¥‡ ê°€ì¥ ìœ ì‚¬í•œ ê¸°ë™ TOP 5")
                                        
                                        for i, result in enumerate(top_5_similar, 1):
                                            with st.expander(f"ğŸ… {i}ìœ„: {result['file_name']} (ê±°ë¦¬: {result['distance']:.4f})"):
                                                col1, col2 = st.columns(2)
                                                
                                                with col1:
                                                    st.markdown("**ğŸŒ¡ï¸ ì˜¨ë„ ë¹„êµ**")
                                                    comparison_data = {
                                                        'íŠ¹ì§•': ['Metal Temp 1st', 'SCR Outlet Temp', 'Exhaust Gas Temp'],
                                                        'ê¸°ì¤€ê°’': [
                                                            f"{reference_temps['metal_temp_1st']:.2f}Â°C",
                                                            f"{reference_temps['scr_outlet_temp']:.2f}Â°C",
                                                            f"{reference_temps['exhaust_gas_temperature']:.2f}Â°C"
                                                        ],
                                                        'ë¹„êµê°’': [
                                                            f"{result['metal_temp_1st']:.2f}Â°C",
                                                            f"{result['scr_outlet_temp']:.2f}Â°C",
                                                            f"{result['exhaust_gas_temperature']:.2f}Â°C"
                                                        ],
                                                        'ì°¨ì´': [
                                                            f"{abs(reference_temps['metal_temp_1st'] - result['metal_temp_1st']):.2f}Â°C",
                                                            f"{abs(reference_temps['scr_outlet_temp'] - result['scr_outlet_temp']):.2f}Â°C",
                                                            f"{abs(reference_temps['exhaust_gas_temperature'] - result['exhaust_gas_temperature']):.2f}Â°C"
                                                        ]
                                                    }
                                                    
                                                    comparison_df = pd.DataFrame(comparison_data)
                                                    st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                                                
                                                with col2:
                                                    st.markdown("**ğŸ“Š ìƒì„¸ ì •ë³´**")
                                                    st.write(f"**íŒŒì¼ëª…**: {result['file_name']}")
                                                    st.write(f"**ìœ í´ë¦¬ë“œ ê±°ë¦¬**: {result['distance']:.6f}")
                                                    st.write(f"**ìˆœìœ„**: {i}/5")
                                                    
                                                    # ê° ì˜¨ë„ë³„ ê°€ì¤‘ ê¸°ì—¬ë„
                                                    metal_contrib = search_weights[0] * abs(reference_temps['metal_temp_1st'] - result['metal_temp_1st'])
                                                    scr_contrib = search_weights[1] * abs(reference_temps['scr_outlet_temp'] - result['scr_outlet_temp'])
                                                    exhaust_contrib = search_weights[2] * abs(reference_temps['exhaust_gas_temperature'] - result['exhaust_gas_temperature'])
                                                    
                                                    st.write("**ê°€ì¤‘ ê¸°ì—¬ë„**:")
                                                    st.write(f"- Metal: {metal_contrib:.4f}")
                                                    st.write(f"- SCR: {scr_contrib:.4f}")
                                                    st.write(f"- Exhaust: {exhaust_contrib:.4f}")
                                        
                                        # ì „ì²´ ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”
                                        st.markdown("### ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
                                        
                                        summary_data = []
                                        for i, result in enumerate(top_5_similar, 1):
                                            summary_data.append({
                                                'ìˆœìœ„': i,
                                                'íŒŒì¼ëª…': result['file_name'],
                                                'ìœ í´ë¦¬ë“œ ê±°ë¦¬': f"{result['distance']:.6f}",
                                                'Metal Temp': f"{result['metal_temp_1st']:.2f}Â°C",
                                                'SCR Temp': f"{result['scr_outlet_temp']:.2f}Â°C",
                                                'Exhaust Temp': f"{result['exhaust_gas_temperature']:.2f}Â°C"
                                            })
                                        
                                        summary_df = pd.DataFrame(summary_data)
                                        st.dataframe(summary_df, use_container_width=True, hide_index=True)
                                        
                                        # ì‹œê°í™” ë¹„êµ ê¸°ëŠ¥ ì¶”ê°€
                                        st.markdown("### ğŸ“ˆ ì‹œê³„ì—´ ë°ì´í„° ë¹„êµ ì‹œê°í™”")
                                        
                                        # ê¸°ì¤€ íŒŒì¼ê³¼ ë¹„êµí•  íŒŒì¼ë“¤ ì„ íƒ
                                        st.markdown("**ê¸°ì¤€ íŒŒì¼ê³¼ ê²€ìƒ‰ ê²°ê³¼ íŒŒì¼ë“¤ì˜ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”:**")
                                        
                                        # ë¹„êµí•  íŒŒì¼ë“¤ ì„ íƒ (ê¸°ì¤€ íŒŒì¼ + TOP 5 ê²°ê³¼)
                                        available_files_for_plot = [reference_file] + [r['file_object'] for r in top_5_similar]
                                        available_file_names = [f"ğŸ¯ {reference_file.name} (ê¸°ì¤€)"] + [f"ğŸ… {i+1}ìœ„: {r['file_name']}" for i, r in enumerate(top_5_similar)]
                                        
                                        selected_plot_file_indices = st.multiselect(
                                            "ë¹„êµ ì‹œê°í™”í•  íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                                            range(len(available_files_for_plot)),
                                            format_func=lambda x: available_file_names[x],
                                            default=[0, 1] if len(available_files_for_plot) > 1 else [0],  # ê¸°ë³¸ê°’: ê¸°ì¤€ íŒŒì¼ + 1ìœ„
                                            key="similarity_plot_file_selection",
                                            help="ì„ íƒëœ íŒŒì¼ë“¤ì˜ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ í•¨ê»˜ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                                        )
                                        
                                        selected_plot_files = [available_files_for_plot[i] for i in selected_plot_file_indices]
                                        
                                        if len(selected_plot_files) >= 1:
                                            # íŠ¹ì§• ì„ íƒ (ê¸°ì¤€ íŒŒì¼ ê¸°ì¤€)
                                            ref_df_for_plot = load_feather_file(reference_file)
                                            if ref_df_for_plot is not None:
                                                selected_plot_features = st.multiselect(
                                                    "ë¹„êµí•  íŠ¹ì§•ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                                                    ref_df_for_plot.columns.tolist(),
                                                    default=['metal_temp_1st', 'scr_outlet_temp', 'exhaust_gas_temperature'] if all(feat in ref_df_for_plot.columns for feat in ['metal_temp_1st', 'scr_outlet_temp', 'exhaust_gas_temperature']) else ref_df_for_plot.columns.tolist()[:3],
                                                    key="similarity_feature_selection",
                                                    help="ì„ íƒëœ íŠ¹ì§•ë“¤ì„ ê° íŒŒì¼ë³„ë¡œ ë¹„êµí•©ë‹ˆë‹¤."
                                                )
                                                
                                                if selected_plot_features:
                                                    # ì‹œê°í™” ì„¤ì • (íƒ­3ê³¼ ë™ì¼í•œ êµ¬ì¡°)
                                                    st.markdown("**âš™ï¸ ì‹œê°í™” ì„¤ì •**")
                                                    
                                                    col1, col2, col3 = st.columns(3)
                                                    with col1:
                                                        similarity_downsample_rate = st.slider(
                                                            "ğŸ“‰ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ (1/N)", 
                                                            min_value=1, max_value=100, value=10,
                                                            key="similarity_downsample"
                                                        )
                                                    with col2:
                                                        similarity_num_segments = st.selectbox(
                                                            "ğŸ“Š ë°ì´í„° ë¶„í•  ìˆ˜",
                                                            options=[1, 2, 3, 4, 5],
                                                            index=2,  # ê¸°ë³¸ê°’: 3ë“±ë¶„
                                                            help="ì „ì²´ ë°ì´í„°ë¥¼ ëª‡ ë“±ë¶„í• ì§€ ì„ íƒ",
                                                            key="similarity_segments"
                                                        )
                                                    with col3:
                                                        similarity_selected_segment = st.selectbox(
                                                            "ğŸ¯ ë¶„ì„ êµ¬ê°„ ì„ íƒ",
                                                            options=list(range(similarity_num_segments)),
                                                            format_func=lambda x: f"êµ¬ê°„ {x+1}",
                                                            index=0,  # ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ êµ¬ê°„
                                                            help="ë¶„ì„í•  êµ¬ê°„ì„ ì„ íƒ",
                                                            key="similarity_segment_select"
                                                        )
                                                    
                                                    similarity_crosshair = st.checkbox("â–¶ï¸ ì‹­ìì„  Hover í™œì„±í™”", value=True, key="similarity_crosshair")
                                                    
                                                    # ì‹œê³„ì—´ ë¹„êµ í”Œë¡¯ ìƒì„±
                                                    try:
                                                        fig_timeseries = create_multi_file_plot(
                                                            selected_plot_files,
                                                            selected_plot_features,
                                                            similarity_downsample_rate,
                                                            similarity_crosshair,
                                                            similarity_num_segments,
                                                            similarity_selected_segment
                                                        )
                                                        
                                                        # ì œëª© ìˆ˜ì •
                                                        segment_info = f"êµ¬ê°„ {similarity_selected_segment + 1}/{similarity_num_segments}"
                                                        fig_timeseries.update_layout(title=f"ğŸ“Š ìœ ì‚¬ ê¸°ë™ ë¹„êµ ë¶„ì„ ({segment_info})")
                                                        
                                                        st.plotly_chart(fig_timeseries, use_container_width=True)
                                                        
                                                        # ë¹„êµ ì •ë³´ í‘œì‹œ
                                                        st.markdown("**ğŸ“‹ ë¹„êµ ì¤‘ì¸ íŒŒì¼:**")
                                                        for i, idx in enumerate(selected_plot_file_indices):
                                                            if idx == 0:
                                                                st.write(f"ğŸ¯ **ê¸°ì¤€**: {reference_file.name}")
                                                            else:
                                                                rank = idx  # 1ìœ„ë¶€í„° ì‹œì‘
                                                                result = top_5_similar[rank-1]
                                                                st.write(f"ğŸ… **{rank}ìœ„**: {result['file_name']} (ê±°ë¦¬: {result['distance']:.4f})")
                                                        
                                                    except Exception as e:
                                                        st.error(f"âŒ ì‹œê³„ì—´ ë¹„êµ í”Œë¡¯ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                                else:
                                                    st.info("ğŸ¯ ë¹„êµí•  íŠ¹ì§•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                                            else:
                                                st.error("âŒ ê¸°ì¤€ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                        else:
                                            st.info("ğŸ“‚ ë¹„êµí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                                        
                                        # ìƒì„¸ ë¶„ì„ ì •ë³´
                                        with st.expander("ğŸ“Š ìƒì„¸ ë¶„ì„ ì •ë³´"):
                                            st.markdown("**ğŸ” ê²€ìƒ‰ í†µê³„**")
                                            all_results = st.session_state.similarity_results
                                            
                                            stats_col1, stats_col2, stats_col3 = st.columns(3)
                                            with stats_col1:
                                                st.metric("ê²€ìƒ‰ëœ íŒŒì¼ ìˆ˜", len(all_results))
                                            with stats_col2:
                                                min_distance = min([r['distance'] for r in all_results])
                                                st.metric("ìµœì†Œ ê±°ë¦¬", f"{min_distance:.6f}")
                                            with stats_col3:
                                                max_distance = max([r['distance'] for r in all_results])
                                                st.metric("ìµœëŒ€ ê±°ë¦¬", f"{max_distance:.6f}")
                                            
                                            st.markdown("**ğŸ“‹ ì „ì²´ ê²€ìƒ‰ ê²°ê³¼**")
                                            full_results_data = []
                                            for i, result in enumerate(all_results, 1):
                                                full_results_data.append({
                                                    'ìˆœìœ„': i,
                                                    'íŒŒì¼ëª…': result['file_name'],
                                                    'ìœ í´ë¦¬ë“œ ê±°ë¦¬': f"{result['distance']:.6f}",
                                                    'Metal Temp': f"{result['metal_temp_1st']:.2f}Â°C",
                                                    'SCR Temp': f"{result['scr_outlet_temp']:.2f}Â°C",
                                                    'Exhaust Temp': f"{result['exhaust_gas_temperature']:.2f}Â°C"
                                                })
                                            
                                            full_results_df = pd.DataFrame(full_results_data)
                                            st.dataframe(full_results_df, use_container_width=True, hide_index=True)
                                    
                                    else:
                                        st.warning("âš ï¸ ìœ ì‚¬í•œ ê¸°ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.error("âŒ ê¸°ì¤€ íŒŒì¼ì˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. tic=80 ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        st.error("âŒ ê¸°ì¤€ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                else:
                    st.warning("âš ï¸ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. (ê¸°ì¤€ íŒŒì¼ 1ê°œ + ê²€ìƒ‰ ëŒ€ìƒ íŒŒì¼ 1ê°œ ì´ìƒ)")
                    st.info("í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ì´ 1ê°œë¿ì…ë‹ˆë‹¤. ì¶”ê°€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                st.error("âŒ ê¸°ì¤€ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ“ ìœ ì‚¬ ê¸°ë™ ê²€ìƒ‰ì„ ìœ„í•´ ë‹¤ì¤‘ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    



# =================================================================================
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# =================================================================================
if __name__ == "__main__":
    main()






