"""
ë°ì´í„° ë¡œë”© UI íƒ­
"""
import streamlit as st
import pandas as pd
import io
import tempfile
import os


def render_loading_tab():
    """ë°ì´í„° ë¡œë”© íƒ­ ë Œë”ë§"""
    st.header("ğŸ“‚ ë°ì´í„° ë¡œë”©")
    
    file_type = st.session_state.config['file_info']['file_type']
    
    # íŒŒì¼ ì—…ë¡œë”
    if file_type == 'csv':
        uploaded_files = st.file_uploader(
            "CSV íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
            type=['csv'],
            accept_multiple_files=True,
            key='csv_upload'
        )
    else:
        uploaded_files = st.file_uploader(
            "Excel íŒŒì¼ ì—…ë¡œë“œ",
            type=['xlsx', 'xls'],
            key='excel_upload'
        )
        if uploaded_files:
            uploaded_files = [uploaded_files]
    
    if uploaded_files:
        if len(uploaded_files) > 1:
            st.info(f"ğŸ“ {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")
            for i, f in enumerate(uploaded_files, 1):
                st.caption(f"{i}. {f.name}")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ ì‹œì‘", type="primary", use_container_width=True):
                progress_text = st.empty()
                progress_bar = st.empty()
                
                with st.spinner("ë°ì´í„°ë¥¼ ë¡œë”©í•˜ëŠ” ì¤‘..."):
                    try:
                        def update_progress(sheet_name, current, total):
                            progress_text.text(f"ì²˜ë¦¬ ì¤‘: {current}/{total} - {sheet_name}")
                            progress_bar.progress(current / total)
                        
                        # ë°ì´í„° ì„œë¹„ìŠ¤ ì‚¬ìš©
                        data_service = st.session_state.data_service
                        
                        all_data = {}
                        
                        for idx, uploaded_file in enumerate(uploaded_files, 1):
                            if len(uploaded_files) > 1:
                                progress_text.text(f"íŒŒì¼ {idx}/{len(uploaded_files)} ì²˜ë¦¬ ì¤‘: {uploaded_file.name}")
                                progress_bar.progress(idx / len(uploaded_files))
                            
                            # ë°ì´í„° ë¡œë“œ
                            data = data_service.load_data(
                                uploaded_file, 
                                st.session_state.config, 
                                file_type,
                                progress_callback=update_progress
                            )
                            
                            file_base_name = uploaded_file.name.rsplit('.', 1)[0]
                            
                            if isinstance(data, pd.DataFrame):
                                df_clean = data_service.prepare_for_display(data)
                                all_data[file_base_name] = df_clean
                            else:
                                for sheet_name, sheet_df in data.items():
                                    combined_name = f"{file_base_name}_{sheet_name}"
                                    df_clean = data_service.prepare_for_display(sheet_df)
                                    all_data[combined_name] = df_clean
                        
                        progress_text.empty()
                        progress_bar.empty()
                        
                        # session_stateì— ì €ì¥
                        if len(all_data) == 1:
                            final_df = list(all_data.values())[0]
                            st.session_state.loaded_data = final_df
                            
                            st.session_state.metadata = {
                                'source_name': final_df.attrs.get('source_name', 'unknown'),
                                'header_metadata': final_df.attrs.get('header_metadata', {}),
                                'shape': final_df.shape,
                                'columns': final_df.columns.tolist(),
                                'dtypes': {str(k): str(v) for k, v in final_df.dtypes.items()}
                            }
                        else:
                            st.session_state.loaded_data = all_data
                            
                            st.session_state.metadata = {
                                sheet: {
                                    'source_name': df.attrs.get('source_name', sheet),
                                    'header_metadata': df.attrs.get('header_metadata', {}),
                                    'shape': df.shape,
                                    'columns': df.columns.tolist(),
                                    'dtypes': {str(k): str(v) for k, v in df.dtypes.items()}
                                }
                                for sheet, df in all_data.items()
                            }
                        
                        st.success("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
                        
                        # ë©”íƒ€ë°ì´í„° ì •ë³´
                        if st.session_state.metadata:
                            header_meta = st.session_state.metadata.get('header_metadata', {})
                            if header_meta:
                                metadata_info = []
                                if 'description' in header_meta:
                                    metadata_info.append(f"âœ… Description: {len(header_meta['description'])}ê°œ")
                                if 'unit' in header_meta:
                                    metadata_info.append(f"âœ… Unit: {len(header_meta['unit'])}ê°œ")
                                if 'tag_name' in header_meta:
                                    metadata_info.append(f"âœ… Tag_name: {len(header_meta['tag_name'])}ê°œ")
                                
                                if metadata_info:
                                    st.info("ğŸ“‹ **ë©”íƒ€ë°ì´í„° ë°œê²¬:**\n" + "\n".join(metadata_info))
                        
                        st.rerun()
                    
                    except Exception as e:
                        st.error(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
        
        with col2:
            if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", use_container_width=True):
                keys_to_remove = ['loaded_data', 'metadata']
                for key in keys_to_remove:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
    
    # ë¡œë“œëœ ë°ì´í„° í‘œì‹œ
    if st.session_state.loaded_data is not None:
        st.divider()
        st.subheader("ğŸ“Š ë¡œë“œëœ ë°ì´í„°")
        
        data = st.session_state.loaded_data
        
        # ë‹¨ì¼ DataFrame
        if isinstance(data, pd.DataFrame):
            st.markdown(f"**Shape:** {data.shape[0]:,} rows Ã— {data.shape[1]:,} columns")
            
            with st.expander("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                n_rows = st.slider("í‘œì‹œí•  í–‰ ìˆ˜", 5, 100, 10, key='single_preview_rows')
                
                # PyArrow í˜¸í™˜ì„ ìœ„í•œ ì•ˆì „í•œ í‘œì‹œ
                preview_df = data.head(n_rows).copy()
                for col in preview_df.columns:
                    if preview_df[col].dtype == 'object':
                        preview_df[col] = preview_df[col].astype(str).replace('nan', '').replace('None', '')
                
                # st.dataframe(preview_df, use_container_width=True)  #width='stretch
                st.dataframe(preview_df, width='stretch')  #
            
            if st.session_state.metadata:
                with st.expander("â„¹ï¸ ë©”íƒ€ë°ì´í„°"):
                    meta = st.session_state.metadata
                    if 'header_metadata' in meta and meta['header_metadata']:
                        st.json(meta['header_metadata'])
            
            with st.expander("ğŸ“ˆ ê¸°ë³¸ í†µê³„"):
                stats_df = data.describe(include='all').reset_index()
                
                # PyArrow í˜¸í™˜ì„ ìœ„í•œ ì•ˆì „í•œ í‘œì‹œ
                for col in stats_df.columns:
                    if stats_df[col].dtype == 'object':
                        stats_df[col] = stats_df[col].astype(str).replace('nan', '').replace('None', '')
                
                # st.dataframe(stats_df, use_container_width=True)
                st.dataframe(stats_df, width='stretch')
            
            # HDF5 ì €ì¥
            st.divider()
            st.subheader("ğŸ’¾ ë°ì´í„° ì €ì¥")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**ì €ì¥ í˜•ì‹:** HDF5")
            
            with col2:
                file_name = st.text_input("íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)", value="output_data", key='single_file_name')
                include_date = st.checkbox("íŒŒì¼ëª…ì— ë‚ ì§œ ì¶”ê°€", value=False, key='single_include_date')
            
            with col3:
                st.write("")
                st.write("")
                if st.button("ğŸ’¾ HDF5 ì €ì¥", type="primary", use_container_width=True, key='single_save_btn'):
                    try:
                        file_service = st.session_state.file_service
                        
                        # ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
                        date_str = file_service.extract_date_range(data) if include_date else ''
                        
                        # HDF5ë¡œ ì €ì¥
                        file_bytes = file_service.save_to_hdf5(data, compression='gzip')
                        
                        # íŒŒì¼ëª… ìƒì„±
                        if date_str:
                            download_name = f"{file_name}_{date_str}.h5"
                        else:
                            download_name = f"{file_name}.h5"
                        
                        st.download_button(
                            label=f"â¬‡ï¸ {download_name} ë‹¤ìš´ë¡œë“œ",
                            data=file_bytes,
                            file_name=download_name,
                            mime='application/x-hdf5',
                            use_container_width=True
                        )
                        
                        st.success("âœ… HDF5 íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ!")
                    
                    except Exception as e:
                        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
        
        # ë‹¤ì¤‘ DataFrame
        else:
            st.markdown(f"**ì´ {len(data)}ê°œ ì‹œíŠ¸ ë¡œë“œë¨**")
            
            selected_sheet = st.selectbox("ì‹œíŠ¸ ì„ íƒ", options=list(data.keys()), key='loading_sheet_select')
            df = data[selected_sheet]
            
            st.markdown(f"**Shape:** {df.shape[0]:,} rows Ã— {df.shape[1]:,} columns")
            
            with st.expander("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                n_rows = st.slider("í‘œì‹œí•  í–‰ ìˆ˜", 5, 100, 10, key='multi_sheet_preview_rows')
                
                # PyArrow í˜¸í™˜ì„ ìœ„í•œ ì•ˆì „í•œ í‘œì‹œ
                preview_df = df.head(n_rows).copy()
                for col in preview_df.columns:
                    if preview_df[col].dtype == 'object':
                        preview_df[col] = preview_df[col].astype(str).replace('nan', '').replace('None', '')
                
                st.dataframe(preview_df, width='stretch')
            
            if st.session_state.metadata and selected_sheet in st.session_state.metadata:
                with st.expander("â„¹ï¸ ë©”íƒ€ë°ì´í„°"):
                    meta = st.session_state.metadata[selected_sheet]
                    if 'header_metadata' in meta and meta['header_metadata']:
                        st.json(meta['header_metadata'])
            
            with st.expander("ğŸ“ˆ ê¸°ë³¸ í†µê³„"):
                stats_df = df.describe(include='all')
                
                # PyArrow í˜¸í™˜ì„ ìœ„í•œ ì•ˆì „í•œ í‘œì‹œ
                for col in stats_df.columns:
                    if stats_df[col].dtype == 'object':
                        stats_df[col] = stats_df[col].astype(str).replace('nan', '').replace('None', '')
                
                st.dataframe(stats_df, width='stretch')
            
            # ì €ì¥ ì˜µì…˜
            st.divider()
            st.subheader("ğŸ’¾ ë°ì´í„° ì €ì¥")
            
            all_sheet_names = list(data.keys())
            
            col_select1, col_select2 = st.columns([3, 1])
            
            with col_select1:
                save_mode = st.radio(
                    "ì €ì¥ ëª¨ë“œ",
                    ["ê°œë³„ ì €ì¥", "ì„ íƒí•œ ì‹œíŠ¸ ë³‘í•©", "ëª¨ë“  ì‹œíŠ¸ ë³‘í•©"],
                    horizontal=True,
                    key='multi_save_mode'
                )
            
            with col_select2:
                if save_mode != "ê°œë³„ ì €ì¥":
                    sort_by_time = st.checkbox("ì‹œê°„ìˆœ ì •ë ¬", value=True, key='sort_by_time')
                else:
                    sort_by_time = False
            
            selected_sheets = []
            if save_mode == "ì„ íƒí•œ ì‹œíŠ¸ ë³‘í•©":
                selected_sheets = st.multiselect(
                    "ë³‘í•©í•  ì‹œíŠ¸ ì„ íƒ",
                    options=all_sheet_names,
                    default=all_sheet_names[:min(3, len(all_sheet_names))],
                    key='selected_sheets_to_merge'
                )
                if not selected_sheets:
                    st.warning("âš ï¸ ë³‘í•©í•  ì‹œíŠ¸ë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif save_mode == "ëª¨ë“  ì‹œíŠ¸ ë³‘í•©":
                selected_sheets = all_sheet_names
                st.info(f"ğŸ“Š ì´ {len(selected_sheets)}ê°œ ì‹œíŠ¸ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.")
            
            st.divider()
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**ì €ì¥ í˜•ì‹:** HDF5")
                if save_mode == "ê°œë³„ ì €ì¥":
                    save_all = st.checkbox("ëª¨ë“  ì‹œíŠ¸ ì €ì¥", value=False, key='multi_save_all')
                else:
                    save_all = False
            
            with col2:
                file_name = st.text_input("íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)", value="output_data", key='multi_file_name')
                include_date = st.checkbox("íŒŒì¼ëª…ì— ë‚ ì§œ ì¶”ê°€", value=True, key='multi_include_date')
            
            with col3:
                st.write("")
                st.write("")
                if st.button("ğŸ’¾ HDF5 ì €ì¥", type="primary", use_container_width=True, key='multi_save_btn'):
                    try:
                        file_service = st.session_state.file_service
                        
                        # ë³‘í•© ëª¨ë“œ
                        if save_mode in ["ì„ íƒí•œ ì‹œíŠ¸ ë³‘í•©", "ëª¨ë“  ì‹œíŠ¸ ë³‘í•©"]:
                            if not selected_sheets:
                                st.error("âŒ ë³‘í•©í•  ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            else:
                                dfs_to_merge = [data[sheet] for sheet in selected_sheets]
                                
                                # timestamp ì»¬ëŸ¼ ì°¾ê¸°
                                has_timestamp = False
                                ts_col = None
                                for df_temp in dfs_to_merge:
                                    for col in df_temp.columns:
                                        if 'timestamp' in str(col).lower() or 'datetime' in str(col).lower():
                                            if pd.api.types.is_datetime64_any_dtype(df_temp[col]):
                                                has_timestamp = True
                                                ts_col = col
                                                break
                                    if has_timestamp:
                                        break
                                
                                merged_df = pd.concat(dfs_to_merge, ignore_index=True)
                                
                                if sort_by_time and has_timestamp and ts_col:
                                    merged_df = merged_df.sort_values(by=ts_col).reset_index(drop=True)
                                    st.success(f"âœ… {len(selected_sheets)}ê°œ ì‹œíŠ¸ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ë³‘í•©í–ˆìŠµë‹ˆë‹¤.")
                                else:
                                    st.success(f"âœ… {len(selected_sheets)}ê°œ ì‹œíŠ¸ë¥¼ ì…ë ¥ ìˆœì„œëŒ€ë¡œ ë³‘í•©í–ˆìŠµë‹ˆë‹¤.")
                                
                                date_str = file_service.extract_date_range(merged_df) if include_date else ''
                                
                                file_bytes = file_service.save_to_hdf5(merged_df, compression='gzip')
                                
                                if date_str:
                                    download_name = f"{file_name}_{date_str}_merged.h5"
                                else:
                                    download_name = f"{file_name}_merged.h5"
                                
                                st.download_button(
                                    label=f"â¬‡ï¸ {download_name} ë‹¤ìš´ë¡œë“œ",
                                    data=file_bytes,
                                    file_name=download_name,
                                    mime='application/x-hdf5',
                                    use_container_width=True
                                )
                        
                        # ê°œë³„ ì €ì¥ ëª¨ë“œ
                        elif save_mode == "ê°œë³„ ì €ì¥":
                            if save_all:
                                st.info(f"ì´ {len(data)}ê°œì˜ HDF5 íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
                                
                                import zipfile
                                zip_buffer = io.BytesIO()
                                
                                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                    for sheet_name, sheet_df in data.items():
                                        import re
                                        safe_name = re.sub(r'[<>:"/\\|?*]', '_', sheet_name)
                                        
                                        date_str = file_service.extract_date_range(sheet_df) if include_date else ''
                                        
                                        file_bytes = file_service.save_to_hdf5(sheet_df, compression='gzip')
                                        
                                        if date_str:
                                            file_name_in_zip = f"{file_name}_{date_str}_{safe_name}.h5"
                                        else:
                                            file_name_in_zip = f"{file_name}_{safe_name}.h5"
                                        
                                        zip_file.writestr(file_name_in_zip, file_bytes)
                                
                                zip_buffer.seek(0)
                                
                                if include_date:
                                    first_sheet = list(data.values())[0]
                                    date_str = file_service.extract_date_range(first_sheet)
                                    if date_str:
                                        zip_name = f"{file_name}_{date_str}_all_sheets.zip"
                                    else:
                                        zip_name = f"{file_name}_all_sheets.zip"
                                else:
                                    zip_name = f"{file_name}_all_sheets.zip"
                                
                                st.download_button(
                                    label=f"â¬‡ï¸ {zip_name} (ì „ì²´ ë‹¤ìš´ë¡œë“œ)",
                                    data=zip_buffer,
                                    file_name=zip_name,
                                    mime='application/zip',
                                    use_container_width=True
                                )
                                st.success(f"âœ… {len(data)}ê°œì˜ HDF5 íŒŒì¼ì´ ZIPìœ¼ë¡œ ì••ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            else:
                                # ì„ íƒëœ ì‹œíŠ¸ë§Œ
                                date_str = file_service.extract_date_range(df) if include_date else ''
                                
                                file_bytes = file_service.save_to_hdf5(df, compression='gzip')
                                
                                if date_str:
                                    download_name = f"{file_name}_{date_str}_{selected_sheet}.h5"
                                else:
                                    download_name = f"{file_name}_{selected_sheet}.h5"
                                
                                st.download_button(
                                    label=f"â¬‡ï¸ {download_name} ë‹¤ìš´ë¡œë“œ",
                                    data=file_bytes,
                                    file_name=download_name,
                                    mime='application/x-hdf5',
                                    use_container_width=True
                                )
                                st.success("âœ… HDF5 íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ!")
                    
                    except Exception as e:
                        st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())